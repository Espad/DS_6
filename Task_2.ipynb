{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекуррентные и свёрточные нейрононные сети и embeddings для работы с текстом.\n",
    "\n",
    "Датасет - Руcскоязычные отзывы с оценками.\n",
    "\n",
    "Метрика - на ваше усмотрение\n",
    "\n",
    "Задачи:\n",
    "\n",
    "- Обучить линейную модель на TF-IDF представлении для предсказания оценки пользователя по его отзыву. Посмотреть на важность для каждой оценки.\n",
    "- Обучить рекуррентную нейронную сеть для предсказания оценки пользователя по его отзыву. Использовать случайную инициализация весов.\n",
    "- Обучить «fasttext» модель на n-граммах используя случайную инициализацию эмбедингов. \n",
    "- Обучить сharacter based модель (вместо слов мы подаём предложение посимвольно). \n",
    "    Заимплементить самому, либо нагуглить готовые имплементации.\n",
    "- Опционально (for honor): Обучить модель из примера имплементации ниже, но с использованием уже предобученного word2vec для русского языка. в качестве инициализации эмбединга.\n",
    "\n",
    "Сравнить качество моделей, сделать выводы\n",
    "Почитать про слои которые используются для решения этого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in c:\\anaconda\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in c:\\anaconda\\lib\\site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in c:\\anaconda\\lib\\site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in c:\\anaconda\\lib\\site-packages (from pandas) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already up-to-date: scikit-learn in c:\\anaconda\\lib\\site-packages (0.20.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already up-to-date: inflect in c:\\anaconda\\lib\\site-packages (2.1.0)\n",
      "Requirement already up-to-date: seaborn in c:\\anaconda\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.15.2 in c:\\anaconda\\lib\\site-packages (from seaborn) (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in c:\\anaconda\\lib\\site-packages (from seaborn) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in c:\\anaconda\\lib\\site-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in c:\\anaconda\\lib\\site-packages (from seaborn) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in c:\\anaconda\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in c:\\anaconda\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.6.3)\n",
      "Requirement already up-to-date: pprint in c:\\anaconda\\lib\\site-packages (0.1)\n",
      "Requirement already up-to-date: tensorflow in c:\\anaconda\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.13.0,>=1.12.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.0.6)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in c:\\anaconda\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\anaconda\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\anaconda\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\anaconda\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n",
      "Requirement already up-to-date: pymystem3 in c:\\anaconda\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\anaconda\\lib\\site-packages (from pymystem3) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->pymystem3) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->pymystem3) (2018.11.29)\n",
      "Requirement already up-to-date: gensim in c:\\anaconda\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\anaconda\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.7.0 in c:\\anaconda\\lib\\site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\anaconda\\lib\\site-packages (from gensim) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\anaconda\\lib\\site-packages (from gensim) (1.13.3)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in c:\\anaconda\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.9.82)\n",
      "Requirement already satisfied, skipping upgrade: bz2file in c:\\anaconda\\lib\\site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in c:\\anaconda\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\anaconda\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.82 in c:\\anaconda\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.82)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\anaconda\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.2.0,>=0.1.10 in c:\\anaconda\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.1.13)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.10 in c:\\anaconda\\lib\\site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\anaconda\\lib\\site-packages (from botocore<1.13.0,>=1.12.82->boto3->smart-open>=1.7.0->gensim) (2.7.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade inflect\n",
    "!pip install --upgrade seaborn\n",
    "!pip install --upgrade pprint\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade pymystem3\n",
    "#!pip install --upgrade contractions\n",
    "#!pip install --upgrade wordcloud\n",
    "#!pip install --upgrade umap-learn\n",
    "!pip install --upgrade gensim\n",
    "#!pip install --upgrade pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "import inflect\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "#import glob\n",
    "#import contractions\n",
    "#from wordcloud import WordCloud\n",
    "#import umap\n",
    "#import unicodedata\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "#import time\n",
    "\n",
    "#from scipy import interp\n",
    "\n",
    "import pickle\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "seed = 321\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn libs\n",
    "from sklearn.preprocessing import label_binarize,MultiLabelBinarizer,StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score, make_scorer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import gensim\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import json\n",
    "import operator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Bidirectional, GlobalAveragePooling1D,Flatten,BatchNormalization\n",
    "from keras.metrics import binary_accuracy,categorical_accuracy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#convert words to sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chief\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chief\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chief\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\chief\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('names')\n",
    "\n",
    "from nltk.corpus import names\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer # one more stemmer? or lemmatisation\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = data[idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read first ten row to understand, how to parse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = pickle.load(open('data/task_2/reviews_dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769251"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769251"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Потрясающе красивая графика космоса! Уже за это игру можно полюбить. Так же в наличии интересный осмысленный сюжет и удобное управление.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline.\n",
    "\n",
    "Обучить линейную модель на TF-IDF представлении для предсказания оценки пользователя по его отзыву. \n",
    "\n",
    "Посмотреть на важность для каждой оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emails(text):\n",
    "    text = re.sub(r'\\S*@\\S*\\s?','',text)    \n",
    "    return text\n",
    "\n",
    "\n",
    "#version on raw text\n",
    "def remove_punctuation2(text_punctuation,text):\n",
    "    \n",
    "    new_text = []\n",
    "    new_text = re.sub('\\n', ' ',text)\n",
    "    new_text = re.sub('\\t', '',new_text)\n",
    "    new_text = re.sub('['+text_punctuation+']', ' ',new_text)\n",
    "    new_text =  new_text.strip()\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "#version after word_tokenizer\n",
    "def remove_punctuation(text_punctuation,text):\n",
    "    \n",
    "    new_text = []\n",
    "    for word in text: \n",
    "        new_word =  re.sub('['+text_punctuation+']', ' ',word)\n",
    "        new_word =  new_word.strip()\n",
    "        new_text.append(new_word)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "\n",
    "#ntlk word lemmatizer\n",
    "def lemmatize_stemm_text(text):\n",
    "    new_text_lemma = []\n",
    "    new_text_stemm = []\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = LancasterStemmer()\n",
    "    \n",
    "    for word in text:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='n') # v default\n",
    "        new_text_lemma.append(lemma)\n",
    "        \n",
    "        #stemm = stemmer.stem(word)\n",
    "        #new_text_stemm.append(stemm)\n",
    "        \n",
    "    return new_text_lemma, new_text_stemm\n",
    "        \n",
    "\n",
    "StopWords = list(set(stopwords.words('russian')))\n",
    "'''\n",
    "StopWords = list(set( stopwords.words('english') ).union( set(ENGLISH_STOP_WORDS)))\n",
    "newStopWords = ['jfc','jb'] # по ходу работы периодически добавляем стоп-слова\n",
    "newStopWords2 = ['arent', 'didnt', 'doesnt', 'dont', 'hadnt', 'havent', 'isnt', \n",
    "                 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'theres','thatll', 'wasnt', \n",
    "                 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve',\n",
    "                 \"'ll\", \"'re\", \"'ve\", \"n't\", 'need', 'sha', 'anna','n t','ann mari', 'ann marie', \n",
    "                 'anna diana', 'anna diane', 'anna maria', 'anne corinne', 'anne mar', 'anne marie', \n",
    "                 'barbara anne', 'bette ann', 'carol jean', 'diane marie', 'e lane', 'hans peter', \n",
    "                 'helen elizabeth', 'holly anne', 'jean christophe', 'jean francois', 'jean lou', \n",
    "                 'jean luc', 'jean marc', 'jean paul', 'jean pierre', 'jo anne', 'john david', 'john patrick', \n",
    "                 'kara lynn', 'marie ann', 'marie jeanne', 'paula grace', 'sara ann', \n",
    "                 'sheila kathryn', 'sue elle', 'terri jo', 'theresa marie','sza']\n",
    "\n",
    "#StopWords.extend(newStopWords)\n",
    "#StopWords.extend(newStopWords2)\n",
    "\n",
    "\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "\n",
    "Common_First_Names = list(set(male_names).union(set(female_names)))\n",
    "Common_First_Names = list(map(lambda word: word.lower(), Common_First_Names))\n",
    "# temporaly disabled to reduce tfidf time\n",
    "#StopWords.extend(Common_First_Names) ''';\n",
    "\n",
    "def remove_stopwords(stop_words ,text):\n",
    "    \n",
    "    new_words = []\n",
    "    for word in text:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def remove_short_words(text, word_len):\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if len(word) >= word_len:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    return new_text\n",
    "\n",
    "\n",
    "# getting source from string.punctuation\n",
    "text_punctuation = '!\"#$%&\\'()*+,-.:;<=>?@[\\\\]_`{|}~/^'\n",
    "\n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    \n",
    "    # remove emails from text to prevent overfit\n",
    "    text = remove_emails(text)\n",
    "    \n",
    "    # text to lowercase\n",
    "    text =  text.lower()\n",
    "\n",
    "    \n",
    "    #remove punctuation\n",
    "    text = remove_punctuation2(text_punctuation, text) \n",
    "\n",
    "    # tokenize text\n",
    "    words = word_tokenize(text,language='english')\n",
    "\n",
    "       \n",
    "    # remove stopwords\n",
    "    words = remove_stopwords(StopWords,words)\n",
    "    \n",
    "    #lemmatize words ,improve to 0.69 f1score\n",
    "    words,_ = lemmatize_stemm_text(words)\n",
    "    \n",
    "    #filter short words\n",
    "    words = remove_short_words(words, 2) #default 3\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = tokenize(x_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['таки',\n",
       " 'удержался',\n",
       " 'написать',\n",
       " 'топ',\n",
       " 'скорей',\n",
       " 'сотрут',\n",
       " 'прочтет',\n",
       " 'ужасной',\n",
       " 'игры',\n",
       " 'star',\n",
       " 'war',\n",
       " 'empire',\n",
       " 'at',\n",
       " 'war',\n",
       " 'dvd',\n",
       " 'ещё',\n",
       " 'поискать',\n",
       " 'нормального',\n",
       " 'сюжета',\n",
       " 'стратегия',\n",
       " 'это',\n",
       " 'вовсе',\n",
       " 'провал',\n",
       " 'давно',\n",
       " 'убедился',\n",
       " 'всё',\n",
       " 'берётся',\n",
       " '1с',\n",
       " 'плане',\n",
       " 'игр',\n",
       " 'отстой',\n",
       " 'хорошая',\n",
       " 'стратегия',\n",
       " 'эпизодам',\n",
       " 'star',\n",
       " 'war',\n",
       " 'это',\n",
       " 'star',\n",
       " 'war',\n",
       " 'galactic',\n",
       " 'battleground',\n",
       " 'играл',\n",
       " 'поймет']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = seed, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF + LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=StopWords,\n",
    "                             tokenizer=tokenize, \n",
    "                             min_df=4, # ignore terms with freq less that т, lower majoring 4\n",
    "                             max_df=0.8, # ignore terms with freq more that n, upper majoring 0.8\n",
    "                             #max_features=100000,\n",
    "                             use_idf=True,  \n",
    "                             sublinear_tf=True,\n",
    "                             norm='l2',\n",
    "                             #ngram_range= (1, 3) # также используем н-граммы\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorised_train_documents = vectorizer.fit_transform(x_train)\n",
    "vectorised_test_documents = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538475, 143312)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_train_documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230776, 143312)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_test_documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_score(classifier, X_train, X_test, y_train, y_test):\n",
    "    clf = classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = clf.predict(X_train)\n",
    "    #print (\"Train score\")\n",
    "    f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "\n",
    "    #print (\"Test score\")\n",
    "    pred_test = clf.predict(X_test)\n",
    "    f1_test = f1_score(y_test, pred_test, average='weighted')\n",
    "    \n",
    "    return f1_train, f1_test, clf\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Paired):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2', tol=0.0001, C=1, \n",
    "                             class_weight='balanced', random_state=seed, \n",
    "                             max_iter=1000, solver = 'newton-cg',\n",
    "                             multi_class='ovr', verbose=0, \n",
    "                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_,_, clf = classify_and_score(log_reg, vectorised_train_documents, \n",
    "                           vectorised_test_documents, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.57      0.48     16683\n",
      "           2       0.16      0.22      0.19      9679\n",
      "           3       0.24      0.34      0.28     17653\n",
      "           4       0.34      0.41      0.37     33086\n",
      "           5       0.89      0.76      0.82    153675\n",
      "\n",
      "   micro avg       0.64      0.64      0.64    230776\n",
      "   macro avg       0.41      0.46      0.43    230776\n",
      "weighted avg       0.70      0.64      0.66    230776\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = clf.classes_\n",
    "pred_test = clf.predict(vectorised_test_documents)\n",
    "print(classification_report(y_test,pred_test,labels = labels))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, pred_test)\n",
    "print(plot_confusion_matrix(cnf_matrix, classes = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить рекуррентную нейронную сеть для предсказания оценки пользователя по его отзыву. Использовать случайную инициализация весов.\n",
    "\n",
    "- add stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = seed, \n",
    "                                                    test_size=0.3, shuffle=True,\n",
    "                                                    stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "num_word = 15000\n",
    "max_features = 20000\n",
    "batch_size = 128\n",
    "embedding_dims = 128\n",
    "epochs = 3\n",
    "maxlen = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485401\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(num_words=num_word)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print (vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_y_train)\n",
    "y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.array(y_train)\n",
    "#y_test = np.array(y_test)\n",
    "\n",
    "print (vocab_size)\n",
    "\n",
    "print(x_train[0])\n",
    "\n",
    "print(len(x_train[0]))\n",
    "\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6579   365     7 14591     1  2034    15  7231  2724    11    28    20\n",
      "  3633    39     1   548    13    80     4  6272  3817  7044  8109    11\n",
      "  1967  1093  3690    19     6  2560     1     2  1696  6620   828     1\n",
      "    39     5 12961     9  4132  4398  7125     3     7  6858 12318  3059\n",
      "  1786     7 12318  3059     2     4  3784   102  3817   665  1525  3729\n",
      "     6    33    14 13308  1708     7 12318  3059   879  4643     7  2726\n",
      "    10    54 10758    15   283 14297   558  3611]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62131328"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size * 128 # params of first layer, 128 is number of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 80, 128)           62131328  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 62,230,789\n",
      "Trainable params: 62,230,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = 128, \n",
    "                    input_length=maxlen))#weights!\n",
    "model.add(Bidirectional(LSTM(64)))# weights!\n",
    "model.add(Dropout(0.1))\n",
    "#model.add(Dropout(0.5)) #1\n",
    "model.add(Dense(5, activation='softmax')) #softmax due to multiclass\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=2, verbose=2, mode='max',restore_best_weights=True)\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no stratify\n",
    "x_train_part,y_train_part = next_batch(15000, x_train, y_train)\n",
    "x_test_part,y_test_part = next_batch(5000, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      " - 219s - loss: 1.0673 - acc: 0.6558 - val_loss: 0.9358 - val_acc: 0.6658\n",
      "Epoch 2/3\n",
      " - 214s - loss: 0.8162 - acc: 0.6897 - val_loss: 0.9086 - val_acc: 0.6704\n",
      "Epoch 3/3\n",
      " - 221s - loss: 0.6613 - acc: 0.7504 - val_loss: 0.9878 - val_acc: 0.6750\n",
      "Wall time: 10min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Train...')\n",
    "model.fit(x_train_part, y_train_part,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose = 2,\n",
    "          callbacks=[earlyStopping],\n",
    "          validation_data=[x_test_part, y_test_part])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.11      0.19       369\n",
      "           1       0.00      0.00      0.00       206\n",
      "           2       0.00      0.00      0.00       384\n",
      "           3       0.41      0.11      0.17       717\n",
      "           4       0.81      0.86      0.83      3324\n",
      "\n",
      "   micro avg       0.78      0.60      0.68      5000\n",
      "   macro avg       0.37      0.22      0.24      5000\n",
      "weighted avg       0.64      0.60      0.59      5000\n",
      " samples avg       0.60      0.60      0.60      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_scores = model.predict(x_test_part)\n",
    "y_predicted_scores[y_predicted_scores>=0.5] = 1\n",
    "y_predicted_scores[y_predicted_scores<0.5] = 0\n",
    "\n",
    "print('Classification report\\n')\n",
    "print(classification_report(y_test_part, y_predicted_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fasttext.\n",
    "\n",
    "Обучить «fasttext» модель на n-граммах используя случайную инициализацию эмбедингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = seed, \n",
    "                                                    test_size=0.3, shuffle=True,\n",
    "                                                    stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters:\n",
    "# ngram_range = 2 will add bi-grams features\n",
    "ngram_range = 2\n",
    "max_features = 20000\n",
    "maxlen = 250\n",
    "batch_size = 128\n",
    "embedding_dims = 64\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_y_train)\n",
    "y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2-gram features\n",
      "Average train sequence length: 54\n",
      "Average test sequence length: 52\n"
     ]
    }
   ],
   "source": [
    "if ngram_range > 1:\n",
    "    print('Adding {}-gram features'.format(ngram_range))\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in x_train:\n",
    "        for i in range(2, ngram_range + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = max_features + 1\n",
    "    token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indice_token = {token_indice[k]: k for k in token_indice}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    max_features = np.max(list(indice_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    x_train = add_ngram(x_train, token_indice, ngram_range)\n",
    "    x_test = add_ngram(x_test, token_indice, ngram_range)\n",
    "    print('Average train sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_train)), dtype=int)))\n",
    "    print('Average test sequence length: {}'.format(\n",
    "        np.mean(list(map(len, x_test)), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (538475, 250)\n",
      "x_test shape: (230776, 250)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = x_train.max()#len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_part,y_train_part = next_batch(25000, x_train, y_train)\n",
    "x_test_part,y_test_part = next_batch(11000, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 250, 64)           132820032 \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 132,820,357\n",
      "Trainable params: 132,820,357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "# используя случайную инициализацию эмбедингов\n",
    "model.add(Embedding(input_dim = vocab_size,\n",
    "                    output_dim = embedding_dims,\n",
    "                    input_length=maxlen, \n",
    "                    embeddings_initializer = 'RandomNormal')) \n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a softmax:\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=2, verbose=2, mode='max',restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = sgd,\n",
    "              #optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='mse', optimizer=TFOptimizer(tf.train.GradientDescentOptimizer(0.1)))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:109: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 132820032 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 11000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - ETA: 27:38 - loss: 1.6295 - acc: 0.05 - ETA: 16:07 - loss: 1.6277 - acc: 0.05 - ETA: 12:16 - loss: 1.6247 - acc: 0.05 - ETA: 10:15 - loss: 1.6185 - acc: 0.04 - ETA: 9:03 - loss: 1.6122 - acc: 0.0797 - ETA: 8:10 - loss: 1.6034 - acc: 0.181 - ETA: 7:32 - loss: 1.5934 - acc: 0.248 - ETA: 7:03 - loss: 1.5849 - acc: 0.293 - ETA: 6:41 - loss: 1.5754 - acc: 0.327 - ETA: 6:22 - loss: 1.5626 - acc: 0.362 - ETA: 6:07 - loss: 1.5487 - acc: 0.393 - ETA: 5:54 - loss: 1.5347 - acc: 0.418 - ETA: 5:43 - loss: 1.5221 - acc: 0.437 - ETA: 5:34 - loss: 1.5129 - acc: 0.448 - ETA: 5:24 - loss: 1.4980 - acc: 0.465 - ETA: 5:17 - loss: 1.4860 - acc: 0.476 - ETA: 5:10 - loss: 1.4759 - acc: 0.483 - ETA: 5:04 - loss: 1.4647 - acc: 0.491 - ETA: 4:58 - loss: 1.4511 - acc: 0.501 - ETA: 4:53 - loss: 1.4372 - acc: 0.511 - ETA: 4:48 - loss: 1.4228 - acc: 0.520 - ETA: 4:44 - loss: 1.4090 - acc: 0.529 - ETA: 4:39 - loss: 1.4019 - acc: 0.532 - ETA: 4:35 - loss: 1.3919 - acc: 0.537 - ETA: 4:31 - loss: 1.3818 - acc: 0.543 - ETA: 4:28 - loss: 1.3717 - acc: 0.547 - ETA: 4:25 - loss: 1.3618 - acc: 0.552 - ETA: 4:22 - loss: 1.3590 - acc: 0.552 - ETA: 4:20 - loss: 1.3473 - acc: 0.558 - ETA: 4:18 - loss: 1.3425 - acc: 0.559 - ETA: 4:15 - loss: 1.3382 - acc: 0.561 - ETA: 4:12 - loss: 1.3306 - acc: 0.564 - ETA: 4:09 - loss: 1.3252 - acc: 0.567 - ETA: 4:06 - loss: 1.3144 - acc: 0.571 - ETA: 4:03 - loss: 1.3101 - acc: 0.573 - ETA: 4:00 - loss: 1.3072 - acc: 0.574 - ETA: 3:58 - loss: 1.3003 - acc: 0.577 - ETA: 3:55 - loss: 1.2932 - acc: 0.580 - ETA: 3:53 - loss: 1.2877 - acc: 0.582 - ETA: 3:50 - loss: 1.2804 - acc: 0.585 - ETA: 3:48 - loss: 1.2805 - acc: 0.585 - ETA: 3:46 - loss: 1.2782 - acc: 0.586 - ETA: 3:44 - loss: 1.2741 - acc: 0.587 - ETA: 3:43 - loss: 1.2688 - acc: 0.589 - ETA: 3:41 - loss: 1.2670 - acc: 0.590 - ETA: 3:39 - loss: 1.2650 - acc: 0.591 - ETA: 3:37 - loss: 1.2593 - acc: 0.593 - ETA: 3:35 - loss: 1.2555 - acc: 0.594 - ETA: 3:34 - loss: 1.2529 - acc: 0.595 - ETA: 3:32 - loss: 1.2510 - acc: 0.596 - ETA: 3:30 - loss: 1.2483 - acc: 0.597 - ETA: 3:28 - loss: 1.2426 - acc: 0.600 - ETA: 3:27 - loss: 1.2391 - acc: 0.601 - ETA: 3:25 - loss: 1.2349 - acc: 0.603 - ETA: 3:23 - loss: 1.2311 - acc: 0.605 - ETA: 3:21 - loss: 1.2275 - acc: 0.606 - ETA: 3:19 - loss: 1.2279 - acc: 0.605 - ETA: 3:17 - loss: 1.2249 - acc: 0.606 - ETA: 3:15 - loss: 1.2238 - acc: 0.607 - ETA: 3:13 - loss: 1.2214 - acc: 0.608 - ETA: 3:12 - loss: 1.2193 - acc: 0.609 - ETA: 3:10 - loss: 1.2181 - acc: 0.609 - ETA: 3:08 - loss: 1.2159 - acc: 0.610 - ETA: 3:06 - loss: 1.2156 - acc: 0.609 - ETA: 3:05 - loss: 1.2135 - acc: 0.610 - ETA: 3:03 - loss: 1.2124 - acc: 0.611 - ETA: 3:01 - loss: 1.2099 - acc: 0.612 - ETA: 3:00 - loss: 1.2084 - acc: 0.612 - ETA: 2:58 - loss: 1.2079 - acc: 0.612 - ETA: 2:56 - loss: 1.2054 - acc: 0.613 - ETA: 2:55 - loss: 1.2040 - acc: 0.614 - ETA: 2:53 - loss: 1.2013 - acc: 0.615 - ETA: 2:52 - loss: 1.1984 - acc: 0.616 - ETA: 2:50 - loss: 1.1980 - acc: 0.616 - ETA: 2:49 - loss: 1.1974 - acc: 0.616 - ETA: 2:47 - loss: 1.1962 - acc: 0.616 - ETA: 2:46 - loss: 1.1946 - acc: 0.617 - ETA: 2:44 - loss: 1.1925 - acc: 0.618 - ETA: 2:42 - loss: 1.1902 - acc: 0.619 - ETA: 2:41 - loss: 1.1868 - acc: 0.621 - ETA: 2:39 - loss: 1.1872 - acc: 0.620 - ETA: 2:38 - loss: 1.1856 - acc: 0.621 - ETA: 2:36 - loss: 1.1846 - acc: 0.621 - ETA: 2:35 - loss: 1.1849 - acc: 0.621 - ETA: 2:33 - loss: 1.1826 - acc: 0.622 - ETA: 2:32 - loss: 1.1821 - acc: 0.622 - ETA: 2:31 - loss: 1.1813 - acc: 0.622 - ETA: 2:29 - loss: 1.1791 - acc: 0.623 - ETA: 2:27 - loss: 1.1787 - acc: 0.624 - ETA: 2:26 - loss: 1.1784 - acc: 0.624 - ETA: 2:24 - loss: 1.1780 - acc: 0.623 - ETA: 2:23 - loss: 1.1777 - acc: 0.623 - ETA: 2:22 - loss: 1.1773 - acc: 0.623 - ETA: 2:20 - loss: 1.1760 - acc: 0.624 - ETA: 2:19 - loss: 1.1748 - acc: 0.624 - ETA: 2:17 - loss: 1.1733 - acc: 0.625 - ETA: 2:16 - loss: 1.1719 - acc: 0.625 - ETA: 2:14 - loss: 1.1703 - acc: 0.626 - ETA: 2:13 - loss: 1.1694 - acc: 0.626 - ETA: 2:11 - loss: 1.1674 - acc: 0.627 - ETA: 2:10 - loss: 1.1660 - acc: 0.628 - ETA: 2:08 - loss: 1.1657 - acc: 0.628 - ETA: 2:07 - loss: 1.1643 - acc: 0.628 - ETA: 2:05 - loss: 1.1630 - acc: 0.628 - ETA: 2:04 - loss: 1.1624 - acc: 0.628 - ETA: 2:02 - loss: 1.1625 - acc: 0.628 - ETA: 2:01 - loss: 1.1612 - acc: 0.629 - ETA: 1:59 - loss: 1.1602 - acc: 0.629 - ETA: 1:58 - loss: 1.1599 - acc: 0.629 - ETA: 1:57 - loss: 1.1579 - acc: 0.630 - ETA: 1:55 - loss: 1.1590 - acc: 0.630 - ETA: 1:54 - loss: 1.1584 - acc: 0.630 - ETA: 1:52 - loss: 1.1570 - acc: 0.630 - ETA: 1:51 - loss: 1.1563 - acc: 0.631 - ETA: 1:50 - loss: 1.1543 - acc: 0.632 - ETA: 1:48 - loss: 1.1543 - acc: 0.631 - ETA: 1:47 - loss: 1.1540 - acc: 0.631 - ETA: 1:45 - loss: 1.1528 - acc: 0.632 - ETA: 1:44 - loss: 1.1520 - acc: 0.632 - ETA: 1:43 - loss: 1.1516 - acc: 0.632 - ETA: 1:41 - loss: 1.1516 - acc: 0.632 - ETA: 1:40 - loss: 1.1513 - acc: 0.633 - ETA: 1:38 - loss: 1.1512 - acc: 0.633 - ETA: 1:37 - loss: 1.1506 - acc: 0.633 - ETA: 1:36 - loss: 1.1501 - acc: 0.633 - ETA: 1:34 - loss: 1.1496 - acc: 0.633 - ETA: 1:33 - loss: 1.1487 - acc: 0.634 - ETA: 1:32 - loss: 1.1483 - acc: 0.634 - ETA: 1:30 - loss: 1.1478 - acc: 0.634 - ETA: 1:29 - loss: 1.1463 - acc: 0.635 - ETA: 1:28 - loss: 1.1461 - acc: 0.635 - ETA: 1:26 - loss: 1.1468 - acc: 0.634 - ETA: 1:25 - loss: 1.1454 - acc: 0.635 - ETA: 1:23 - loss: 1.1443 - acc: 0.635 - ETA: 1:22 - loss: 1.1437 - acc: 0.636 - ETA: 1:21 - loss: 1.1429 - acc: 0.636 - ETA: 1:19 - loss: 1.1437 - acc: 0.636 - ETA: 1:18 - loss: 1.1429 - acc: 0.636 - ETA: 1:17 - loss: 1.1418 - acc: 0.636 - ETA: 1:15 - loss: 1.1404 - acc: 0.637 - ETA: 1:14 - loss: 1.1406 - acc: 0.637 - ETA: 1:13 - loss: 1.1406 - acc: 0.637 - ETA: 1:11 - loss: 1.1404 - acc: 0.637 - ETA: 1:10 - loss: 1.1389 - acc: 0.637 - ETA: 1:09 - loss: 1.1385 - acc: 0.638 - ETA: 1:07 - loss: 1.1381 - acc: 0.638 - ETA: 1:06 - loss: 1.1382 - acc: 0.638 - ETA: 1:04 - loss: 1.1373 - acc: 0.638 - ETA: 1:03 - loss: 1.1362 - acc: 0.638 - ETA: 1:02 - loss: 1.1370 - acc: 0.638 - ETA: 1:00 - loss: 1.1364 - acc: 0.638 - ETA: 59s - loss: 1.1360 - acc: 0.639 - ETA: 57s - loss: 1.1356 - acc: 0.63 - ETA: 56s - loss: 1.1349 - acc: 0.63 - ETA: 55s - loss: 1.1344 - acc: 0.63 - ETA: 53s - loss: 1.1329 - acc: 0.64 - ETA: 52s - loss: 1.1324 - acc: 0.64 - ETA: 50s - loss: 1.1324 - acc: 0.64 - ETA: 49s - loss: 1.1312 - acc: 0.64 - ETA: 48s - loss: 1.1301 - acc: 0.64 - ETA: 46s - loss: 1.1306 - acc: 0.64 - ETA: 45s - loss: 1.1299 - acc: 0.64 - ETA: 44s - loss: 1.1301 - acc: 0.64 - ETA: 42s - loss: 1.1299 - acc: 0.64 - ETA: 41s - loss: 1.1294 - acc: 0.64 - ETA: 39s - loss: 1.1289 - acc: 0.64 - ETA: 38s - loss: 1.1281 - acc: 0.64 - ETA: 37s - loss: 1.1271 - acc: 0.64 - ETA: 35s - loss: 1.1269 - acc: 0.64 - ETA: 34s - loss: 1.1268 - acc: 0.64 - ETA: 33s - loss: 1.1259 - acc: 0.64 - ETA: 31s - loss: 1.1243 - acc: 0.64 - ETA: 30s - loss: 1.1245 - acc: 0.64 - ETA: 29s - loss: 1.1246 - acc: 0.64 - ETA: 27s - loss: 1.1248 - acc: 0.64 - ETA: 26s - loss: 1.1248 - acc: 0.64 - ETA: 24s - loss: 1.1245 - acc: 0.64 - ETA: 23s - loss: 1.1245 - acc: 0.64 - ETA: 22s - loss: 1.1247 - acc: 0.64 - ETA: 20s - loss: 1.1248 - acc: 0.64 - ETA: 19s - loss: 1.1244 - acc: 0.64 - ETA: 18s - loss: 1.1235 - acc: 0.64 - ETA: 16s - loss: 1.1228 - acc: 0.64 - ETA: 15s - loss: 1.1226 - acc: 0.64 - ETA: 13s - loss: 1.1224 - acc: 0.64 - ETA: 12s - loss: 1.1221 - acc: 0.64 - ETA: 11s - loss: 1.1226 - acc: 0.64 - ETA: 9s - loss: 1.1219 - acc: 0.6445 - ETA: 8s - loss: 1.1215 - acc: 0.644 - ETA: 7s - loss: 1.1215 - acc: 0.644 - ETA: 5s - loss: 1.1210 - acc: 0.644 - ETA: 4s - loss: 1.1206 - acc: 0.645 - ETA: 3s - loss: 1.1206 - acc: 0.645 - ETA: 1s - loss: 1.1208 - acc: 0.644 - ETA: 0s - loss: 1.1210 - acc: 0.644 - 266s 11ms/step - loss: 1.1210 - acc: 0.6447 - val_loss: 1.0822 - val_acc: 0.6605\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - ETA: 4:07 - loss: 1.0741 - acc: 0.656 - ETA: 4:10 - loss: 1.0352 - acc: 0.679 - ETA: 4:09 - loss: 0.9831 - acc: 0.703 - ETA: 4:08 - loss: 1.0380 - acc: 0.681 - ETA: 4:06 - loss: 1.0402 - acc: 0.676 - ETA: 4:04 - loss: 1.0430 - acc: 0.675 - ETA: 4:03 - loss: 1.0424 - acc: 0.678 - ETA: 4:01 - loss: 1.0381 - acc: 0.681 - ETA: 4:02 - loss: 1.0476 - acc: 0.676 - ETA: 3:59 - loss: 1.0575 - acc: 0.670 - ETA: 3:58 - loss: 1.0476 - acc: 0.674 - ETA: 3:56 - loss: 1.0601 - acc: 0.668 - ETA: 3:55 - loss: 1.0669 - acc: 0.664 - ETA: 3:54 - loss: 1.0642 - acc: 0.664 - ETA: 3:53 - loss: 1.0675 - acc: 0.663 - ETA: 3:52 - loss: 1.0638 - acc: 0.664 - ETA: 3:50 - loss: 1.0736 - acc: 0.660 - ETA: 3:49 - loss: 1.0699 - acc: 0.662 - ETA: 3:48 - loss: 1.0692 - acc: 0.661 - ETA: 3:46 - loss: 1.0694 - acc: 0.660 - ETA: 3:45 - loss: 1.0690 - acc: 0.660 - ETA: 3:44 - loss: 1.0674 - acc: 0.660 - ETA: 3:42 - loss: 1.0655 - acc: 0.662 - ETA: 3:40 - loss: 1.0650 - acc: 0.662 - ETA: 3:39 - loss: 1.0646 - acc: 0.663 - ETA: 3:38 - loss: 1.0640 - acc: 0.664 - ETA: 3:37 - loss: 1.0679 - acc: 0.662 - ETA: 3:35 - loss: 1.0655 - acc: 0.664 - ETA: 3:34 - loss: 1.0653 - acc: 0.665 - ETA: 3:33 - loss: 1.0686 - acc: 0.663 - ETA: 3:31 - loss: 1.0665 - acc: 0.664 - ETA: 3:30 - loss: 1.0670 - acc: 0.664 - ETA: 3:29 - loss: 1.0638 - acc: 0.666 - ETA: 3:27 - loss: 1.0655 - acc: 0.665 - ETA: 3:26 - loss: 1.0692 - acc: 0.663 - ETA: 3:25 - loss: 1.0715 - acc: 0.661 - ETA: 3:24 - loss: 1.0710 - acc: 0.662 - ETA: 3:22 - loss: 1.0741 - acc: 0.660 - ETA: 3:21 - loss: 1.0738 - acc: 0.660 - ETA: 3:20 - loss: 1.0758 - acc: 0.659 - ETA: 3:18 - loss: 1.0759 - acc: 0.658 - ETA: 3:17 - loss: 1.0763 - acc: 0.659 - ETA: 3:16 - loss: 1.0745 - acc: 0.660 - ETA: 3:14 - loss: 1.0735 - acc: 0.660 - ETA: 3:13 - loss: 1.0751 - acc: 0.660 - ETA: 3:12 - loss: 1.0749 - acc: 0.660 - ETA: 3:10 - loss: 1.0784 - acc: 0.658 - ETA: 3:09 - loss: 1.0801 - acc: 0.657 - ETA: 3:08 - loss: 1.0783 - acc: 0.658 - ETA: 3:07 - loss: 1.0780 - acc: 0.658 - ETA: 3:05 - loss: 1.0807 - acc: 0.657 - ETA: 3:04 - loss: 1.0814 - acc: 0.657 - ETA: 3:03 - loss: 1.0811 - acc: 0.657 - ETA: 3:01 - loss: 1.0810 - acc: 0.657 - ETA: 3:00 - loss: 1.0804 - acc: 0.657 - ETA: 2:59 - loss: 1.0822 - acc: 0.656 - ETA: 2:57 - loss: 1.0803 - acc: 0.658 - ETA: 2:56 - loss: 1.0794 - acc: 0.658 - ETA: 2:55 - loss: 1.0793 - acc: 0.658 - ETA: 2:54 - loss: 1.0791 - acc: 0.658 - ETA: 2:53 - loss: 1.0806 - acc: 0.657 - ETA: 2:51 - loss: 1.0806 - acc: 0.657 - ETA: 2:50 - loss: 1.0794 - acc: 0.658 - ETA: 2:49 - loss: 1.0812 - acc: 0.657 - ETA: 2:47 - loss: 1.0791 - acc: 0.658 - ETA: 2:46 - loss: 1.0797 - acc: 0.658 - ETA: 2:45 - loss: 1.0819 - acc: 0.657 - ETA: 2:44 - loss: 1.0812 - acc: 0.658 - ETA: 2:42 - loss: 1.0813 - acc: 0.658 - ETA: 2:41 - loss: 1.0824 - acc: 0.657 - ETA: 2:40 - loss: 1.0817 - acc: 0.657 - ETA: 2:38 - loss: 1.0824 - acc: 0.657 - ETA: 2:37 - loss: 1.0826 - acc: 0.657 - ETA: 2:36 - loss: 1.0818 - acc: 0.657 - ETA: 2:35 - loss: 1.0832 - acc: 0.656 - ETA: 2:33 - loss: 1.0835 - acc: 0.656 - ETA: 2:32 - loss: 1.0827 - acc: 0.656 - ETA: 2:31 - loss: 1.0822 - acc: 0.657 - ETA: 2:29 - loss: 1.0820 - acc: 0.657 - ETA: 2:28 - loss: 1.0800 - acc: 0.658 - ETA: 2:27 - loss: 1.0816 - acc: 0.657 - ETA: 2:25 - loss: 1.0827 - acc: 0.657 - ETA: 2:24 - loss: 1.0845 - acc: 0.656 - ETA: 2:23 - loss: 1.0843 - acc: 0.656 - ETA: 2:22 - loss: 1.0851 - acc: 0.655 - ETA: 2:20 - loss: 1.0851 - acc: 0.656 - ETA: 2:19 - loss: 1.0836 - acc: 0.657 - ETA: 2:18 - loss: 1.0825 - acc: 0.657 - ETA: 2:17 - loss: 1.0822 - acc: 0.657 - ETA: 2:15 - loss: 1.0828 - acc: 0.657 - ETA: 2:14 - loss: 1.0831 - acc: 0.657 - ETA: 2:13 - loss: 1.0832 - acc: 0.657 - ETA: 2:11 - loss: 1.0806 - acc: 0.658 - ETA: 2:10 - loss: 1.0812 - acc: 0.658 - ETA: 2:09 - loss: 1.0831 - acc: 0.657 - ETA: 2:07 - loss: 1.0832 - acc: 0.657 - ETA: 2:06 - loss: 1.0817 - acc: 0.658 - ETA: 2:05 - loss: 1.0817 - acc: 0.657 - ETA: 2:04 - loss: 1.0813 - acc: 0.658 - ETA: 2:02 - loss: 1.0819 - acc: 0.657 - ETA: 2:01 - loss: 1.0814 - acc: 0.658 - ETA: 2:00 - loss: 1.0821 - acc: 0.657 - ETA: 1:58 - loss: 1.0827 - acc: 0.657 - ETA: 1:57 - loss: 1.0820 - acc: 0.657 - ETA: 1:56 - loss: 1.0803 - acc: 0.658 - ETA: 1:54 - loss: 1.0801 - acc: 0.658 - ETA: 1:53 - loss: 1.0796 - acc: 0.659 - ETA: 1:52 - loss: 1.0802 - acc: 0.658 - ETA: 1:51 - loss: 1.0802 - acc: 0.658 - ETA: 1:49 - loss: 1.0793 - acc: 0.659 - ETA: 1:48 - loss: 1.0790 - acc: 0.659 - ETA: 1:47 - loss: 1.0787 - acc: 0.659 - ETA: 1:45 - loss: 1.0785 - acc: 0.659 - ETA: 1:44 - loss: 1.0794 - acc: 0.658 - ETA: 1:43 - loss: 1.0784 - acc: 0.659 - ETA: 1:42 - loss: 1.0783 - acc: 0.659 - ETA: 1:40 - loss: 1.0787 - acc: 0.659 - ETA: 1:39 - loss: 1.0792 - acc: 0.658 - ETA: 1:38 - loss: 1.0782 - acc: 0.659 - ETA: 1:36 - loss: 1.0783 - acc: 0.659 - ETA: 1:35 - loss: 1.0787 - acc: 0.659 - ETA: 1:34 - loss: 1.0789 - acc: 0.658 - ETA: 1:33 - loss: 1.0796 - acc: 0.658 - ETA: 1:31 - loss: 1.0790 - acc: 0.658 - ETA: 1:30 - loss: 1.0806 - acc: 0.658 - ETA: 1:29 - loss: 1.0817 - acc: 0.657 - ETA: 1:27 - loss: 1.0816 - acc: 0.657 - ETA: 1:26 - loss: 1.0821 - acc: 0.657 - ETA: 1:25 - loss: 1.0824 - acc: 0.657 - ETA: 1:23 - loss: 1.0814 - acc: 0.657 - ETA: 1:22 - loss: 1.0814 - acc: 0.657 - ETA: 1:21 - loss: 1.0806 - acc: 0.658 - ETA: 1:20 - loss: 1.0800 - acc: 0.658 - ETA: 1:18 - loss: 1.0801 - acc: 0.658 - ETA: 1:17 - loss: 1.0809 - acc: 0.658 - ETA: 1:16 - loss: 1.0806 - acc: 0.658 - ETA: 1:14 - loss: 1.0802 - acc: 0.658 - ETA: 1:13 - loss: 1.0805 - acc: 0.658 - ETA: 1:12 - loss: 1.0811 - acc: 0.658 - ETA: 1:11 - loss: 1.0810 - acc: 0.657 - ETA: 1:09 - loss: 1.0813 - acc: 0.657 - ETA: 1:08 - loss: 1.0807 - acc: 0.658 - ETA: 1:07 - loss: 1.0795 - acc: 0.658 - ETA: 1:05 - loss: 1.0805 - acc: 0.658 - ETA: 1:04 - loss: 1.0804 - acc: 0.658 - ETA: 1:03 - loss: 1.0798 - acc: 0.658 - ETA: 1:02 - loss: 1.0796 - acc: 0.658 - ETA: 1:00 - loss: 1.0795 - acc: 0.658 - ETA: 59s - loss: 1.0799 - acc: 0.658 - ETA: 58s - loss: 1.0802 - acc: 0.65 - ETA: 56s - loss: 1.0803 - acc: 0.65 - ETA: 55s - loss: 1.0798 - acc: 0.65 - ETA: 54s - loss: 1.0793 - acc: 0.65 - ETA: 53s - loss: 1.0793 - acc: 0.65 - ETA: 51s - loss: 1.0794 - acc: 0.65 - ETA: 50s - loss: 1.0793 - acc: 0.65 - ETA: 49s - loss: 1.0792 - acc: 0.65 - ETA: 47s - loss: 1.0792 - acc: 0.65 - ETA: 46s - loss: 1.0783 - acc: 0.65 - ETA: 45s - loss: 1.0789 - acc: 0.65 - ETA: 44s - loss: 1.0796 - acc: 0.65 - ETA: 42s - loss: 1.0798 - acc: 0.65 - ETA: 41s - loss: 1.0804 - acc: 0.65 - ETA: 40s - loss: 1.0796 - acc: 0.65 - ETA: 38s - loss: 1.0787 - acc: 0.65 - ETA: 37s - loss: 1.0783 - acc: 0.66 - ETA: 36s - loss: 1.0780 - acc: 0.66 - ETA: 35s - loss: 1.0777 - acc: 0.66 - ETA: 33s - loss: 1.0776 - acc: 0.66 - ETA: 32s - loss: 1.0780 - acc: 0.66 - ETA: 31s - loss: 1.0787 - acc: 0.66 - ETA: 29s - loss: 1.0781 - acc: 0.66 - ETA: 28s - loss: 1.0775 - acc: 0.66 - ETA: 27s - loss: 1.0777 - acc: 0.66 - ETA: 26s - loss: 1.0773 - acc: 0.66 - ETA: 24s - loss: 1.0779 - acc: 0.66 - ETA: 23s - loss: 1.0786 - acc: 0.65 - ETA: 22s - loss: 1.0798 - acc: 0.65 - ETA: 20s - loss: 1.0793 - acc: 0.65 - ETA: 19s - loss: 1.0795 - acc: 0.65 - ETA: 18s - loss: 1.0798 - acc: 0.65 - ETA: 17s - loss: 1.0802 - acc: 0.65 - ETA: 15s - loss: 1.0806 - acc: 0.65 - ETA: 14s - loss: 1.0808 - acc: 0.65 - ETA: 13s - loss: 1.0802 - acc: 0.65 - ETA: 11s - loss: 1.0805 - acc: 0.65 - ETA: 10s - loss: 1.0812 - acc: 0.65 - ETA: 9s - loss: 1.0805 - acc: 0.6590 - ETA: 8s - loss: 1.0802 - acc: 0.659 - ETA: 6s - loss: 1.0796 - acc: 0.659 - ETA: 5s - loss: 1.0801 - acc: 0.659 - ETA: 4s - loss: 1.0806 - acc: 0.659 - ETA: 2s - loss: 1.0805 - acc: 0.659 - ETA: 1s - loss: 1.0799 - acc: 0.659 - ETA: 0s - loss: 1.0795 - acc: 0.659 - 252s 10ms/step - loss: 1.0795 - acc: 0.6594 - val_loss: 1.0817 - val_acc: 0.6605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29c17d85908>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_part, y_train_part,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3, #epochs\n",
    "          callbacks=[earlyStopping],\n",
    "          validation_data=(x_test_part, y_test_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_scores = model.predict(x_test_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       777\n",
      "           1       0.00      0.00      0.00       490\n",
      "           2       0.00      0.00      0.00       906\n",
      "           3       0.00      0.00      0.00      1561\n",
      "           4       0.66      0.98      0.79      7266\n",
      "\n",
      "   micro avg       0.66      0.65      0.65     11000\n",
      "   macro avg       0.13      0.20      0.16     11000\n",
      "weighted avg       0.44      0.65      0.52     11000\n",
      " samples avg       0.65      0.65      0.65     11000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_scores[y_predicted_scores>=0.5] = 1\n",
    "y_predicted_scores[y_predicted_scores<0.5] = 0\n",
    "\n",
    "print('Classification report\\n')\n",
    "print(classification_report(y_test_part, y_predicted_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить сharacter based модель (вместо слов мы подаём предложение посимвольно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = seed, \n",
    "                                                    test_size=0.3, shuffle=True,\n",
    "                                                    stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 400\n",
    "batch_size = 64\n",
    "embedding_dims = 64\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(\n",
    "    char_level=True,\n",
    "    #filters=None,\n",
    "    lower=True,\n",
    "    num_words=max_features\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = sequence.pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_y_train)\n",
    "y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538475, 400)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538475, 5)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_part,y_train_part = next_batch(100000, x_train, y_train)\n",
    "x_test_part,y_test_part = next_batch(33000, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 400)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_part.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "- Time Steps. One time step is one point of observation in the sample.\n",
    "- Features. One feature is one observation at a time step.\n",
    "\n",
    "so, we have x_train_part.shape[0] samples, 1 time step and maxlen = x_train_part.shape[1] features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_part = np.reshape(x_train_part, (x_train_part.shape[0], 1,  x_train_part.shape[1]))\n",
    "x_test_part = np.reshape(x_test_part, ( x_test_part.shape[0], 1,  x_test_part.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1, 400)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 33000 samples\n",
      "Epoch 1/4\n",
      " 46080/100000 [============>.................] - ETA: 2:03:36 - loss: 1.8717 - acc: 0.20 - ETA: 31:16 - loss: 1.8974 - acc: 0.2109 - ETA: 18:01 - loss: 1.8694 - acc: 0.24 - ETA: 12:43 - loss: 1.8526 - acc: 0.25 - ETA: 9:10 - loss: 1.8510 - acc: 0.2433 - ETA: 7:37 - loss: 1.8474 - acc: 0.242 - ETA: 6:32 - loss: 1.8379 - acc: 0.239 - ETA: 5:44 - loss: 1.8340 - acc: 0.237 - ETA: 4:55 - loss: 1.8136 - acc: 0.249 - ETA: 4:28 - loss: 1.8015 - acc: 0.253 - ETA: 3:59 - loss: 1.7810 - acc: 0.259 - ETA: 3:41 - loss: 1.7698 - acc: 0.263 - ETA: 3:26 - loss: 1.7670 - acc: 0.261 - ETA: 3:09 - loss: 1.7524 - acc: 0.266 - ETA: 2:55 - loss: 1.7445 - acc: 0.270 - ETA: 2:43 - loss: 1.7244 - acc: 0.282 - ETA: 2:32 - loss: 1.7111 - acc: 0.290 - ETA: 2:23 - loss: 1.6929 - acc: 0.299 - ETA: 2:15 - loss: 1.6800 - acc: 0.307 - ETA: 2:10 - loss: 1.6683 - acc: 0.314 - ETA: 2:04 - loss: 1.6569 - acc: 0.320 - ETA: 1:58 - loss: 1.6424 - acc: 0.328 - ETA: 1:54 - loss: 1.6360 - acc: 0.333 - ETA: 1:51 - loss: 1.6258 - acc: 0.339 - ETA: 1:46 - loss: 1.6120 - acc: 0.349 - ETA: 1:42 - loss: 1.5983 - acc: 0.357 - ETA: 1:39 - loss: 1.5831 - acc: 0.367 - ETA: 1:36 - loss: 1.5705 - acc: 0.374 - ETA: 1:34 - loss: 1.5629 - acc: 0.380 - ETA: 1:31 - loss: 1.5495 - acc: 0.388 - ETA: 1:28 - loss: 1.5393 - acc: 0.394 - ETA: 1:25 - loss: 1.5339 - acc: 0.399 - ETA: 1:24 - loss: 1.5257 - acc: 0.404 - ETA: 1:21 - loss: 1.5184 - acc: 0.409 - ETA: 1:20 - loss: 1.5088 - acc: 0.415 - ETA: 1:18 - loss: 1.4997 - acc: 0.421 - ETA: 1:17 - loss: 1.4944 - acc: 0.425 - ETA: 1:15 - loss: 1.4867 - acc: 0.431 - ETA: 1:14 - loss: 1.4822 - acc: 0.434 - ETA: 1:13 - loss: 1.4746 - acc: 0.438 - ETA: 1:11 - loss: 1.4659 - acc: 0.443 - ETA: 1:09 - loss: 1.4572 - acc: 0.449 - ETA: 1:08 - loss: 1.4523 - acc: 0.453 - ETA: 1:07 - loss: 1.4474 - acc: 0.456 - ETA: 1:06 - loss: 1.4419 - acc: 0.459 - ETA: 1:05 - loss: 1.4354 - acc: 0.464 - ETA: 1:04 - loss: 1.4304 - acc: 0.467 - ETA: 1:03 - loss: 1.4242 - acc: 0.470 - ETA: 1:02 - loss: 1.4179 - acc: 0.475 - ETA: 1:01 - loss: 1.4112 - acc: 0.479 - ETA: 1:00 - loss: 1.4056 - acc: 0.483 - ETA: 59s - loss: 1.4030 - acc: 0.485 - ETA: 59s - loss: 1.3955 - acc: 0.49 - ETA: 58s - loss: 1.3888 - acc: 0.49 - ETA: 57s - loss: 1.3828 - acc: 0.49 - ETA: 56s - loss: 1.3778 - acc: 0.50 - ETA: 56s - loss: 1.3742 - acc: 0.50 - ETA: 55s - loss: 1.3712 - acc: 0.50 - ETA: 54s - loss: 1.3680 - acc: 0.50 - ETA: 54s - loss: 1.3647 - acc: 0.50 - ETA: 53s - loss: 1.3562 - acc: 0.51 - ETA: 52s - loss: 1.3535 - acc: 0.51 - ETA: 52s - loss: 1.3527 - acc: 0.51 - ETA: 51s - loss: 1.3498 - acc: 0.51 - ETA: 51s - loss: 1.3463 - acc: 0.52 - ETA: 50s - loss: 1.3427 - acc: 0.52 - ETA: 50s - loss: 1.3394 - acc: 0.52 - ETA: 49s - loss: 1.3366 - acc: 0.52 - ETA: 49s - loss: 1.3323 - acc: 0.52 - ETA: 48s - loss: 1.3303 - acc: 0.53 - ETA: 48s - loss: 1.3294 - acc: 0.53 - ETA: 47s - loss: 1.3258 - acc: 0.53 - ETA: 46s - loss: 1.3243 - acc: 0.53 - ETA: 46s - loss: 1.3205 - acc: 0.53 - ETA: 45s - loss: 1.3192 - acc: 0.53 - ETA: 45s - loss: 1.3172 - acc: 0.53 - ETA: 45s - loss: 1.3143 - acc: 0.54 - ETA: 44s - loss: 1.3112 - acc: 0.54 - ETA: 44s - loss: 1.3090 - acc: 0.54 - ETA: 43s - loss: 1.3072 - acc: 0.54 - ETA: 43s - loss: 1.3051 - acc: 0.54 - ETA: 43s - loss: 1.3025 - acc: 0.54 - ETA: 42s - loss: 1.3018 - acc: 0.54 - ETA: 42s - loss: 1.3004 - acc: 0.55 - ETA: 41s - loss: 1.2987 - acc: 0.55 - ETA: 41s - loss: 1.2957 - acc: 0.55 - ETA: 40s - loss: 1.2935 - acc: 0.55 - ETA: 40s - loss: 1.2910 - acc: 0.55 - ETA: 40s - loss: 1.2899 - acc: 0.55 - ETA: 39s - loss: 1.2887 - acc: 0.55 - ETA: 39s - loss: 1.2860 - acc: 0.55 - ETA: 39s - loss: 1.2848 - acc: 0.55 - ETA: 39s - loss: 1.2835 - acc: 0.56 - ETA: 38s - loss: 1.2819 - acc: 0.56 - ETA: 38s - loss: 1.2800 - acc: 0.56 - ETA: 38s - loss: 1.2781 - acc: 0.56 - ETA: 38s - loss: 1.2771 - acc: 0.56 - ETA: 37s - loss: 1.2757 - acc: 0.56 - ETA: 37s - loss: 1.2752 - acc: 0.56 - ETA: 37s - loss: 1.2732 - acc: 0.56 - ETA: 37s - loss: 1.2721 - acc: 0.56 - ETA: 36s - loss: 1.2703 - acc: 0.56 - ETA: 36s - loss: 1.2690 - acc: 0.56 - ETA: 36s - loss: 1.2672 - acc: 0.57 - ETA: 36s - loss: 1.2668 - acc: 0.57 - ETA: 35s - loss: 1.2666 - acc: 0.57 - ETA: 35s - loss: 1.2648 - acc: 0.57 - ETA: 35s - loss: 1.2634 - acc: 0.57 - ETA: 35s - loss: 1.2609 - acc: 0.57 - ETA: 34s - loss: 1.2601 - acc: 0.57 - ETA: 34s - loss: 1.2586 - acc: 0.57 - ETA: 34s - loss: 1.2577 - acc: 0.57 - ETA: 34s - loss: 1.2554 - acc: 0.57 - ETA: 33s - loss: 1.2543 - acc: 0.57 - ETA: 33s - loss: 1.2543 - acc: 0.57 - ETA: 33s - loss: 1.2535 - acc: 0.57 - ETA: 33s - loss: 1.2523 - acc: 0.57 - ETA: 32s - loss: 1.2490 - acc: 0.58 - ETA: 32s - loss: 1.2472 - acc: 0.58 - ETA: 32s - loss: 1.2458 - acc: 0.58 - ETA: 32s - loss: 1.2460 - acc: 0.58 - ETA: 32s - loss: 1.2455 - acc: 0.58 - ETA: 32s - loss: 1.2439 - acc: 0.58 - ETA: 32s - loss: 1.2424 - acc: 0.58 - ETA: 31s - loss: 1.2411 - acc: 0.58 - ETA: 31s - loss: 1.2405 - acc: 0.58 - ETA: 31s - loss: 1.2399 - acc: 0.58 - ETA: 31s - loss: 1.2387 - acc: 0.58 - ETA: 31s - loss: 1.2370 - acc: 0.58 - ETA: 30s - loss: 1.2369 - acc: 0.58 - ETA: 30s - loss: 1.2357 - acc: 0.58 - ETA: 30s - loss: 1.2355 - acc: 0.58 - ETA: 30s - loss: 1.2348 - acc: 0.58 - ETA: 30s - loss: 1.2334 - acc: 0.58 - ETA: 29s - loss: 1.2322 - acc: 0.58 - ETA: 29s - loss: 1.2309 - acc: 0.58 - ETA: 29s - loss: 1.2297 - acc: 0.59 - ETA: 29s - loss: 1.2289 - acc: 0.59 - ETA: 29s - loss: 1.2285 - acc: 0.59 - ETA: 29s - loss: 1.2281 - acc: 0.59 - ETA: 29s - loss: 1.2270 - acc: 0.59 - ETA: 28s - loss: 1.2272 - acc: 0.59 - ETA: 28s - loss: 1.2261 - acc: 0.59 - ETA: 28s - loss: 1.2249 - acc: 0.59 - ETA: 28s - loss: 1.2257 - acc: 0.59 - ETA: 28s - loss: 1.2249 - acc: 0.59 - ETA: 28s - loss: 1.2237 - acc: 0.59 - ETA: 27s - loss: 1.2227 - acc: 0.59 - ETA: 27s - loss: 1.2229 - acc: 0.59 - ETA: 27s - loss: 1.2220 - acc: 0.59 - ETA: 27s - loss: 1.2205 - acc: 0.59 - ETA: 27s - loss: 1.2198 - acc: 0.59 - ETA: 27s - loss: 1.2184 - acc: 0.59 - ETA: 27s - loss: 1.2177 - acc: 0.59 - ETA: 26s - loss: 1.2171 - acc: 0.59 - ETA: 26s - loss: 1.2162 - acc: 0.59 - ETA: 26s - loss: 1.2161 - acc: 0.59 - ETA: 26s - loss: 1.2151 - acc: 0.59 - ETA: 26s - loss: 1.2147 - acc: 0.59 - ETA: 26s - loss: 1.2142 - acc: 0.59 - ETA: 26s - loss: 1.2136 - acc: 0.59 - ETA: 25s - loss: 1.2132 - acc: 0.60 - ETA: 25s - loss: 1.2122 - acc: 0.60 - ETA: 25s - loss: 1.2123 - acc: 0.60 - ETA: 25s - loss: 1.2114 - acc: 0.60 - ETA: 25s - loss: 1.2094 - acc: 0.60 - ETA: 25s - loss: 1.2085 - acc: 0.60 - ETA: 25s - loss: 1.2079 - acc: 0.60 - ETA: 24s - loss: 1.2066 - acc: 0.60 - ETA: 24s - loss: 1.2058 - acc: 0.60 - ETA: 24s - loss: 1.2057 - acc: 0.60 - ETA: 24s - loss: 1.2057 - acc: 0.60 - ETA: 24s - loss: 1.2057 - acc: 0.60 - ETA: 24s - loss: 1.2061 - acc: 0.60 - ETA: 24s - loss: 1.2058 - acc: 0.60 - ETA: 24s - loss: 1.2050 - acc: 0.60 - ETA: 23s - loss: 1.2044 - acc: 0.60 - ETA: 23s - loss: 1.2035 - acc: 0.60 - ETA: 23s - loss: 1.2028 - acc: 0.60 - ETA: 23s - loss: 1.2017 - acc: 0.60 - ETA: 23s - loss: 1.2011 - acc: 0.60 - ETA: 23s - loss: 1.2009 - acc: 0.60 - ETA: 23s - loss: 1.2009 - acc: 0.60 - ETA: 23s - loss: 1.2001 - acc: 0.60 - ETA: 22s - loss: 1.1999 - acc: 0.60 - ETA: 22s - loss: 1.1997 - acc: 0.60 - ETA: 22s - loss: 1.1993 - acc: 0.60 - ETA: 22s - loss: 1.1986 - acc: 0.60 - ETA: 22s - loss: 1.1984 - acc: 0.60 - ETA: 22s - loss: 1.1978 - acc: 0.60 - ETA: 22s - loss: 1.1974 - acc: 0.60 - ETA: 21s - loss: 1.1969 - acc: 0.60 - ETA: 21s - loss: 1.1966 - acc: 0.60 - ETA: 21s - loss: 1.1957 - acc: 0.60 - ETA: 21s - loss: 1.1949 - acc: 0.61 - ETA: 21s - loss: 1.1942 - acc: 0.61 - ETA: 21s - loss: 1.1937 - acc: 0.61 - ETA: 21s - loss: 1.1938 - acc: 0.61 - ETA: 21s - loss: 1.1936 - acc: 0.61 - ETA: 20s - loss: 1.1928 - acc: 0.61 - ETA: 20s - loss: 1.1919 - acc: 0.61 - ETA: 20s - loss: 1.1912 - acc: 0.61 - ETA: 20s - loss: 1.1901 - acc: 0.61 - ETA: 20s - loss: 1.1891 - acc: 0.61 - ETA: 20s - loss: 1.1891 - acc: 0.61 - ETA: 20s - loss: 1.1887 - acc: 0.61 - ETA: 20s - loss: 1.1882 - acc: 0.61 - ETA: 20s - loss: 1.1877 - acc: 0.61 - ETA: 19s - loss: 1.1873 - acc: 0.61 - ETA: 19s - loss: 1.1868 - acc: 0.61 92992/100000 [==========================>...] - ETA: 19s - loss: 1.1860 - acc: 0.61 - ETA: 19s - loss: 1.1858 - acc: 0.61 - ETA: 19s - loss: 1.1856 - acc: 0.61 - ETA: 19s - loss: 1.1855 - acc: 0.61 - ETA: 19s - loss: 1.1845 - acc: 0.61 - ETA: 19s - loss: 1.1841 - acc: 0.61 - ETA: 18s - loss: 1.1831 - acc: 0.61 - ETA: 18s - loss: 1.1826 - acc: 0.61 - ETA: 18s - loss: 1.1827 - acc: 0.61 - ETA: 18s - loss: 1.1828 - acc: 0.61 - ETA: 18s - loss: 1.1825 - acc: 0.61 - ETA: 18s - loss: 1.1825 - acc: 0.61 - ETA: 18s - loss: 1.1825 - acc: 0.61 - ETA: 18s - loss: 1.1825 - acc: 0.61 - ETA: 18s - loss: 1.1819 - acc: 0.61 - ETA: 17s - loss: 1.1814 - acc: 0.61 - ETA: 17s - loss: 1.1806 - acc: 0.61 - ETA: 17s - loss: 1.1800 - acc: 0.61 - ETA: 17s - loss: 1.1795 - acc: 0.61 - ETA: 17s - loss: 1.1789 - acc: 0.61 - ETA: 17s - loss: 1.1782 - acc: 0.61 - ETA: 17s - loss: 1.1778 - acc: 0.61 - ETA: 17s - loss: 1.1771 - acc: 0.61 - ETA: 17s - loss: 1.1768 - acc: 0.61 - ETA: 16s - loss: 1.1766 - acc: 0.61 - ETA: 16s - loss: 1.1765 - acc: 0.61 - ETA: 16s - loss: 1.1762 - acc: 0.61 - ETA: 16s - loss: 1.1755 - acc: 0.62 - ETA: 16s - loss: 1.1755 - acc: 0.62 - ETA: 16s - loss: 1.1748 - acc: 0.62 - ETA: 16s - loss: 1.1744 - acc: 0.62 - ETA: 16s - loss: 1.1742 - acc: 0.62 - ETA: 16s - loss: 1.1737 - acc: 0.62 - ETA: 16s - loss: 1.1737 - acc: 0.62 - ETA: 16s - loss: 1.1740 - acc: 0.62 - ETA: 16s - loss: 1.1737 - acc: 0.62 - ETA: 15s - loss: 1.1736 - acc: 0.62 - ETA: 15s - loss: 1.1732 - acc: 0.62 - ETA: 15s - loss: 1.1723 - acc: 0.62 - ETA: 15s - loss: 1.1717 - acc: 0.62 - ETA: 15s - loss: 1.1714 - acc: 0.62 - ETA: 15s - loss: 1.1712 - acc: 0.62 - ETA: 15s - loss: 1.1714 - acc: 0.62 - ETA: 15s - loss: 1.1710 - acc: 0.62 - ETA: 15s - loss: 1.1703 - acc: 0.62 - ETA: 15s - loss: 1.1702 - acc: 0.62 - ETA: 15s - loss: 1.1700 - acc: 0.62 - ETA: 14s - loss: 1.1695 - acc: 0.62 - ETA: 14s - loss: 1.1692 - acc: 0.62 - ETA: 14s - loss: 1.1689 - acc: 0.62 - ETA: 14s - loss: 1.1686 - acc: 0.62 - ETA: 14s - loss: 1.1684 - acc: 0.62 - ETA: 14s - loss: 1.1678 - acc: 0.62 - ETA: 14s - loss: 1.1668 - acc: 0.62 - ETA: 14s - loss: 1.1667 - acc: 0.62 - ETA: 14s - loss: 1.1664 - acc: 0.62 - ETA: 14s - loss: 1.1663 - acc: 0.62 - ETA: 14s - loss: 1.1658 - acc: 0.62 - ETA: 13s - loss: 1.1655 - acc: 0.62 - ETA: 13s - loss: 1.1654 - acc: 0.62 - ETA: 13s - loss: 1.1657 - acc: 0.62 - ETA: 13s - loss: 1.1651 - acc: 0.62 - ETA: 13s - loss: 1.1646 - acc: 0.62 - ETA: 13s - loss: 1.1641 - acc: 0.62 - ETA: 13s - loss: 1.1639 - acc: 0.62 - ETA: 13s - loss: 1.1639 - acc: 0.62 - ETA: 13s - loss: 1.1638 - acc: 0.62 - ETA: 13s - loss: 1.1634 - acc: 0.62 - ETA: 13s - loss: 1.1635 - acc: 0.62 - ETA: 12s - loss: 1.1632 - acc: 0.62 - ETA: 12s - loss: 1.1632 - acc: 0.62 - ETA: 12s - loss: 1.1628 - acc: 0.62 - ETA: 12s - loss: 1.1626 - acc: 0.62 - ETA: 12s - loss: 1.1624 - acc: 0.62 - ETA: 12s - loss: 1.1617 - acc: 0.62 - ETA: 12s - loss: 1.1611 - acc: 0.62 - ETA: 12s - loss: 1.1609 - acc: 0.62 - ETA: 12s - loss: 1.1607 - acc: 0.62 - ETA: 12s - loss: 1.1608 - acc: 0.62 - ETA: 12s - loss: 1.1607 - acc: 0.62 - ETA: 12s - loss: 1.1603 - acc: 0.62 - ETA: 11s - loss: 1.1600 - acc: 0.62 - ETA: 11s - loss: 1.1597 - acc: 0.62 - ETA: 11s - loss: 1.1593 - acc: 0.62 - ETA: 11s - loss: 1.1591 - acc: 0.62 - ETA: 11s - loss: 1.1592 - acc: 0.62 - ETA: 11s - loss: 1.1589 - acc: 0.62 - ETA: 11s - loss: 1.1587 - acc: 0.62 - ETA: 11s - loss: 1.1581 - acc: 0.62 - ETA: 11s - loss: 1.1580 - acc: 0.62 - ETA: 11s - loss: 1.1577 - acc: 0.62 - ETA: 11s - loss: 1.1575 - acc: 0.62 - ETA: 11s - loss: 1.1569 - acc: 0.62 - ETA: 11s - loss: 1.1563 - acc: 0.62 - ETA: 10s - loss: 1.1560 - acc: 0.62 - ETA: 10s - loss: 1.1556 - acc: 0.62 - ETA: 10s - loss: 1.1554 - acc: 0.62 - ETA: 10s - loss: 1.1551 - acc: 0.62 - ETA: 10s - loss: 1.1551 - acc: 0.62 - ETA: 10s - loss: 1.1547 - acc: 0.62 - ETA: 10s - loss: 1.1544 - acc: 0.63 - ETA: 10s - loss: 1.1541 - acc: 0.63 - ETA: 10s - loss: 1.1543 - acc: 0.63 - ETA: 10s - loss: 1.1542 - acc: 0.63 - ETA: 10s - loss: 1.1541 - acc: 0.63 - ETA: 10s - loss: 1.1538 - acc: 0.63 - ETA: 10s - loss: 1.1535 - acc: 0.63 - ETA: 10s - loss: 1.1530 - acc: 0.63 - ETA: 9s - loss: 1.1533 - acc: 0.6306 - ETA: 9s - loss: 1.1529 - acc: 0.630 - ETA: 9s - loss: 1.1528 - acc: 0.630 - ETA: 9s - loss: 1.1526 - acc: 0.630 - ETA: 9s - loss: 1.1525 - acc: 0.631 - ETA: 9s - loss: 1.1520 - acc: 0.631 - ETA: 9s - loss: 1.1520 - acc: 0.631 - ETA: 9s - loss: 1.1520 - acc: 0.631 - ETA: 9s - loss: 1.1518 - acc: 0.631 - ETA: 9s - loss: 1.1511 - acc: 0.631 - ETA: 9s - loss: 1.1509 - acc: 0.631 - ETA: 9s - loss: 1.1507 - acc: 0.631 - ETA: 9s - loss: 1.1503 - acc: 0.632 - ETA: 8s - loss: 1.1504 - acc: 0.632 - ETA: 8s - loss: 1.1505 - acc: 0.632 - ETA: 8s - loss: 1.1504 - acc: 0.632 - ETA: 8s - loss: 1.1502 - acc: 0.632 - ETA: 8s - loss: 1.1501 - acc: 0.632 - ETA: 8s - loss: 1.1498 - acc: 0.632 - ETA: 8s - loss: 1.1497 - acc: 0.632 - ETA: 8s - loss: 1.1494 - acc: 0.632 - ETA: 8s - loss: 1.1495 - acc: 0.632 - ETA: 8s - loss: 1.1493 - acc: 0.632 - ETA: 8s - loss: 1.1491 - acc: 0.632 - ETA: 8s - loss: 1.1492 - acc: 0.632 - ETA: 8s - loss: 1.1490 - acc: 0.632 - ETA: 8s - loss: 1.1489 - acc: 0.632 - ETA: 7s - loss: 1.1485 - acc: 0.632 - ETA: 7s - loss: 1.1479 - acc: 0.633 - ETA: 7s - loss: 1.1478 - acc: 0.633 - ETA: 7s - loss: 1.1477 - acc: 0.633 - ETA: 7s - loss: 1.1474 - acc: 0.633 - ETA: 7s - loss: 1.1473 - acc: 0.633 - ETA: 7s - loss: 1.1473 - acc: 0.633 - ETA: 7s - loss: 1.1468 - acc: 0.633 - ETA: 7s - loss: 1.1463 - acc: 0.634 - ETA: 7s - loss: 1.1456 - acc: 0.634 - ETA: 7s - loss: 1.1452 - acc: 0.634 - ETA: 7s - loss: 1.1450 - acc: 0.634 - ETA: 7s - loss: 1.1447 - acc: 0.634 - ETA: 6s - loss: 1.1445 - acc: 0.634 - ETA: 6s - loss: 1.1444 - acc: 0.634 - ETA: 6s - loss: 1.1442 - acc: 0.634 - ETA: 6s - loss: 1.1444 - acc: 0.634 - ETA: 6s - loss: 1.1440 - acc: 0.635 - ETA: 6s - loss: 1.1440 - acc: 0.635 - ETA: 6s - loss: 1.1440 - acc: 0.635 - ETA: 6s - loss: 1.1437 - acc: 0.635 - ETA: 6s - loss: 1.1435 - acc: 0.635 - ETA: 6s - loss: 1.1435 - acc: 0.635 - ETA: 6s - loss: 1.1433 - acc: 0.635 - ETA: 6s - loss: 1.1430 - acc: 0.635 - ETA: 6s - loss: 1.1427 - acc: 0.635 - ETA: 5s - loss: 1.1425 - acc: 0.635 - ETA: 5s - loss: 1.1421 - acc: 0.635 - ETA: 5s - loss: 1.1421 - acc: 0.635 - ETA: 5s - loss: 1.1420 - acc: 0.635 - ETA: 5s - loss: 1.1419 - acc: 0.635 - ETA: 5s - loss: 1.1416 - acc: 0.635 - ETA: 5s - loss: 1.1418 - acc: 0.635 - ETA: 5s - loss: 1.1416 - acc: 0.635 - ETA: 5s - loss: 1.1417 - acc: 0.635 - ETA: 5s - loss: 1.1412 - acc: 0.636 - ETA: 5s - loss: 1.1410 - acc: 0.636 - ETA: 5s - loss: 1.1409 - acc: 0.636 - ETA: 5s - loss: 1.1409 - acc: 0.636 - ETA: 4s - loss: 1.1407 - acc: 0.636 - ETA: 4s - loss: 1.1404 - acc: 0.636 - ETA: 4s - loss: 1.1403 - acc: 0.636 - ETA: 4s - loss: 1.1402 - acc: 0.636 - ETA: 4s - loss: 1.1398 - acc: 0.636 - ETA: 4s - loss: 1.1397 - acc: 0.636 - ETA: 4s - loss: 1.1395 - acc: 0.637 - ETA: 4s - loss: 1.1397 - acc: 0.636 - ETA: 4s - loss: 1.1397 - acc: 0.636 - ETA: 4s - loss: 1.1393 - acc: 0.637 - ETA: 4s - loss: 1.1392 - acc: 0.637 - ETA: 4s - loss: 1.1390 - acc: 0.637 - ETA: 4s - loss: 1.1388 - acc: 0.637 - ETA: 4s - loss: 1.1387 - acc: 0.637 - ETA: 3s - loss: 1.1387 - acc: 0.637 - ETA: 3s - loss: 1.1383 - acc: 0.637 - ETA: 3s - loss: 1.1381 - acc: 0.637 - ETA: 3s - loss: 1.1379 - acc: 0.637 - ETA: 3s - loss: 1.1378 - acc: 0.637 - ETA: 3s - loss: 1.1379 - acc: 0.637 - ETA: 3s - loss: 1.1375 - acc: 0.637 - ETA: 3s - loss: 1.1372 - acc: 0.638 - ETA: 3s - loss: 1.1371 - acc: 0.638 - ETA: 3s - loss: 1.1369 - acc: 0.638 - ETA: 3s - loss: 1.1368 - acc: 0.638 - ETA: 3s - loss: 1.1366 - acc: 0.638 - ETA: 3s - loss: 1.1368 - acc: 0.638 - ETA: 3s - loss: 1.1365 - acc: 0.638 - ETA: 2s - loss: 1.1362 - acc: 0.638 - ETA: 2s - loss: 1.1360 - acc: 0.638 - ETA: 2s - loss: 1.1358 - acc: 0.638 - ETA: 2s - loss: 1.1356 - acc: 0.638 - ETA: 2s - loss: 1.1354 - acc: 0.638 - ETA: 2s - loss: 1.1350 - acc: 0.639 - ETA: 2s - loss: 1.1352 - acc: 0.639 - ETA: 2s - loss: 1.1349 - acc: 0.639 - ETA: 2s - loss: 1.1350 - acc: 0.639 - ETA: 2s - loss: 1.1348 - acc: 0.639 - ETA: 2s - loss: 1.1350 - acc: 0.639 - ETA: 2s - loss: 1.1350 - acc: 0.639 - ETA: 2s - loss: 1.1346 - acc: 0.6393100000/100000 [==============================] - ETA: 2s - loss: 1.1344 - acc: 0.639 - ETA: 2s - loss: 1.1345 - acc: 0.639 - ETA: 1s - loss: 1.1342 - acc: 0.639 - ETA: 1s - loss: 1.1343 - acc: 0.639 - ETA: 1s - loss: 1.1340 - acc: 0.639 - ETA: 1s - loss: 1.1337 - acc: 0.639 - ETA: 1s - loss: 1.1337 - acc: 0.639 - ETA: 1s - loss: 1.1336 - acc: 0.639 - ETA: 1s - loss: 1.1336 - acc: 0.639 - ETA: 1s - loss: 1.1336 - acc: 0.639 - ETA: 1s - loss: 1.1335 - acc: 0.639 - ETA: 1s - loss: 1.1336 - acc: 0.639 - ETA: 1s - loss: 1.1336 - acc: 0.639 - ETA: 1s - loss: 1.1334 - acc: 0.639 - ETA: 1s - loss: 1.1332 - acc: 0.640 - ETA: 1s - loss: 1.1331 - acc: 0.640 - ETA: 1s - loss: 1.1331 - acc: 0.640 - ETA: 0s - loss: 1.1328 - acc: 0.640 - ETA: 0s - loss: 1.1325 - acc: 0.640 - ETA: 0s - loss: 1.1326 - acc: 0.640 - ETA: 0s - loss: 1.1325 - acc: 0.640 - ETA: 0s - loss: 1.1324 - acc: 0.640 - ETA: 0s - loss: 1.1321 - acc: 0.640 - ETA: 0s - loss: 1.1321 - acc: 0.640 - ETA: 0s - loss: 1.1320 - acc: 0.640 - ETA: 0s - loss: 1.1318 - acc: 0.640 - ETA: 0s - loss: 1.1316 - acc: 0.640 - ETA: 0s - loss: 1.1315 - acc: 0.640 - ETA: 0s - loss: 1.1313 - acc: 0.640 - ETA: 0s - loss: 1.1314 - acc: 0.640 - ETA: 0s - loss: 1.1314 - acc: 0.640 - ETA: 0s - loss: 1.1311 - acc: 0.641 - 34s 338us/step - loss: 1.1309 - acc: 0.6411 - val_loss: 1.0608 - val_acc: 0.6692\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47552/100000 [=============>................] - ETA: 35s - loss: 1.2555 - acc: 0.60 - ETA: 28s - loss: 1.1638 - acc: 0.63 - ETA: 28s - loss: 1.1223 - acc: 0.64 - ETA: 28s - loss: 1.1111 - acc: 0.64 - ETA: 28s - loss: 1.0889 - acc: 0.65 - ETA: 28s - loss: 1.0926 - acc: 0.65 - ETA: 28s - loss: 1.1028 - acc: 0.65 - ETA: 27s - loss: 1.0959 - acc: 0.65 - ETA: 28s - loss: 1.0919 - acc: 0.65 - ETA: 28s - loss: 1.0815 - acc: 0.66 - ETA: 28s - loss: 1.0899 - acc: 0.65 - ETA: 28s - loss: 1.0931 - acc: 0.65 - ETA: 27s - loss: 1.0972 - acc: 0.65 - ETA: 27s - loss: 1.0971 - acc: 0.65 - ETA: 26s - loss: 1.0971 - acc: 0.65 - ETA: 27s - loss: 1.0937 - acc: 0.65 - ETA: 26s - loss: 1.0931 - acc: 0.65 - ETA: 26s - loss: 1.0938 - acc: 0.65 - ETA: 26s - loss: 1.0957 - acc: 0.65 - ETA: 26s - loss: 1.0941 - acc: 0.65 - ETA: 26s - loss: 1.0971 - acc: 0.65 - ETA: 26s - loss: 1.0951 - acc: 0.65 - ETA: 26s - loss: 1.0951 - acc: 0.65 - ETA: 26s - loss: 1.0932 - acc: 0.65 - ETA: 26s - loss: 1.0901 - acc: 0.65 - ETA: 26s - loss: 1.0908 - acc: 0.65 - ETA: 26s - loss: 1.0899 - acc: 0.65 - ETA: 26s - loss: 1.0893 - acc: 0.65 - ETA: 26s - loss: 1.0874 - acc: 0.65 - ETA: 26s - loss: 1.0840 - acc: 0.65 - ETA: 26s - loss: 1.0846 - acc: 0.65 - ETA: 26s - loss: 1.0876 - acc: 0.65 - ETA: 26s - loss: 1.0882 - acc: 0.65 - ETA: 26s - loss: 1.0906 - acc: 0.65 - ETA: 26s - loss: 1.0895 - acc: 0.65 - ETA: 25s - loss: 1.0903 - acc: 0.65 - ETA: 25s - loss: 1.0897 - acc: 0.65 - ETA: 25s - loss: 1.0896 - acc: 0.65 - ETA: 25s - loss: 1.0881 - acc: 0.65 - ETA: 25s - loss: 1.0907 - acc: 0.65 - ETA: 25s - loss: 1.0928 - acc: 0.65 - ETA: 25s - loss: 1.0922 - acc: 0.65 - ETA: 25s - loss: 1.0881 - acc: 0.65 - ETA: 24s - loss: 1.0904 - acc: 0.65 - ETA: 24s - loss: 1.0893 - acc: 0.65 - ETA: 25s - loss: 1.0873 - acc: 0.65 - ETA: 24s - loss: 1.0881 - acc: 0.65 - ETA: 24s - loss: 1.0879 - acc: 0.65 - ETA: 24s - loss: 1.0886 - acc: 0.65 - ETA: 24s - loss: 1.0880 - acc: 0.65 - ETA: 24s - loss: 1.0882 - acc: 0.65 - ETA: 24s - loss: 1.0883 - acc: 0.65 - ETA: 24s - loss: 1.0875 - acc: 0.65 - ETA: 24s - loss: 1.0890 - acc: 0.65 - ETA: 24s - loss: 1.0866 - acc: 0.65 - ETA: 24s - loss: 1.0876 - acc: 0.65 - ETA: 23s - loss: 1.0870 - acc: 0.65 - ETA: 23s - loss: 1.0875 - acc: 0.65 - ETA: 23s - loss: 1.0885 - acc: 0.65 - ETA: 23s - loss: 1.0889 - acc: 0.65 - ETA: 23s - loss: 1.0912 - acc: 0.65 - ETA: 23s - loss: 1.0910 - acc: 0.65 - ETA: 23s - loss: 1.0910 - acc: 0.65 - ETA: 23s - loss: 1.0905 - acc: 0.65 - ETA: 23s - loss: 1.0894 - acc: 0.65 - ETA: 23s - loss: 1.0890 - acc: 0.65 - ETA: 23s - loss: 1.0874 - acc: 0.65 - ETA: 23s - loss: 1.0858 - acc: 0.65 - ETA: 23s - loss: 1.0870 - acc: 0.65 - ETA: 23s - loss: 1.0861 - acc: 0.65 - ETA: 23s - loss: 1.0855 - acc: 0.65 - ETA: 23s - loss: 1.0864 - acc: 0.65 - ETA: 23s - loss: 1.0875 - acc: 0.65 - ETA: 23s - loss: 1.0870 - acc: 0.65 - ETA: 22s - loss: 1.0868 - acc: 0.65 - ETA: 22s - loss: 1.0860 - acc: 0.65 - ETA: 22s - loss: 1.0852 - acc: 0.65 - ETA: 22s - loss: 1.0854 - acc: 0.65 - ETA: 22s - loss: 1.0852 - acc: 0.65 - ETA: 22s - loss: 1.0865 - acc: 0.65 - ETA: 22s - loss: 1.0877 - acc: 0.65 - ETA: 22s - loss: 1.0876 - acc: 0.65 - ETA: 22s - loss: 1.0884 - acc: 0.65 - ETA: 22s - loss: 1.0867 - acc: 0.65 - ETA: 22s - loss: 1.0856 - acc: 0.65 - ETA: 22s - loss: 1.0847 - acc: 0.65 - ETA: 22s - loss: 1.0853 - acc: 0.65 - ETA: 22s - loss: 1.0858 - acc: 0.65 - ETA: 22s - loss: 1.0870 - acc: 0.65 - ETA: 22s - loss: 1.0861 - acc: 0.65 - ETA: 22s - loss: 1.0858 - acc: 0.65 - ETA: 22s - loss: 1.0865 - acc: 0.65 - ETA: 22s - loss: 1.0858 - acc: 0.65 - ETA: 22s - loss: 1.0857 - acc: 0.65 - ETA: 22s - loss: 1.0856 - acc: 0.65 - ETA: 22s - loss: 1.0849 - acc: 0.65 - ETA: 22s - loss: 1.0841 - acc: 0.66 - ETA: 22s - loss: 1.0844 - acc: 0.66 - ETA: 22s - loss: 1.0839 - acc: 0.66 - ETA: 21s - loss: 1.0840 - acc: 0.66 - ETA: 21s - loss: 1.0835 - acc: 0.66 - ETA: 21s - loss: 1.0828 - acc: 0.66 - ETA: 21s - loss: 1.0821 - acc: 0.66 - ETA: 21s - loss: 1.0818 - acc: 0.66 - ETA: 21s - loss: 1.0810 - acc: 0.66 - ETA: 21s - loss: 1.0810 - acc: 0.66 - ETA: 21s - loss: 1.0818 - acc: 0.66 - ETA: 21s - loss: 1.0813 - acc: 0.66 - ETA: 21s - loss: 1.0801 - acc: 0.66 - ETA: 21s - loss: 1.0790 - acc: 0.66 - ETA: 21s - loss: 1.0783 - acc: 0.66 - ETA: 21s - loss: 1.0780 - acc: 0.66 - ETA: 21s - loss: 1.0790 - acc: 0.66 - ETA: 21s - loss: 1.0779 - acc: 0.66 - ETA: 20s - loss: 1.0774 - acc: 0.66 - ETA: 20s - loss: 1.0772 - acc: 0.66 - ETA: 20s - loss: 1.0764 - acc: 0.66 - ETA: 20s - loss: 1.0768 - acc: 0.66 - ETA: 20s - loss: 1.0774 - acc: 0.66 - ETA: 20s - loss: 1.0776 - acc: 0.66 - ETA: 20s - loss: 1.0766 - acc: 0.66 - ETA: 20s - loss: 1.0764 - acc: 0.66 - ETA: 20s - loss: 1.0770 - acc: 0.66 - ETA: 20s - loss: 1.0781 - acc: 0.66 - ETA: 19s - loss: 1.0778 - acc: 0.66 - ETA: 19s - loss: 1.0768 - acc: 0.66 - ETA: 19s - loss: 1.0765 - acc: 0.66 - ETA: 19s - loss: 1.0756 - acc: 0.66 - ETA: 19s - loss: 1.0747 - acc: 0.66 - ETA: 19s - loss: 1.0743 - acc: 0.66 - ETA: 19s - loss: 1.0735 - acc: 0.66 - ETA: 19s - loss: 1.0732 - acc: 0.66 - ETA: 19s - loss: 1.0725 - acc: 0.66 - ETA: 19s - loss: 1.0719 - acc: 0.66 - ETA: 19s - loss: 1.0721 - acc: 0.66 - ETA: 19s - loss: 1.0722 - acc: 0.66 - ETA: 19s - loss: 1.0722 - acc: 0.66 - ETA: 19s - loss: 1.0722 - acc: 0.66 - ETA: 19s - loss: 1.0719 - acc: 0.66 - ETA: 19s - loss: 1.0725 - acc: 0.66 - ETA: 18s - loss: 1.0728 - acc: 0.66 - ETA: 18s - loss: 1.0733 - acc: 0.66 - ETA: 18s - loss: 1.0730 - acc: 0.66 - ETA: 18s - loss: 1.0730 - acc: 0.66 - ETA: 18s - loss: 1.0725 - acc: 0.66 - ETA: 18s - loss: 1.0727 - acc: 0.66 - ETA: 18s - loss: 1.0728 - acc: 0.66 - ETA: 18s - loss: 1.0721 - acc: 0.66 - ETA: 18s - loss: 1.0719 - acc: 0.66 - ETA: 18s - loss: 1.0713 - acc: 0.66 - ETA: 18s - loss: 1.0718 - acc: 0.66 - ETA: 18s - loss: 1.0717 - acc: 0.66 - ETA: 18s - loss: 1.0725 - acc: 0.66 - ETA: 18s - loss: 1.0721 - acc: 0.66 - ETA: 18s - loss: 1.0717 - acc: 0.66 - ETA: 18s - loss: 1.0722 - acc: 0.66 - ETA: 17s - loss: 1.0729 - acc: 0.66 - ETA: 17s - loss: 1.0727 - acc: 0.66 - ETA: 17s - loss: 1.0726 - acc: 0.66 - ETA: 17s - loss: 1.0722 - acc: 0.66 - ETA: 17s - loss: 1.0715 - acc: 0.66 - ETA: 17s - loss: 1.0711 - acc: 0.66 - ETA: 17s - loss: 1.0711 - acc: 0.66 - ETA: 17s - loss: 1.0713 - acc: 0.66 - ETA: 17s - loss: 1.0713 - acc: 0.66 - ETA: 17s - loss: 1.0716 - acc: 0.66 - ETA: 17s - loss: 1.0715 - acc: 0.66 - ETA: 16s - loss: 1.0719 - acc: 0.66 - ETA: 16s - loss: 1.0721 - acc: 0.66 - ETA: 16s - loss: 1.0728 - acc: 0.66 - ETA: 16s - loss: 1.0723 - acc: 0.66 - ETA: 16s - loss: 1.0721 - acc: 0.66 - ETA: 16s - loss: 1.0721 - acc: 0.66 - ETA: 16s - loss: 1.0724 - acc: 0.66 - ETA: 16s - loss: 1.0726 - acc: 0.66 - ETA: 16s - loss: 1.0727 - acc: 0.66 - ETA: 16s - loss: 1.0731 - acc: 0.66 - ETA: 16s - loss: 1.0735 - acc: 0.66 - ETA: 16s - loss: 1.0734 - acc: 0.66 - ETA: 16s - loss: 1.0737 - acc: 0.66 - ETA: 16s - loss: 1.0735 - acc: 0.66 - ETA: 16s - loss: 1.0726 - acc: 0.66 - ETA: 15s - loss: 1.0723 - acc: 0.66 - ETA: 15s - loss: 1.0722 - acc: 0.66 - ETA: 15s - loss: 1.0721 - acc: 0.66 - ETA: 15s - loss: 1.0722 - acc: 0.66 - ETA: 15s - loss: 1.0719 - acc: 0.66 - ETA: 15s - loss: 1.0719 - acc: 0.66 - ETA: 15s - loss: 1.0721 - acc: 0.66 - ETA: 15s - loss: 1.0727 - acc: 0.66 - ETA: 15s - loss: 1.0734 - acc: 0.66 - ETA: 15s - loss: 1.0738 - acc: 0.66 - ETA: 15s - loss: 1.0737 - acc: 0.66 - ETA: 15s - loss: 1.0739 - acc: 0.66 - ETA: 15s - loss: 1.0733 - acc: 0.66 - ETA: 15s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0728 - acc: 0.66 - ETA: 14s - loss: 1.0727 - acc: 0.66 - ETA: 14s - loss: 1.0726 - acc: 0.66 - ETA: 14s - loss: 1.0730 - acc: 0.66 - ETA: 14s - loss: 1.0732 - acc: 0.66 - ETA: 14s - loss: 1.0734 - acc: 0.66 - ETA: 14s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0743 - acc: 0.66 - ETA: 14s - loss: 1.0744 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0744 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0738 - acc: 0.66 - ETA: 13s - loss: 1.0737 - acc: 0.66 - ETA: 13s - loss: 1.0733 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.6648 89216/100000 [=========================>....] - ETA: 13s - loss: 1.0728 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0732 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0728 - acc: 0.66 - ETA: 13s - loss: 1.0731 - acc: 0.66 - ETA: 13s - loss: 1.0732 - acc: 0.66 - ETA: 13s - loss: 1.0734 - acc: 0.66 - ETA: 13s - loss: 1.0734 - acc: 0.66 - ETA: 13s - loss: 1.0741 - acc: 0.66 - ETA: 13s - loss: 1.0741 - acc: 0.66 - ETA: 13s - loss: 1.0743 - acc: 0.66 - ETA: 12s - loss: 1.0745 - acc: 0.66 - ETA: 12s - loss: 1.0752 - acc: 0.66 - ETA: 12s - loss: 1.0751 - acc: 0.66 - ETA: 12s - loss: 1.0751 - acc: 0.66 - ETA: 12s - loss: 1.0751 - acc: 0.66 - ETA: 12s - loss: 1.0749 - acc: 0.66 - ETA: 12s - loss: 1.0748 - acc: 0.66 - ETA: 12s - loss: 1.0752 - acc: 0.66 - ETA: 12s - loss: 1.0754 - acc: 0.66 - ETA: 12s - loss: 1.0751 - acc: 0.66 - ETA: 12s - loss: 1.0752 - acc: 0.66 - ETA: 12s - loss: 1.0755 - acc: 0.66 - ETA: 12s - loss: 1.0751 - acc: 0.66 - ETA: 12s - loss: 1.0755 - acc: 0.66 - ETA: 12s - loss: 1.0756 - acc: 0.66 - ETA: 12s - loss: 1.0761 - acc: 0.66 - ETA: 12s - loss: 1.0761 - acc: 0.66 - ETA: 12s - loss: 1.0761 - acc: 0.66 - ETA: 12s - loss: 1.0763 - acc: 0.66 - ETA: 12s - loss: 1.0764 - acc: 0.66 - ETA: 11s - loss: 1.0765 - acc: 0.66 - ETA: 11s - loss: 1.0766 - acc: 0.66 - ETA: 11s - loss: 1.0768 - acc: 0.66 - ETA: 11s - loss: 1.0771 - acc: 0.66 - ETA: 11s - loss: 1.0767 - acc: 0.66 - ETA: 11s - loss: 1.0765 - acc: 0.66 - ETA: 11s - loss: 1.0763 - acc: 0.66 - ETA: 11s - loss: 1.0763 - acc: 0.66 - ETA: 11s - loss: 1.0764 - acc: 0.66 - ETA: 11s - loss: 1.0764 - acc: 0.66 - ETA: 11s - loss: 1.0763 - acc: 0.66 - ETA: 11s - loss: 1.0761 - acc: 0.66 - ETA: 11s - loss: 1.0759 - acc: 0.66 - ETA: 11s - loss: 1.0760 - acc: 0.66 - ETA: 11s - loss: 1.0758 - acc: 0.66 - ETA: 11s - loss: 1.0761 - acc: 0.66 - ETA: 11s - loss: 1.0759 - acc: 0.66 - ETA: 10s - loss: 1.0757 - acc: 0.66 - ETA: 10s - loss: 1.0755 - acc: 0.66 - ETA: 10s - loss: 1.0754 - acc: 0.66 - ETA: 10s - loss: 1.0756 - acc: 0.66 - ETA: 10s - loss: 1.0755 - acc: 0.66 - ETA: 10s - loss: 1.0754 - acc: 0.66 - ETA: 10s - loss: 1.0754 - acc: 0.66 - ETA: 10s - loss: 1.0753 - acc: 0.66 - ETA: 10s - loss: 1.0752 - acc: 0.66 - ETA: 10s - loss: 1.0756 - acc: 0.66 - ETA: 10s - loss: 1.0753 - acc: 0.66 - ETA: 10s - loss: 1.0756 - acc: 0.66 - ETA: 10s - loss: 1.0756 - acc: 0.66 - ETA: 10s - loss: 1.0756 - acc: 0.66 - ETA: 10s - loss: 1.0754 - acc: 0.66 - ETA: 10s - loss: 1.0753 - acc: 0.66 - ETA: 10s - loss: 1.0755 - acc: 0.66 - ETA: 10s - loss: 1.0755 - acc: 0.66 - ETA: 10s - loss: 1.0755 - acc: 0.66 - ETA: 10s - loss: 1.0754 - acc: 0.66 - ETA: 9s - loss: 1.0751 - acc: 0.6637 - ETA: 9s - loss: 1.0751 - acc: 0.663 - ETA: 9s - loss: 1.0750 - acc: 0.663 - ETA: 9s - loss: 1.0754 - acc: 0.663 - ETA: 9s - loss: 1.0755 - acc: 0.663 - ETA: 9s - loss: 1.0753 - acc: 0.663 - ETA: 9s - loss: 1.0753 - acc: 0.663 - ETA: 9s - loss: 1.0753 - acc: 0.663 - ETA: 9s - loss: 1.0754 - acc: 0.663 - ETA: 9s - loss: 1.0751 - acc: 0.663 - ETA: 9s - loss: 1.0752 - acc: 0.663 - ETA: 9s - loss: 1.0754 - acc: 0.663 - ETA: 9s - loss: 1.0755 - acc: 0.663 - ETA: 9s - loss: 1.0754 - acc: 0.663 - ETA: 9s - loss: 1.0757 - acc: 0.663 - ETA: 9s - loss: 1.0760 - acc: 0.663 - ETA: 9s - loss: 1.0762 - acc: 0.663 - ETA: 9s - loss: 1.0763 - acc: 0.663 - ETA: 9s - loss: 1.0766 - acc: 0.663 - ETA: 9s - loss: 1.0766 - acc: 0.663 - ETA: 9s - loss: 1.0765 - acc: 0.663 - ETA: 9s - loss: 1.0766 - acc: 0.663 - ETA: 9s - loss: 1.0768 - acc: 0.663 - ETA: 9s - loss: 1.0768 - acc: 0.663 - ETA: 8s - loss: 1.0769 - acc: 0.663 - ETA: 8s - loss: 1.0768 - acc: 0.663 - ETA: 8s - loss: 1.0768 - acc: 0.663 - ETA: 8s - loss: 1.0765 - acc: 0.663 - ETA: 8s - loss: 1.0763 - acc: 0.663 - ETA: 8s - loss: 1.0762 - acc: 0.663 - ETA: 8s - loss: 1.0759 - acc: 0.663 - ETA: 8s - loss: 1.0758 - acc: 0.663 - ETA: 8s - loss: 1.0758 - acc: 0.663 - ETA: 8s - loss: 1.0759 - acc: 0.663 - ETA: 8s - loss: 1.0761 - acc: 0.663 - ETA: 8s - loss: 1.0765 - acc: 0.663 - ETA: 8s - loss: 1.0767 - acc: 0.663 - ETA: 8s - loss: 1.0765 - acc: 0.663 - ETA: 8s - loss: 1.0765 - acc: 0.663 - ETA: 8s - loss: 1.0768 - acc: 0.662 - ETA: 8s - loss: 1.0770 - acc: 0.662 - ETA: 8s - loss: 1.0769 - acc: 0.662 - ETA: 8s - loss: 1.0772 - acc: 0.662 - ETA: 8s - loss: 1.0773 - acc: 0.662 - ETA: 8s - loss: 1.0770 - acc: 0.662 - ETA: 7s - loss: 1.0771 - acc: 0.662 - ETA: 7s - loss: 1.0769 - acc: 0.662 - ETA: 7s - loss: 1.0770 - acc: 0.662 - ETA: 7s - loss: 1.0772 - acc: 0.662 - ETA: 7s - loss: 1.0769 - acc: 0.662 - ETA: 7s - loss: 1.0767 - acc: 0.662 - ETA: 7s - loss: 1.0766 - acc: 0.662 - ETA: 7s - loss: 1.0768 - acc: 0.662 - ETA: 7s - loss: 1.0766 - acc: 0.662 - ETA: 7s - loss: 1.0763 - acc: 0.663 - ETA: 7s - loss: 1.0762 - acc: 0.663 - ETA: 7s - loss: 1.0765 - acc: 0.662 - ETA: 7s - loss: 1.0763 - acc: 0.662 - ETA: 7s - loss: 1.0762 - acc: 0.663 - ETA: 7s - loss: 1.0765 - acc: 0.662 - ETA: 7s - loss: 1.0766 - acc: 0.662 - ETA: 7s - loss: 1.0765 - acc: 0.662 - ETA: 7s - loss: 1.0765 - acc: 0.662 - ETA: 7s - loss: 1.0765 - acc: 0.662 - ETA: 6s - loss: 1.0763 - acc: 0.662 - ETA: 6s - loss: 1.0762 - acc: 0.663 - ETA: 6s - loss: 1.0763 - acc: 0.663 - ETA: 6s - loss: 1.0763 - acc: 0.663 - ETA: 6s - loss: 1.0763 - acc: 0.663 - ETA: 6s - loss: 1.0764 - acc: 0.662 - ETA: 6s - loss: 1.0767 - acc: 0.662 - ETA: 6s - loss: 1.0765 - acc: 0.662 - ETA: 6s - loss: 1.0764 - acc: 0.662 - ETA: 6s - loss: 1.0765 - acc: 0.662 - ETA: 6s - loss: 1.0768 - acc: 0.662 - ETA: 6s - loss: 1.0768 - acc: 0.662 - ETA: 6s - loss: 1.0768 - acc: 0.662 - ETA: 6s - loss: 1.0766 - acc: 0.662 - ETA: 6s - loss: 1.0766 - acc: 0.662 - ETA: 6s - loss: 1.0766 - acc: 0.662 - ETA: 6s - loss: 1.0767 - acc: 0.662 - ETA: 6s - loss: 1.0764 - acc: 0.662 - ETA: 6s - loss: 1.0765 - acc: 0.662 - ETA: 5s - loss: 1.0764 - acc: 0.662 - ETA: 5s - loss: 1.0764 - acc: 0.662 - ETA: 5s - loss: 1.0765 - acc: 0.662 - ETA: 5s - loss: 1.0765 - acc: 0.662 - ETA: 5s - loss: 1.0763 - acc: 0.662 - ETA: 5s - loss: 1.0765 - acc: 0.662 - ETA: 5s - loss: 1.0764 - acc: 0.662 - ETA: 5s - loss: 1.0766 - acc: 0.662 - ETA: 5s - loss: 1.0764 - acc: 0.662 - ETA: 5s - loss: 1.0763 - acc: 0.662 - ETA: 5s - loss: 1.0766 - acc: 0.662 - ETA: 5s - loss: 1.0762 - acc: 0.662 - ETA: 5s - loss: 1.0762 - acc: 0.662 - ETA: 5s - loss: 1.0763 - acc: 0.662 - ETA: 5s - loss: 1.0761 - acc: 0.662 - ETA: 5s - loss: 1.0760 - acc: 0.663 - ETA: 5s - loss: 1.0760 - acc: 0.663 - ETA: 5s - loss: 1.0762 - acc: 0.662 - ETA: 4s - loss: 1.0761 - acc: 0.662 - ETA: 4s - loss: 1.0758 - acc: 0.663 - ETA: 4s - loss: 1.0758 - acc: 0.663 - ETA: 4s - loss: 1.0757 - acc: 0.663 - ETA: 4s - loss: 1.0760 - acc: 0.663 - ETA: 4s - loss: 1.0759 - acc: 0.663 - ETA: 4s - loss: 1.0760 - acc: 0.663 - ETA: 4s - loss: 1.0762 - acc: 0.662 - ETA: 4s - loss: 1.0765 - acc: 0.662 - ETA: 4s - loss: 1.0764 - acc: 0.662 - ETA: 4s - loss: 1.0767 - acc: 0.662 - ETA: 4s - loss: 1.0766 - acc: 0.662 - ETA: 4s - loss: 1.0767 - acc: 0.662 - ETA: 4s - loss: 1.0766 - acc: 0.662 - ETA: 4s - loss: 1.0765 - acc: 0.662 - ETA: 4s - loss: 1.0768 - acc: 0.662 - ETA: 4s - loss: 1.0768 - acc: 0.662 - ETA: 4s - loss: 1.0768 - acc: 0.662 - ETA: 4s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0768 - acc: 0.662 - ETA: 3s - loss: 1.0768 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0771 - acc: 0.662 - ETA: 3s - loss: 1.0771 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0767 - acc: 0.662 - ETA: 3s - loss: 1.0769 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0771 - acc: 0.662 - ETA: 3s - loss: 1.0772 - acc: 0.662 - ETA: 3s - loss: 1.0772 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0773 - acc: 0.662 - ETA: 3s - loss: 1.0772 - acc: 0.662 - ETA: 3s - loss: 1.0771 - acc: 0.662 - ETA: 3s - loss: 1.0771 - acc: 0.662 - ETA: 3s - loss: 1.0770 - acc: 0.662 - ETA: 3s - loss: 1.0768 - acc: 0.662 - ETA: 3s - loss: 1.0768 - acc: 0.662 - ETA: 3s - loss: 1.0765 - acc: 0.663 - ETA: 3s - loss: 1.0764 - acc: 0.663 - ETA: 3s - loss: 1.0764 - acc: 0.663 - ETA: 3s - loss: 1.0762 - acc: 0.6631"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 3s - loss: 1.0764 - acc: 0.663 - ETA: 2s - loss: 1.0766 - acc: 0.662 - ETA: 2s - loss: 1.0764 - acc: 0.663 - ETA: 2s - loss: 1.0764 - acc: 0.663 - ETA: 2s - loss: 1.0765 - acc: 0.663 - ETA: 2s - loss: 1.0766 - acc: 0.662 - ETA: 2s - loss: 1.0766 - acc: 0.662 - ETA: 2s - loss: 1.0766 - acc: 0.662 - ETA: 2s - loss: 1.0764 - acc: 0.663 - ETA: 2s - loss: 1.0763 - acc: 0.663 - ETA: 2s - loss: 1.0765 - acc: 0.662 - ETA: 2s - loss: 1.0764 - acc: 0.662 - ETA: 2s - loss: 1.0764 - acc: 0.662 - ETA: 2s - loss: 1.0763 - acc: 0.663 - ETA: 2s - loss: 1.0761 - acc: 0.663 - ETA: 2s - loss: 1.0765 - acc: 0.662 - ETA: 2s - loss: 1.0766 - acc: 0.662 - ETA: 2s - loss: 1.0768 - acc: 0.662 - ETA: 2s - loss: 1.0770 - acc: 0.662 - ETA: 1s - loss: 1.0772 - acc: 0.662 - ETA: 1s - loss: 1.0769 - acc: 0.662 - ETA: 1s - loss: 1.0770 - acc: 0.662 - ETA: 1s - loss: 1.0770 - acc: 0.662 - ETA: 1s - loss: 1.0768 - acc: 0.662 - ETA: 1s - loss: 1.0771 - acc: 0.662 - ETA: 1s - loss: 1.0772 - acc: 0.662 - ETA: 1s - loss: 1.0771 - acc: 0.662 - ETA: 1s - loss: 1.0769 - acc: 0.662 - ETA: 1s - loss: 1.0768 - acc: 0.662 - ETA: 1s - loss: 1.0769 - acc: 0.662 - ETA: 1s - loss: 1.0769 - acc: 0.662 - ETA: 1s - loss: 1.0768 - acc: 0.662 - ETA: 1s - loss: 1.0769 - acc: 0.662 - ETA: 1s - loss: 1.0768 - acc: 0.662 - ETA: 1s - loss: 1.0767 - acc: 0.662 - ETA: 1s - loss: 1.0764 - acc: 0.663 - ETA: 1s - loss: 1.0764 - acc: 0.663 - ETA: 1s - loss: 1.0764 - acc: 0.662 - ETA: 1s - loss: 1.0765 - acc: 0.662 - ETA: 0s - loss: 1.0765 - acc: 0.662 - ETA: 0s - loss: 1.0763 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0760 - acc: 0.663 - ETA: 0s - loss: 1.0760 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0760 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0760 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0761 - acc: 0.663 - ETA: 0s - loss: 1.0762 - acc: 0.663 - ETA: 0s - loss: 1.0763 - acc: 0.662 - ETA: 0s - loss: 1.0764 - acc: 0.662 - 32s 318us/step - loss: 1.0764 - acc: 0.6628 - val_loss: 1.0581 - val_acc: 0.6690\n",
      "Epoch 3/4\n",
      " 39680/100000 [==========>...................] - ETA: 1:03 - loss: 1.1196 - acc: 0.609 - ETA: 38s - loss: 1.0623 - acc: 0.660 - ETA: 34s - loss: 1.0504 - acc: 0.67 - ETA: 32s - loss: 1.0531 - acc: 0.67 - ETA: 31s - loss: 1.0609 - acc: 0.67 - ETA: 31s - loss: 1.0792 - acc: 0.66 - ETA: 30s - loss: 1.0799 - acc: 0.66 - ETA: 31s - loss: 1.0792 - acc: 0.66 - ETA: 30s - loss: 1.0832 - acc: 0.66 - ETA: 31s - loss: 1.0812 - acc: 0.66 - ETA: 31s - loss: 1.0700 - acc: 0.66 - ETA: 30s - loss: 1.0803 - acc: 0.66 - ETA: 31s - loss: 1.0784 - acc: 0.66 - ETA: 31s - loss: 1.0778 - acc: 0.66 - ETA: 30s - loss: 1.0717 - acc: 0.66 - ETA: 30s - loss: 1.0719 - acc: 0.66 - ETA: 30s - loss: 1.0689 - acc: 0.66 - ETA: 30s - loss: 1.0702 - acc: 0.66 - ETA: 31s - loss: 1.0689 - acc: 0.66 - ETA: 31s - loss: 1.0711 - acc: 0.66 - ETA: 31s - loss: 1.0667 - acc: 0.66 - ETA: 31s - loss: 1.0706 - acc: 0.66 - ETA: 30s - loss: 1.0698 - acc: 0.66 - ETA: 31s - loss: 1.0718 - acc: 0.66 - ETA: 31s - loss: 1.0701 - acc: 0.66 - ETA: 30s - loss: 1.0721 - acc: 0.66 - ETA: 30s - loss: 1.0737 - acc: 0.66 - ETA: 30s - loss: 1.0710 - acc: 0.66 - ETA: 31s - loss: 1.0713 - acc: 0.66 - ETA: 31s - loss: 1.0743 - acc: 0.66 - ETA: 31s - loss: 1.0725 - acc: 0.66 - ETA: 30s - loss: 1.0698 - acc: 0.66 - ETA: 30s - loss: 1.0654 - acc: 0.66 - ETA: 30s - loss: 1.0668 - acc: 0.66 - ETA: 30s - loss: 1.0667 - acc: 0.66 - ETA: 30s - loss: 1.0670 - acc: 0.66 - ETA: 30s - loss: 1.0685 - acc: 0.66 - ETA: 31s - loss: 1.0718 - acc: 0.66 - ETA: 30s - loss: 1.0731 - acc: 0.66 - ETA: 31s - loss: 1.0752 - acc: 0.66 - ETA: 30s - loss: 1.0770 - acc: 0.66 - ETA: 30s - loss: 1.0794 - acc: 0.66 - ETA: 30s - loss: 1.0790 - acc: 0.66 - ETA: 30s - loss: 1.0772 - acc: 0.66 - ETA: 30s - loss: 1.0767 - acc: 0.66 - ETA: 30s - loss: 1.0750 - acc: 0.66 - ETA: 30s - loss: 1.0746 - acc: 0.66 - ETA: 30s - loss: 1.0737 - acc: 0.66 - ETA: 29s - loss: 1.0727 - acc: 0.66 - ETA: 29s - loss: 1.0751 - acc: 0.66 - ETA: 29s - loss: 1.0756 - acc: 0.66 - ETA: 29s - loss: 1.0749 - acc: 0.66 - ETA: 29s - loss: 1.0741 - acc: 0.66 - ETA: 29s - loss: 1.0734 - acc: 0.66 - ETA: 29s - loss: 1.0763 - acc: 0.66 - ETA: 28s - loss: 1.0764 - acc: 0.66 - ETA: 28s - loss: 1.0764 - acc: 0.66 - ETA: 28s - loss: 1.0746 - acc: 0.66 - ETA: 28s - loss: 1.0767 - acc: 0.66 - ETA: 28s - loss: 1.0790 - acc: 0.66 - ETA: 28s - loss: 1.0774 - acc: 0.66 - ETA: 28s - loss: 1.0777 - acc: 0.66 - ETA: 28s - loss: 1.0786 - acc: 0.66 - ETA: 28s - loss: 1.0795 - acc: 0.66 - ETA: 28s - loss: 1.0804 - acc: 0.66 - ETA: 28s - loss: 1.0805 - acc: 0.65 - ETA: 28s - loss: 1.0801 - acc: 0.66 - ETA: 28s - loss: 1.0781 - acc: 0.66 - ETA: 28s - loss: 1.0787 - acc: 0.66 - ETA: 28s - loss: 1.0795 - acc: 0.66 - ETA: 28s - loss: 1.0810 - acc: 0.66 - ETA: 28s - loss: 1.0805 - acc: 0.66 - ETA: 28s - loss: 1.0804 - acc: 0.66 - ETA: 28s - loss: 1.0796 - acc: 0.66 - ETA: 28s - loss: 1.0787 - acc: 0.66 - ETA: 28s - loss: 1.0802 - acc: 0.66 - ETA: 27s - loss: 1.0777 - acc: 0.66 - ETA: 27s - loss: 1.0761 - acc: 0.66 - ETA: 27s - loss: 1.0754 - acc: 0.66 - ETA: 27s - loss: 1.0745 - acc: 0.66 - ETA: 27s - loss: 1.0741 - acc: 0.66 - ETA: 27s - loss: 1.0737 - acc: 0.66 - ETA: 27s - loss: 1.0727 - acc: 0.66 - ETA: 27s - loss: 1.0735 - acc: 0.66 - ETA: 27s - loss: 1.0737 - acc: 0.66 - ETA: 27s - loss: 1.0727 - acc: 0.66 - ETA: 27s - loss: 1.0729 - acc: 0.66 - ETA: 27s - loss: 1.0734 - acc: 0.66 - ETA: 27s - loss: 1.0728 - acc: 0.66 - ETA: 27s - loss: 1.0719 - acc: 0.66 - ETA: 27s - loss: 1.0725 - acc: 0.66 - ETA: 27s - loss: 1.0736 - acc: 0.66 - ETA: 27s - loss: 1.0734 - acc: 0.66 - ETA: 26s - loss: 1.0738 - acc: 0.66 - ETA: 26s - loss: 1.0747 - acc: 0.66 - ETA: 26s - loss: 1.0743 - acc: 0.66 - ETA: 26s - loss: 1.0737 - acc: 0.66 - ETA: 26s - loss: 1.0720 - acc: 0.66 - ETA: 26s - loss: 1.0718 - acc: 0.66 - ETA: 26s - loss: 1.0729 - acc: 0.66 - ETA: 26s - loss: 1.0729 - acc: 0.66 - ETA: 26s - loss: 1.0723 - acc: 0.66 - ETA: 26s - loss: 1.0738 - acc: 0.66 - ETA: 26s - loss: 1.0754 - acc: 0.66 - ETA: 25s - loss: 1.0755 - acc: 0.66 - ETA: 25s - loss: 1.0747 - acc: 0.66 - ETA: 25s - loss: 1.0745 - acc: 0.66 - ETA: 25s - loss: 1.0746 - acc: 0.66 - ETA: 25s - loss: 1.0745 - acc: 0.66 - ETA: 25s - loss: 1.0737 - acc: 0.66 - ETA: 25s - loss: 1.0728 - acc: 0.66 - ETA: 25s - loss: 1.0729 - acc: 0.66 - ETA: 25s - loss: 1.0734 - acc: 0.66 - ETA: 25s - loss: 1.0730 - acc: 0.66 - ETA: 25s - loss: 1.0735 - acc: 0.66 - ETA: 25s - loss: 1.0740 - acc: 0.66 - ETA: 25s - loss: 1.0746 - acc: 0.66 - ETA: 25s - loss: 1.0737 - acc: 0.66 - ETA: 25s - loss: 1.0743 - acc: 0.66 - ETA: 25s - loss: 1.0743 - acc: 0.66 - ETA: 25s - loss: 1.0738 - acc: 0.66 - ETA: 25s - loss: 1.0739 - acc: 0.66 - ETA: 24s - loss: 1.0747 - acc: 0.66 - ETA: 24s - loss: 1.0758 - acc: 0.66 - ETA: 24s - loss: 1.0747 - acc: 0.66 - ETA: 24s - loss: 1.0753 - acc: 0.66 - ETA: 24s - loss: 1.0752 - acc: 0.66 - ETA: 24s - loss: 1.0749 - acc: 0.66 - ETA: 24s - loss: 1.0754 - acc: 0.66 - ETA: 24s - loss: 1.0757 - acc: 0.66 - ETA: 24s - loss: 1.0759 - acc: 0.66 - ETA: 24s - loss: 1.0759 - acc: 0.66 - ETA: 24s - loss: 1.0759 - acc: 0.66 - ETA: 24s - loss: 1.0753 - acc: 0.66 - ETA: 24s - loss: 1.0749 - acc: 0.66 - ETA: 24s - loss: 1.0750 - acc: 0.66 - ETA: 24s - loss: 1.0753 - acc: 0.66 - ETA: 24s - loss: 1.0756 - acc: 0.66 - ETA: 24s - loss: 1.0747 - acc: 0.66 - ETA: 24s - loss: 1.0756 - acc: 0.66 - ETA: 24s - loss: 1.0759 - acc: 0.66 - ETA: 23s - loss: 1.0764 - acc: 0.66 - ETA: 23s - loss: 1.0763 - acc: 0.66 - ETA: 23s - loss: 1.0762 - acc: 0.66 - ETA: 23s - loss: 1.0768 - acc: 0.66 - ETA: 23s - loss: 1.0763 - acc: 0.66 - ETA: 23s - loss: 1.0766 - acc: 0.66 - ETA: 23s - loss: 1.0774 - acc: 0.66 - ETA: 23s - loss: 1.0768 - acc: 0.66 - ETA: 23s - loss: 1.0765 - acc: 0.66 - ETA: 23s - loss: 1.0772 - acc: 0.66 - ETA: 23s - loss: 1.0761 - acc: 0.66 - ETA: 22s - loss: 1.0763 - acc: 0.66 - ETA: 22s - loss: 1.0764 - acc: 0.66 - ETA: 22s - loss: 1.0766 - acc: 0.66 - ETA: 22s - loss: 1.0758 - acc: 0.66 - ETA: 22s - loss: 1.0757 - acc: 0.66 - ETA: 22s - loss: 1.0759 - acc: 0.66 - ETA: 22s - loss: 1.0754 - acc: 0.66 - ETA: 22s - loss: 1.0758 - acc: 0.66 - ETA: 22s - loss: 1.0760 - acc: 0.66 - ETA: 22s - loss: 1.0761 - acc: 0.66 - ETA: 22s - loss: 1.0761 - acc: 0.66 - ETA: 22s - loss: 1.0757 - acc: 0.66 - ETA: 21s - loss: 1.0753 - acc: 0.66 - ETA: 21s - loss: 1.0754 - acc: 0.66 - ETA: 21s - loss: 1.0759 - acc: 0.66 - ETA: 21s - loss: 1.0756 - acc: 0.66 - ETA: 21s - loss: 1.0757 - acc: 0.66 - ETA: 21s - loss: 1.0762 - acc: 0.66 - ETA: 21s - loss: 1.0759 - acc: 0.66 - ETA: 21s - loss: 1.0757 - acc: 0.66 - ETA: 21s - loss: 1.0753 - acc: 0.66 - ETA: 21s - loss: 1.0752 - acc: 0.66 - ETA: 21s - loss: 1.0758 - acc: 0.66 - ETA: 21s - loss: 1.0757 - acc: 0.66 - ETA: 21s - loss: 1.0754 - acc: 0.66 - ETA: 21s - loss: 1.0752 - acc: 0.66 - ETA: 21s - loss: 1.0758 - acc: 0.66 - ETA: 21s - loss: 1.0761 - acc: 0.66 - ETA: 21s - loss: 1.0763 - acc: 0.66 - ETA: 21s - loss: 1.0763 - acc: 0.66 - ETA: 21s - loss: 1.0768 - acc: 0.66 - ETA: 21s - loss: 1.0768 - acc: 0.66 - ETA: 20s - loss: 1.0768 - acc: 0.66 - ETA: 20s - loss: 1.0759 - acc: 0.66 - ETA: 20s - loss: 1.0765 - acc: 0.66 - ETA: 20s - loss: 1.0758 - acc: 0.66 - ETA: 20s - loss: 1.0754 - acc: 0.66 - ETA: 20s - loss: 1.0752 - acc: 0.66 - ETA: 20s - loss: 1.0751 - acc: 0.66 - ETA: 20s - loss: 1.0748 - acc: 0.66 - ETA: 20s - loss: 1.0743 - acc: 0.66 - ETA: 20s - loss: 1.0743 - acc: 0.66 - ETA: 20s - loss: 1.0748 - acc: 0.66 - ETA: 20s - loss: 1.0747 - acc: 0.66 - ETA: 20s - loss: 1.0749 - acc: 0.66 - ETA: 20s - loss: 1.0745 - acc: 0.66 - ETA: 20s - loss: 1.0751 - acc: 0.66 - ETA: 20s - loss: 1.0750 - acc: 0.66 - ETA: 20s - loss: 1.0746 - acc: 0.66 - ETA: 20s - loss: 1.0748 - acc: 0.66 - ETA: 20s - loss: 1.0748 - acc: 0.66 - ETA: 20s - loss: 1.0742 - acc: 0.66 - ETA: 19s - loss: 1.0745 - acc: 0.66 - ETA: 19s - loss: 1.0743 - acc: 0.66 - ETA: 19s - loss: 1.0747 - acc: 0.66 - ETA: 19s - loss: 1.0746 - acc: 0.66 - ETA: 19s - loss: 1.0741 - acc: 0.66 - ETA: 19s - loss: 1.0739 - acc: 0.66 - ETA: 19s - loss: 1.0733 - acc: 0.66 - ETA: 19s - loss: 1.0736 - acc: 0.66 - ETA: 19s - loss: 1.0736 - acc: 0.66 - ETA: 19s - loss: 1.0740 - acc: 0.66 - ETA: 19s - loss: 1.0739 - acc: 0.6632 79360/100000 [======================>.......] - ETA: 19s - loss: 1.0737 - acc: 0.66 - ETA: 19s - loss: 1.0737 - acc: 0.66 - ETA: 19s - loss: 1.0741 - acc: 0.66 - ETA: 19s - loss: 1.0735 - acc: 0.66 - ETA: 19s - loss: 1.0735 - acc: 0.66 - ETA: 19s - loss: 1.0738 - acc: 0.66 - ETA: 19s - loss: 1.0736 - acc: 0.66 - ETA: 19s - loss: 1.0731 - acc: 0.66 - ETA: 19s - loss: 1.0739 - acc: 0.66 - ETA: 18s - loss: 1.0740 - acc: 0.66 - ETA: 18s - loss: 1.0737 - acc: 0.66 - ETA: 18s - loss: 1.0742 - acc: 0.66 - ETA: 18s - loss: 1.0743 - acc: 0.66 - ETA: 18s - loss: 1.0746 - acc: 0.66 - ETA: 18s - loss: 1.0748 - acc: 0.66 - ETA: 18s - loss: 1.0752 - acc: 0.66 - ETA: 18s - loss: 1.0746 - acc: 0.66 - ETA: 18s - loss: 1.0739 - acc: 0.66 - ETA: 18s - loss: 1.0740 - acc: 0.66 - ETA: 18s - loss: 1.0737 - acc: 0.66 - ETA: 18s - loss: 1.0731 - acc: 0.66 - ETA: 18s - loss: 1.0731 - acc: 0.66 - ETA: 18s - loss: 1.0729 - acc: 0.66 - ETA: 18s - loss: 1.0730 - acc: 0.66 - ETA: 18s - loss: 1.0733 - acc: 0.66 - ETA: 17s - loss: 1.0736 - acc: 0.66 - ETA: 17s - loss: 1.0736 - acc: 0.66 - ETA: 17s - loss: 1.0734 - acc: 0.66 - ETA: 17s - loss: 1.0735 - acc: 0.66 - ETA: 17s - loss: 1.0733 - acc: 0.66 - ETA: 17s - loss: 1.0727 - acc: 0.66 - ETA: 17s - loss: 1.0728 - acc: 0.66 - ETA: 17s - loss: 1.0726 - acc: 0.66 - ETA: 17s - loss: 1.0727 - acc: 0.66 - ETA: 17s - loss: 1.0725 - acc: 0.66 - ETA: 17s - loss: 1.0729 - acc: 0.66 - ETA: 17s - loss: 1.0725 - acc: 0.66 - ETA: 17s - loss: 1.0723 - acc: 0.66 - ETA: 17s - loss: 1.0721 - acc: 0.66 - ETA: 17s - loss: 1.0725 - acc: 0.66 - ETA: 17s - loss: 1.0726 - acc: 0.66 - ETA: 16s - loss: 1.0727 - acc: 0.66 - ETA: 16s - loss: 1.0729 - acc: 0.66 - ETA: 16s - loss: 1.0726 - acc: 0.66 - ETA: 16s - loss: 1.0727 - acc: 0.66 - ETA: 16s - loss: 1.0728 - acc: 0.66 - ETA: 16s - loss: 1.0729 - acc: 0.66 - ETA: 16s - loss: 1.0728 - acc: 0.66 - ETA: 16s - loss: 1.0727 - acc: 0.66 - ETA: 16s - loss: 1.0725 - acc: 0.66 - ETA: 16s - loss: 1.0723 - acc: 0.66 - ETA: 16s - loss: 1.0724 - acc: 0.66 - ETA: 16s - loss: 1.0725 - acc: 0.66 - ETA: 16s - loss: 1.0725 - acc: 0.66 - ETA: 16s - loss: 1.0731 - acc: 0.66 - ETA: 16s - loss: 1.0732 - acc: 0.66 - ETA: 16s - loss: 1.0732 - acc: 0.66 - ETA: 15s - loss: 1.0731 - acc: 0.66 - ETA: 15s - loss: 1.0730 - acc: 0.66 - ETA: 15s - loss: 1.0731 - acc: 0.66 - ETA: 15s - loss: 1.0730 - acc: 0.66 - ETA: 15s - loss: 1.0734 - acc: 0.66 - ETA: 15s - loss: 1.0734 - acc: 0.66 - ETA: 15s - loss: 1.0735 - acc: 0.66 - ETA: 15s - loss: 1.0734 - acc: 0.66 - ETA: 15s - loss: 1.0736 - acc: 0.66 - ETA: 15s - loss: 1.0739 - acc: 0.66 - ETA: 15s - loss: 1.0743 - acc: 0.66 - ETA: 15s - loss: 1.0747 - acc: 0.66 - ETA: 15s - loss: 1.0747 - acc: 0.66 - ETA: 15s - loss: 1.0747 - acc: 0.66 - ETA: 15s - loss: 1.0744 - acc: 0.66 - ETA: 15s - loss: 1.0744 - acc: 0.66 - ETA: 15s - loss: 1.0747 - acc: 0.66 - ETA: 15s - loss: 1.0748 - acc: 0.66 - ETA: 15s - loss: 1.0749 - acc: 0.66 - ETA: 14s - loss: 1.0746 - acc: 0.66 - ETA: 14s - loss: 1.0750 - acc: 0.66 - ETA: 14s - loss: 1.0749 - acc: 0.66 - ETA: 14s - loss: 1.0746 - acc: 0.66 - ETA: 14s - loss: 1.0746 - acc: 0.66 - ETA: 14s - loss: 1.0746 - acc: 0.66 - ETA: 14s - loss: 1.0744 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0741 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0742 - acc: 0.66 - ETA: 14s - loss: 1.0746 - acc: 0.66 - ETA: 14s - loss: 1.0745 - acc: 0.66 - ETA: 13s - loss: 1.0744 - acc: 0.66 - ETA: 13s - loss: 1.0744 - acc: 0.66 - ETA: 13s - loss: 1.0748 - acc: 0.66 - ETA: 13s - loss: 1.0748 - acc: 0.66 - ETA: 13s - loss: 1.0748 - acc: 0.66 - ETA: 13s - loss: 1.0747 - acc: 0.66 - ETA: 13s - loss: 1.0747 - acc: 0.66 - ETA: 13s - loss: 1.0749 - acc: 0.66 - ETA: 13s - loss: 1.0748 - acc: 0.66 - ETA: 13s - loss: 1.0749 - acc: 0.66 - ETA: 13s - loss: 1.0746 - acc: 0.66 - ETA: 13s - loss: 1.0748 - acc: 0.66 - ETA: 13s - loss: 1.0743 - acc: 0.66 - ETA: 13s - loss: 1.0743 - acc: 0.66 - ETA: 13s - loss: 1.0744 - acc: 0.66 - ETA: 13s - loss: 1.0743 - acc: 0.66 - ETA: 13s - loss: 1.0737 - acc: 0.66 - ETA: 12s - loss: 1.0736 - acc: 0.66 - ETA: 12s - loss: 1.0733 - acc: 0.66 - ETA: 12s - loss: 1.0733 - acc: 0.66 - ETA: 12s - loss: 1.0732 - acc: 0.66 - ETA: 12s - loss: 1.0729 - acc: 0.66 - ETA: 12s - loss: 1.0728 - acc: 0.66 - ETA: 12s - loss: 1.0733 - acc: 0.66 - ETA: 12s - loss: 1.0731 - acc: 0.66 - ETA: 12s - loss: 1.0727 - acc: 0.66 - ETA: 12s - loss: 1.0725 - acc: 0.66 - ETA: 12s - loss: 1.0725 - acc: 0.66 - ETA: 12s - loss: 1.0723 - acc: 0.66 - ETA: 12s - loss: 1.0722 - acc: 0.66 - ETA: 12s - loss: 1.0719 - acc: 0.66 - ETA: 12s - loss: 1.0722 - acc: 0.66 - ETA: 12s - loss: 1.0722 - acc: 0.66 - ETA: 11s - loss: 1.0723 - acc: 0.66 - ETA: 11s - loss: 1.0727 - acc: 0.66 - ETA: 11s - loss: 1.0728 - acc: 0.66 - ETA: 11s - loss: 1.0728 - acc: 0.66 - ETA: 11s - loss: 1.0726 - acc: 0.66 - ETA: 11s - loss: 1.0727 - acc: 0.66 - ETA: 11s - loss: 1.0725 - acc: 0.66 - ETA: 11s - loss: 1.0723 - acc: 0.66 - ETA: 11s - loss: 1.0726 - acc: 0.66 - ETA: 11s - loss: 1.0723 - acc: 0.66 - ETA: 11s - loss: 1.0722 - acc: 0.66 - ETA: 11s - loss: 1.0720 - acc: 0.66 - ETA: 11s - loss: 1.0720 - acc: 0.66 - ETA: 11s - loss: 1.0720 - acc: 0.66 - ETA: 11s - loss: 1.0716 - acc: 0.66 - ETA: 11s - loss: 1.0716 - acc: 0.66 - ETA: 10s - loss: 1.0716 - acc: 0.66 - ETA: 10s - loss: 1.0713 - acc: 0.66 - ETA: 10s - loss: 1.0717 - acc: 0.66 - ETA: 10s - loss: 1.0717 - acc: 0.66 - ETA: 10s - loss: 1.0718 - acc: 0.66 - ETA: 10s - loss: 1.0719 - acc: 0.66 - ETA: 10s - loss: 1.0718 - acc: 0.66 - ETA: 10s - loss: 1.0718 - acc: 0.66 - ETA: 10s - loss: 1.0719 - acc: 0.66 - ETA: 10s - loss: 1.0718 - acc: 0.66 - ETA: 10s - loss: 1.0718 - acc: 0.66 - ETA: 10s - loss: 1.0719 - acc: 0.66 - ETA: 10s - loss: 1.0720 - acc: 0.66 - ETA: 10s - loss: 1.0720 - acc: 0.66 - ETA: 10s - loss: 1.0721 - acc: 0.66 - ETA: 10s - loss: 1.0722 - acc: 0.66 - ETA: 9s - loss: 1.0720 - acc: 0.6643 - ETA: 9s - loss: 1.0720 - acc: 0.664 - ETA: 9s - loss: 1.0723 - acc: 0.664 - ETA: 9s - loss: 1.0728 - acc: 0.663 - ETA: 9s - loss: 1.0728 - acc: 0.664 - ETA: 9s - loss: 1.0729 - acc: 0.663 - ETA: 9s - loss: 1.0727 - acc: 0.664 - ETA: 9s - loss: 1.0725 - acc: 0.664 - ETA: 9s - loss: 1.0727 - acc: 0.664 - ETA: 9s - loss: 1.0726 - acc: 0.664 - ETA: 9s - loss: 1.0723 - acc: 0.664 - ETA: 9s - loss: 1.0724 - acc: 0.664 - ETA: 9s - loss: 1.0723 - acc: 0.664 - ETA: 9s - loss: 1.0723 - acc: 0.664 - ETA: 9s - loss: 1.0725 - acc: 0.664 - ETA: 9s - loss: 1.0723 - acc: 0.664 - ETA: 9s - loss: 1.0722 - acc: 0.664 - ETA: 8s - loss: 1.0724 - acc: 0.664 - ETA: 8s - loss: 1.0725 - acc: 0.664 - ETA: 8s - loss: 1.0725 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0721 - acc: 0.664 - ETA: 8s - loss: 1.0720 - acc: 0.664 - ETA: 8s - loss: 1.0719 - acc: 0.664 - ETA: 8s - loss: 1.0722 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0722 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0724 - acc: 0.664 - ETA: 8s - loss: 1.0726 - acc: 0.664 - ETA: 8s - loss: 1.0723 - acc: 0.664 - ETA: 8s - loss: 1.0722 - acc: 0.664 - ETA: 8s - loss: 1.0722 - acc: 0.664 - ETA: 7s - loss: 1.0721 - acc: 0.664 - ETA: 7s - loss: 1.0720 - acc: 0.664 - ETA: 7s - loss: 1.0723 - acc: 0.664 - ETA: 7s - loss: 1.0722 - acc: 0.664 - ETA: 7s - loss: 1.0721 - acc: 0.664 - ETA: 7s - loss: 1.0722 - acc: 0.664 - ETA: 7s - loss: 1.0723 - acc: 0.664 - ETA: 7s - loss: 1.0721 - acc: 0.664 - ETA: 7s - loss: 1.0723 - acc: 0.664 - ETA: 7s - loss: 1.0725 - acc: 0.664 - ETA: 7s - loss: 1.0724 - acc: 0.664 - ETA: 7s - loss: 1.0726 - acc: 0.664 - ETA: 7s - loss: 1.0725 - acc: 0.664 - ETA: 7s - loss: 1.0729 - acc: 0.663 - ETA: 7s - loss: 1.0730 - acc: 0.663 - ETA: 7s - loss: 1.0727 - acc: 0.664 - ETA: 6s - loss: 1.0727 - acc: 0.664 - ETA: 6s - loss: 1.0725 - acc: 0.664 - ETA: 6s - loss: 1.0725 - acc: 0.664 - ETA: 6s - loss: 1.0723 - acc: 0.664 - ETA: 6s - loss: 1.0722 - acc: 0.664 - ETA: 6s - loss: 1.0722 - acc: 0.6642100000/100000 [==============================] - ETA: 6s - loss: 1.0722 - acc: 0.664 - ETA: 6s - loss: 1.0721 - acc: 0.664 - ETA: 6s - loss: 1.0724 - acc: 0.664 - ETA: 6s - loss: 1.0725 - acc: 0.664 - ETA: 6s - loss: 1.0727 - acc: 0.664 - ETA: 6s - loss: 1.0731 - acc: 0.663 - ETA: 6s - loss: 1.0734 - acc: 0.663 - ETA: 6s - loss: 1.0732 - acc: 0.663 - ETA: 6s - loss: 1.0733 - acc: 0.663 - ETA: 5s - loss: 1.0733 - acc: 0.663 - ETA: 5s - loss: 1.0732 - acc: 0.663 - ETA: 5s - loss: 1.0732 - acc: 0.663 - ETA: 5s - loss: 1.0733 - acc: 0.663 - ETA: 5s - loss: 1.0735 - acc: 0.663 - ETA: 5s - loss: 1.0737 - acc: 0.663 - ETA: 5s - loss: 1.0740 - acc: 0.663 - ETA: 5s - loss: 1.0737 - acc: 0.663 - ETA: 5s - loss: 1.0737 - acc: 0.663 - ETA: 5s - loss: 1.0739 - acc: 0.663 - ETA: 5s - loss: 1.0742 - acc: 0.663 - ETA: 5s - loss: 1.0741 - acc: 0.663 - ETA: 5s - loss: 1.0740 - acc: 0.663 - ETA: 5s - loss: 1.0741 - acc: 0.663 - ETA: 4s - loss: 1.0740 - acc: 0.663 - ETA: 4s - loss: 1.0743 - acc: 0.663 - ETA: 4s - loss: 1.0745 - acc: 0.662 - ETA: 4s - loss: 1.0742 - acc: 0.663 - ETA: 4s - loss: 1.0744 - acc: 0.662 - ETA: 4s - loss: 1.0744 - acc: 0.662 - ETA: 4s - loss: 1.0745 - acc: 0.662 - ETA: 4s - loss: 1.0744 - acc: 0.662 - ETA: 4s - loss: 1.0744 - acc: 0.663 - ETA: 4s - loss: 1.0744 - acc: 0.662 - ETA: 4s - loss: 1.0746 - acc: 0.662 - ETA: 4s - loss: 1.0748 - acc: 0.662 - ETA: 4s - loss: 1.0750 - acc: 0.662 - ETA: 4s - loss: 1.0750 - acc: 0.662 - ETA: 4s - loss: 1.0752 - acc: 0.662 - ETA: 4s - loss: 1.0751 - acc: 0.662 - ETA: 4s - loss: 1.0750 - acc: 0.662 - ETA: 3s - loss: 1.0753 - acc: 0.662 - ETA: 3s - loss: 1.0754 - acc: 0.662 - ETA: 3s - loss: 1.0754 - acc: 0.662 - ETA: 3s - loss: 1.0754 - acc: 0.662 - ETA: 3s - loss: 1.0757 - acc: 0.662 - ETA: 3s - loss: 1.0757 - acc: 0.662 - ETA: 3s - loss: 1.0760 - acc: 0.662 - ETA: 3s - loss: 1.0761 - acc: 0.662 - ETA: 3s - loss: 1.0760 - acc: 0.662 - ETA: 3s - loss: 1.0759 - acc: 0.662 - ETA: 3s - loss: 1.0758 - acc: 0.662 - ETA: 3s - loss: 1.0759 - acc: 0.662 - ETA: 3s - loss: 1.0760 - acc: 0.662 - ETA: 3s - loss: 1.0758 - acc: 0.662 - ETA: 2s - loss: 1.0757 - acc: 0.662 - ETA: 2s - loss: 1.0757 - acc: 0.662 - ETA: 2s - loss: 1.0756 - acc: 0.662 - ETA: 2s - loss: 1.0754 - acc: 0.662 - ETA: 2s - loss: 1.0755 - acc: 0.662 - ETA: 2s - loss: 1.0754 - acc: 0.662 - ETA: 2s - loss: 1.0755 - acc: 0.662 - ETA: 2s - loss: 1.0756 - acc: 0.662 - ETA: 2s - loss: 1.0752 - acc: 0.662 - ETA: 2s - loss: 1.0754 - acc: 0.662 - ETA: 2s - loss: 1.0757 - acc: 0.662 - ETA: 2s - loss: 1.0759 - acc: 0.662 - ETA: 2s - loss: 1.0757 - acc: 0.662 - ETA: 2s - loss: 1.0756 - acc: 0.662 - ETA: 1s - loss: 1.0755 - acc: 0.662 - ETA: 1s - loss: 1.0753 - acc: 0.662 - ETA: 1s - loss: 1.0752 - acc: 0.662 - ETA: 1s - loss: 1.0752 - acc: 0.662 - ETA: 1s - loss: 1.0750 - acc: 0.662 - ETA: 1s - loss: 1.0748 - acc: 0.662 - ETA: 1s - loss: 1.0746 - acc: 0.662 - ETA: 1s - loss: 1.0747 - acc: 0.662 - ETA: 1s - loss: 1.0746 - acc: 0.662 - ETA: 1s - loss: 1.0748 - acc: 0.662 - ETA: 1s - loss: 1.0746 - acc: 0.662 - ETA: 1s - loss: 1.0747 - acc: 0.662 - ETA: 1s - loss: 1.0747 - acc: 0.662 - ETA: 1s - loss: 1.0747 - acc: 0.662 - ETA: 1s - loss: 1.0747 - acc: 0.662 - ETA: 1s - loss: 1.0745 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0742 - acc: 0.663 - ETA: 0s - loss: 1.0745 - acc: 0.662 - ETA: 0s - loss: 1.0745 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0742 - acc: 0.662 - ETA: 0s - loss: 1.0743 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0743 - acc: 0.662 - ETA: 0s - loss: 1.0742 - acc: 0.663 - ETA: 0s - loss: 1.0743 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0744 - acc: 0.662 - ETA: 0s - loss: 1.0743 - acc: 0.662 - 36s 361us/step - loss: 1.0743 - acc: 0.6629 - val_loss: 1.0574 - val_acc: 0.6694\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31744/100000 [========>.....................] - ETA: 1:02 - loss: 0.9684 - acc: 0.718 - ETA: 56s - loss: 1.0168 - acc: 0.703 - ETA: 45s - loss: 1.0438 - acc: 0.67 - ETA: 53s - loss: 1.0497 - acc: 0.67 - ETA: 47s - loss: 1.0551 - acc: 0.67 - ETA: 47s - loss: 1.0440 - acc: 0.67 - ETA: 46s - loss: 1.0472 - acc: 0.67 - ETA: 47s - loss: 1.0350 - acc: 0.68 - ETA: 45s - loss: 1.0558 - acc: 0.67 - ETA: 45s - loss: 1.0590 - acc: 0.67 - ETA: 45s - loss: 1.0647 - acc: 0.66 - ETA: 43s - loss: 1.0584 - acc: 0.67 - ETA: 43s - loss: 1.0609 - acc: 0.67 - ETA: 43s - loss: 1.0635 - acc: 0.66 - ETA: 43s - loss: 1.0731 - acc: 0.66 - ETA: 43s - loss: 1.0693 - acc: 0.66 - ETA: 44s - loss: 1.0784 - acc: 0.66 - ETA: 44s - loss: 1.0802 - acc: 0.66 - ETA: 44s - loss: 1.0708 - acc: 0.66 - ETA: 44s - loss: 1.0689 - acc: 0.66 - ETA: 44s - loss: 1.0712 - acc: 0.66 - ETA: 44s - loss: 1.0698 - acc: 0.66 - ETA: 44s - loss: 1.0690 - acc: 0.66 - ETA: 44s - loss: 1.0669 - acc: 0.66 - ETA: 44s - loss: 1.0655 - acc: 0.66 - ETA: 44s - loss: 1.0632 - acc: 0.66 - ETA: 44s - loss: 1.0661 - acc: 0.66 - ETA: 44s - loss: 1.0650 - acc: 0.66 - ETA: 44s - loss: 1.0657 - acc: 0.66 - ETA: 43s - loss: 1.0674 - acc: 0.66 - ETA: 43s - loss: 1.0674 - acc: 0.66 - ETA: 42s - loss: 1.0685 - acc: 0.66 - ETA: 43s - loss: 1.0727 - acc: 0.66 - ETA: 42s - loss: 1.0757 - acc: 0.66 - ETA: 42s - loss: 1.0775 - acc: 0.65 - ETA: 41s - loss: 1.0760 - acc: 0.66 - ETA: 41s - loss: 1.0747 - acc: 0.66 - ETA: 41s - loss: 1.0739 - acc: 0.66 - ETA: 40s - loss: 1.0714 - acc: 0.66 - ETA: 40s - loss: 1.0720 - acc: 0.66 - ETA: 40s - loss: 1.0715 - acc: 0.66 - ETA: 39s - loss: 1.0708 - acc: 0.66 - ETA: 39s - loss: 1.0695 - acc: 0.66 - ETA: 39s - loss: 1.0712 - acc: 0.66 - ETA: 39s - loss: 1.0705 - acc: 0.66 - ETA: 39s - loss: 1.0712 - acc: 0.66 - ETA: 39s - loss: 1.0717 - acc: 0.66 - ETA: 39s - loss: 1.0686 - acc: 0.66 - ETA: 39s - loss: 1.0706 - acc: 0.66 - ETA: 39s - loss: 1.0699 - acc: 0.66 - ETA: 39s - loss: 1.0707 - acc: 0.66 - ETA: 39s - loss: 1.0711 - acc: 0.66 - ETA: 38s - loss: 1.0705 - acc: 0.66 - ETA: 38s - loss: 1.0710 - acc: 0.66 - ETA: 38s - loss: 1.0689 - acc: 0.66 - ETA: 38s - loss: 1.0670 - acc: 0.66 - ETA: 38s - loss: 1.0652 - acc: 0.66 - ETA: 38s - loss: 1.0633 - acc: 0.66 - ETA: 38s - loss: 1.0626 - acc: 0.66 - ETA: 38s - loss: 1.0628 - acc: 0.66 - ETA: 38s - loss: 1.0646 - acc: 0.66 - ETA: 38s - loss: 1.0655 - acc: 0.66 - ETA: 39s - loss: 1.0640 - acc: 0.66 - ETA: 39s - loss: 1.0648 - acc: 0.66 - ETA: 39s - loss: 1.0653 - acc: 0.66 - ETA: 39s - loss: 1.0645 - acc: 0.66 - ETA: 39s - loss: 1.0638 - acc: 0.66 - ETA: 39s - loss: 1.0633 - acc: 0.66 - ETA: 39s - loss: 1.0622 - acc: 0.66 - ETA: 39s - loss: 1.0628 - acc: 0.66 - ETA: 39s - loss: 1.0635 - acc: 0.66 - ETA: 39s - loss: 1.0638 - acc: 0.66 - ETA: 38s - loss: 1.0621 - acc: 0.66 - ETA: 38s - loss: 1.0624 - acc: 0.66 - ETA: 38s - loss: 1.0624 - acc: 0.66 - ETA: 38s - loss: 1.0612 - acc: 0.66 - ETA: 38s - loss: 1.0627 - acc: 0.66 - ETA: 38s - loss: 1.0633 - acc: 0.66 - ETA: 38s - loss: 1.0639 - acc: 0.66 - ETA: 38s - loss: 1.0650 - acc: 0.66 - ETA: 38s - loss: 1.0647 - acc: 0.66 - ETA: 38s - loss: 1.0653 - acc: 0.66 - ETA: 38s - loss: 1.0644 - acc: 0.66 - ETA: 38s - loss: 1.0636 - acc: 0.66 - ETA: 38s - loss: 1.0625 - acc: 0.66 - ETA: 38s - loss: 1.0627 - acc: 0.66 - ETA: 38s - loss: 1.0616 - acc: 0.66 - ETA: 38s - loss: 1.0609 - acc: 0.66 - ETA: 38s - loss: 1.0612 - acc: 0.66 - ETA: 38s - loss: 1.0610 - acc: 0.66 - ETA: 38s - loss: 1.0605 - acc: 0.66 - ETA: 37s - loss: 1.0594 - acc: 0.66 - ETA: 37s - loss: 1.0616 - acc: 0.66 - ETA: 37s - loss: 1.0615 - acc: 0.66 - ETA: 37s - loss: 1.0622 - acc: 0.66 - ETA: 37s - loss: 1.0617 - acc: 0.66 - ETA: 37s - loss: 1.0610 - acc: 0.66 - ETA: 37s - loss: 1.0600 - acc: 0.66 - ETA: 37s - loss: 1.0599 - acc: 0.66 - ETA: 37s - loss: 1.0595 - acc: 0.66 - ETA: 37s - loss: 1.0597 - acc: 0.66 - ETA: 37s - loss: 1.0599 - acc: 0.66 - ETA: 37s - loss: 1.0593 - acc: 0.66 - ETA: 37s - loss: 1.0590 - acc: 0.66 - ETA: 37s - loss: 1.0590 - acc: 0.66 - ETA: 37s - loss: 1.0601 - acc: 0.66 - ETA: 37s - loss: 1.0616 - acc: 0.66 - ETA: 37s - loss: 1.0616 - acc: 0.66 - ETA: 37s - loss: 1.0609 - acc: 0.66 - ETA: 37s - loss: 1.0615 - acc: 0.66 - ETA: 37s - loss: 1.0614 - acc: 0.66 - ETA: 37s - loss: 1.0620 - acc: 0.66 - ETA: 36s - loss: 1.0612 - acc: 0.66 - ETA: 36s - loss: 1.0616 - acc: 0.66 - ETA: 36s - loss: 1.0616 - acc: 0.66 - ETA: 36s - loss: 1.0617 - acc: 0.66 - ETA: 36s - loss: 1.0607 - acc: 0.66 - ETA: 35s - loss: 1.0604 - acc: 0.66 - ETA: 35s - loss: 1.0610 - acc: 0.66 - ETA: 35s - loss: 1.0612 - acc: 0.66 - ETA: 35s - loss: 1.0614 - acc: 0.66 - ETA: 35s - loss: 1.0624 - acc: 0.66 - ETA: 35s - loss: 1.0626 - acc: 0.66 - ETA: 35s - loss: 1.0637 - acc: 0.66 - ETA: 35s - loss: 1.0631 - acc: 0.66 - ETA: 34s - loss: 1.0627 - acc: 0.66 - ETA: 34s - loss: 1.0616 - acc: 0.66 - ETA: 34s - loss: 1.0615 - acc: 0.66 - ETA: 34s - loss: 1.0626 - acc: 0.66 - ETA: 34s - loss: 1.0624 - acc: 0.66 - ETA: 34s - loss: 1.0622 - acc: 0.66 - ETA: 33s - loss: 1.0605 - acc: 0.66 - ETA: 33s - loss: 1.0607 - acc: 0.66 - ETA: 33s - loss: 1.0607 - acc: 0.66 - ETA: 33s - loss: 1.0612 - acc: 0.66 - ETA: 33s - loss: 1.0626 - acc: 0.66 - ETA: 33s - loss: 1.0635 - acc: 0.66 - ETA: 32s - loss: 1.0629 - acc: 0.66 - ETA: 32s - loss: 1.0632 - acc: 0.66 - ETA: 32s - loss: 1.0630 - acc: 0.66 - ETA: 32s - loss: 1.0626 - acc: 0.66 - ETA: 32s - loss: 1.0634 - acc: 0.66 - ETA: 32s - loss: 1.0639 - acc: 0.66 - ETA: 32s - loss: 1.0644 - acc: 0.66 - ETA: 31s - loss: 1.0638 - acc: 0.66 - ETA: 31s - loss: 1.0635 - acc: 0.66 - ETA: 31s - loss: 1.0640 - acc: 0.66 - ETA: 31s - loss: 1.0635 - acc: 0.66 - ETA: 31s - loss: 1.0642 - acc: 0.66 - ETA: 31s - loss: 1.0640 - acc: 0.66 - ETA: 31s - loss: 1.0638 - acc: 0.66 - ETA: 31s - loss: 1.0640 - acc: 0.66 - ETA: 31s - loss: 1.0637 - acc: 0.66 - ETA: 31s - loss: 1.0632 - acc: 0.66 - ETA: 31s - loss: 1.0622 - acc: 0.66 - ETA: 31s - loss: 1.0624 - acc: 0.66 - ETA: 31s - loss: 1.0631 - acc: 0.66 - ETA: 31s - loss: 1.0626 - acc: 0.66 - ETA: 31s - loss: 1.0623 - acc: 0.66 - ETA: 31s - loss: 1.0627 - acc: 0.66 - ETA: 31s - loss: 1.0632 - acc: 0.66 - ETA: 31s - loss: 1.0642 - acc: 0.66 - ETA: 31s - loss: 1.0643 - acc: 0.66 - ETA: 31s - loss: 1.0636 - acc: 0.66 - ETA: 31s - loss: 1.0633 - acc: 0.66 - ETA: 31s - loss: 1.0631 - acc: 0.66 - ETA: 31s - loss: 1.0638 - acc: 0.66 - ETA: 31s - loss: 1.0634 - acc: 0.66 - ETA: 31s - loss: 1.0630 - acc: 0.66 - ETA: 31s - loss: 1.0627 - acc: 0.66 - ETA: 30s - loss: 1.0625 - acc: 0.66 - ETA: 30s - loss: 1.0629 - acc: 0.66 - ETA: 30s - loss: 1.0625 - acc: 0.66 - ETA: 30s - loss: 1.0625 - acc: 0.66 - ETA: 30s - loss: 1.0631 - acc: 0.66 - ETA: 30s - loss: 1.0630 - acc: 0.66 - ETA: 30s - loss: 1.0629 - acc: 0.66 - ETA: 30s - loss: 1.0631 - acc: 0.66 - ETA: 30s - loss: 1.0636 - acc: 0.66 - ETA: 30s - loss: 1.0628 - acc: 0.66 - ETA: 30s - loss: 1.0623 - acc: 0.66 - ETA: 30s - loss: 1.0627 - acc: 0.66 - ETA: 30s - loss: 1.0627 - acc: 0.66 - ETA: 30s - loss: 1.0628 - acc: 0.66 - ETA: 30s - loss: 1.0626 - acc: 0.66 - ETA: 30s - loss: 1.0625 - acc: 0.66 - ETA: 30s - loss: 1.0620 - acc: 0.66 - ETA: 30s - loss: 1.0626 - acc: 0.66 - ETA: 30s - loss: 1.0632 - acc: 0.66 - ETA: 30s - loss: 1.0634 - acc: 0.66 - ETA: 30s - loss: 1.0630 - acc: 0.66 - ETA: 30s - loss: 1.0627 - acc: 0.66 - ETA: 30s - loss: 1.0632 - acc: 0.66 - ETA: 30s - loss: 1.0624 - acc: 0.66 - ETA: 29s - loss: 1.0623 - acc: 0.66 - ETA: 30s - loss: 1.0625 - acc: 0.66 - ETA: 29s - loss: 1.0625 - acc: 0.66 - ETA: 29s - loss: 1.0623 - acc: 0.66 - ETA: 29s - loss: 1.0619 - acc: 0.66 - ETA: 29s - loss: 1.0628 - acc: 0.66 - ETA: 29s - loss: 1.0643 - acc: 0.66 - ETA: 29s - loss: 1.0642 - acc: 0.66 - ETA: 29s - loss: 1.0644 - acc: 0.66 - ETA: 29s - loss: 1.0647 - acc: 0.66 - ETA: 29s - loss: 1.0649 - acc: 0.66 - ETA: 29s - loss: 1.0648 - acc: 0.66 - ETA: 29s - loss: 1.0652 - acc: 0.66 - ETA: 29s - loss: 1.0655 - acc: 0.66 - ETA: 29s - loss: 1.0665 - acc: 0.66 - ETA: 29s - loss: 1.0664 - acc: 0.66 - ETA: 29s - loss: 1.0668 - acc: 0.66 - ETA: 29s - loss: 1.0670 - acc: 0.66 - ETA: 29s - loss: 1.0678 - acc: 0.66 - ETA: 28s - loss: 1.0677 - acc: 0.66 - ETA: 28s - loss: 1.0679 - acc: 0.6643 60736/100000 [=================>............] - ETA: 28s - loss: 1.0677 - acc: 0.66 - ETA: 28s - loss: 1.0679 - acc: 0.66 - ETA: 28s - loss: 1.0680 - acc: 0.66 - ETA: 28s - loss: 1.0677 - acc: 0.66 - ETA: 28s - loss: 1.0674 - acc: 0.66 - ETA: 28s - loss: 1.0676 - acc: 0.66 - ETA: 28s - loss: 1.0675 - acc: 0.66 - ETA: 28s - loss: 1.0681 - acc: 0.66 - ETA: 28s - loss: 1.0684 - acc: 0.66 - ETA: 28s - loss: 1.0683 - acc: 0.66 - ETA: 28s - loss: 1.0687 - acc: 0.66 - ETA: 28s - loss: 1.0688 - acc: 0.66 - ETA: 28s - loss: 1.0686 - acc: 0.66 - ETA: 28s - loss: 1.0691 - acc: 0.66 - ETA: 28s - loss: 1.0691 - acc: 0.66 - ETA: 28s - loss: 1.0688 - acc: 0.66 - ETA: 28s - loss: 1.0686 - acc: 0.66 - ETA: 28s - loss: 1.0686 - acc: 0.66 - ETA: 28s - loss: 1.0686 - acc: 0.66 - ETA: 28s - loss: 1.0685 - acc: 0.66 - ETA: 28s - loss: 1.0685 - acc: 0.66 - ETA: 27s - loss: 1.0687 - acc: 0.66 - ETA: 27s - loss: 1.0695 - acc: 0.66 - ETA: 27s - loss: 1.0696 - acc: 0.66 - ETA: 27s - loss: 1.0692 - acc: 0.66 - ETA: 27s - loss: 1.0693 - acc: 0.66 - ETA: 27s - loss: 1.0691 - acc: 0.66 - ETA: 27s - loss: 1.0692 - acc: 0.66 - ETA: 27s - loss: 1.0689 - acc: 0.66 - ETA: 27s - loss: 1.0688 - acc: 0.66 - ETA: 27s - loss: 1.0688 - acc: 0.66 - ETA: 27s - loss: 1.0688 - acc: 0.66 - ETA: 27s - loss: 1.0690 - acc: 0.66 - ETA: 27s - loss: 1.0691 - acc: 0.66 - ETA: 27s - loss: 1.0695 - acc: 0.66 - ETA: 27s - loss: 1.0692 - acc: 0.66 - ETA: 27s - loss: 1.0684 - acc: 0.66 - ETA: 27s - loss: 1.0680 - acc: 0.66 - ETA: 27s - loss: 1.0686 - acc: 0.66 - ETA: 27s - loss: 1.0686 - acc: 0.66 - ETA: 27s - loss: 1.0683 - acc: 0.66 - ETA: 27s - loss: 1.0684 - acc: 0.66 - ETA: 27s - loss: 1.0688 - acc: 0.66 - ETA: 27s - loss: 1.0684 - acc: 0.66 - ETA: 27s - loss: 1.0684 - acc: 0.66 - ETA: 27s - loss: 1.0679 - acc: 0.66 - ETA: 27s - loss: 1.0678 - acc: 0.66 - ETA: 26s - loss: 1.0685 - acc: 0.66 - ETA: 26s - loss: 1.0680 - acc: 0.66 - ETA: 26s - loss: 1.0681 - acc: 0.66 - ETA: 26s - loss: 1.0683 - acc: 0.66 - ETA: 26s - loss: 1.0682 - acc: 0.66 - ETA: 26s - loss: 1.0682 - acc: 0.66 - ETA: 26s - loss: 1.0680 - acc: 0.66 - ETA: 26s - loss: 1.0677 - acc: 0.66 - ETA: 26s - loss: 1.0681 - acc: 0.66 - ETA: 26s - loss: 1.0676 - acc: 0.66 - ETA: 26s - loss: 1.0679 - acc: 0.66 - ETA: 26s - loss: 1.0685 - acc: 0.66 - ETA: 26s - loss: 1.0686 - acc: 0.66 - ETA: 26s - loss: 1.0681 - acc: 0.66 - ETA: 26s - loss: 1.0683 - acc: 0.66 - ETA: 26s - loss: 1.0686 - acc: 0.66 - ETA: 26s - loss: 1.0684 - acc: 0.66 - ETA: 26s - loss: 1.0689 - acc: 0.66 - ETA: 26s - loss: 1.0689 - acc: 0.66 - ETA: 26s - loss: 1.0688 - acc: 0.66 - ETA: 26s - loss: 1.0694 - acc: 0.66 - ETA: 26s - loss: 1.0698 - acc: 0.66 - ETA: 26s - loss: 1.0702 - acc: 0.66 - ETA: 26s - loss: 1.0699 - acc: 0.66 - ETA: 26s - loss: 1.0701 - acc: 0.66 - ETA: 26s - loss: 1.0702 - acc: 0.66 - ETA: 26s - loss: 1.0702 - acc: 0.66 - ETA: 26s - loss: 1.0702 - acc: 0.66 - ETA: 25s - loss: 1.0702 - acc: 0.66 - ETA: 25s - loss: 1.0698 - acc: 0.66 - ETA: 25s - loss: 1.0698 - acc: 0.66 - ETA: 25s - loss: 1.0700 - acc: 0.66 - ETA: 25s - loss: 1.0701 - acc: 0.66 - ETA: 25s - loss: 1.0705 - acc: 0.66 - ETA: 25s - loss: 1.0703 - acc: 0.66 - ETA: 25s - loss: 1.0702 - acc: 0.66 - ETA: 25s - loss: 1.0704 - acc: 0.66 - ETA: 25s - loss: 1.0709 - acc: 0.66 - ETA: 25s - loss: 1.0714 - acc: 0.66 - ETA: 25s - loss: 1.0715 - acc: 0.66 - ETA: 25s - loss: 1.0714 - acc: 0.66 - ETA: 25s - loss: 1.0714 - acc: 0.66 - ETA: 25s - loss: 1.0713 - acc: 0.66 - ETA: 25s - loss: 1.0711 - acc: 0.66 - ETA: 25s - loss: 1.0709 - acc: 0.66 - ETA: 25s - loss: 1.0712 - acc: 0.66 - ETA: 25s - loss: 1.0711 - acc: 0.66 - ETA: 25s - loss: 1.0709 - acc: 0.66 - ETA: 25s - loss: 1.0713 - acc: 0.66 - ETA: 24s - loss: 1.0711 - acc: 0.66 - ETA: 24s - loss: 1.0712 - acc: 0.66 - ETA: 24s - loss: 1.0712 - acc: 0.66 - ETA: 24s - loss: 1.0716 - acc: 0.66 - ETA: 24s - loss: 1.0721 - acc: 0.66 - ETA: 24s - loss: 1.0721 - acc: 0.66 - ETA: 24s - loss: 1.0723 - acc: 0.66 - ETA: 24s - loss: 1.0722 - acc: 0.66 - ETA: 24s - loss: 1.0724 - acc: 0.66 - ETA: 24s - loss: 1.0724 - acc: 0.66 - ETA: 24s - loss: 1.0726 - acc: 0.66 - ETA: 24s - loss: 1.0720 - acc: 0.66 - ETA: 24s - loss: 1.0717 - acc: 0.66 - ETA: 24s - loss: 1.0716 - acc: 0.66 - ETA: 24s - loss: 1.0717 - acc: 0.66 - ETA: 24s - loss: 1.0715 - acc: 0.66 - ETA: 24s - loss: 1.0714 - acc: 0.66 - ETA: 24s - loss: 1.0709 - acc: 0.66 - ETA: 23s - loss: 1.0706 - acc: 0.66 - ETA: 23s - loss: 1.0706 - acc: 0.66 - ETA: 23s - loss: 1.0707 - acc: 0.66 - ETA: 23s - loss: 1.0709 - acc: 0.66 - ETA: 23s - loss: 1.0711 - acc: 0.66 - ETA: 23s - loss: 1.0716 - acc: 0.66 - ETA: 23s - loss: 1.0714 - acc: 0.66 - ETA: 23s - loss: 1.0717 - acc: 0.66 - ETA: 23s - loss: 1.0719 - acc: 0.66 - ETA: 23s - loss: 1.0721 - acc: 0.66 - ETA: 23s - loss: 1.0722 - acc: 0.66 - ETA: 23s - loss: 1.0720 - acc: 0.66 - ETA: 23s - loss: 1.0718 - acc: 0.66 - ETA: 23s - loss: 1.0719 - acc: 0.66 - ETA: 23s - loss: 1.0721 - acc: 0.66 - ETA: 23s - loss: 1.0718 - acc: 0.66 - ETA: 23s - loss: 1.0717 - acc: 0.66 - ETA: 22s - loss: 1.0718 - acc: 0.66 - ETA: 22s - loss: 1.0719 - acc: 0.66 - ETA: 22s - loss: 1.0717 - acc: 0.66 - ETA: 22s - loss: 1.0719 - acc: 0.66 - ETA: 22s - loss: 1.0715 - acc: 0.66 - ETA: 22s - loss: 1.0716 - acc: 0.66 - ETA: 22s - loss: 1.0719 - acc: 0.66 - ETA: 22s - loss: 1.0721 - acc: 0.66 - ETA: 22s - loss: 1.0723 - acc: 0.66 - ETA: 22s - loss: 1.0720 - acc: 0.66 - ETA: 22s - loss: 1.0720 - acc: 0.66 - ETA: 22s - loss: 1.0722 - acc: 0.66 - ETA: 22s - loss: 1.0724 - acc: 0.66 - ETA: 22s - loss: 1.0723 - acc: 0.66 - ETA: 22s - loss: 1.0725 - acc: 0.66 - ETA: 22s - loss: 1.0724 - acc: 0.66 - ETA: 21s - loss: 1.0722 - acc: 0.66 - ETA: 21s - loss: 1.0723 - acc: 0.66 - ETA: 21s - loss: 1.0724 - acc: 0.66 - ETA: 21s - loss: 1.0725 - acc: 0.66 - ETA: 21s - loss: 1.0728 - acc: 0.66 - ETA: 21s - loss: 1.0726 - acc: 0.66 - ETA: 21s - loss: 1.0723 - acc: 0.66 - ETA: 21s - loss: 1.0722 - acc: 0.66 - ETA: 21s - loss: 1.0722 - acc: 0.66 - ETA: 21s - loss: 1.0724 - acc: 0.66 - ETA: 21s - loss: 1.0724 - acc: 0.66 - ETA: 21s - loss: 1.0725 - acc: 0.66 - ETA: 21s - loss: 1.0727 - acc: 0.66 - ETA: 21s - loss: 1.0726 - acc: 0.66 - ETA: 20s - loss: 1.0724 - acc: 0.66 - ETA: 20s - loss: 1.0726 - acc: 0.66 - ETA: 20s - loss: 1.0726 - acc: 0.66 - ETA: 20s - loss: 1.0726 - acc: 0.66 - ETA: 20s - loss: 1.0729 - acc: 0.66 - ETA: 20s - loss: 1.0730 - acc: 0.66 - ETA: 20s - loss: 1.0730 - acc: 0.66 - ETA: 20s - loss: 1.0733 - acc: 0.66 - ETA: 20s - loss: 1.0731 - acc: 0.66 - ETA: 20s - loss: 1.0731 - acc: 0.66 - ETA: 20s - loss: 1.0729 - acc: 0.66 - ETA: 20s - loss: 1.0728 - acc: 0.66 - ETA: 20s - loss: 1.0728 - acc: 0.66 - ETA: 20s - loss: 1.0729 - acc: 0.66 - ETA: 20s - loss: 1.0727 - acc: 0.66 - ETA: 20s - loss: 1.0727 - acc: 0.66 - ETA: 19s - loss: 1.0728 - acc: 0.66 - ETA: 19s - loss: 1.0728 - acc: 0.66 - ETA: 19s - loss: 1.0729 - acc: 0.66 - ETA: 19s - loss: 1.0728 - acc: 0.66 - ETA: 19s - loss: 1.0730 - acc: 0.66 - ETA: 19s - loss: 1.0729 - acc: 0.66 - ETA: 19s - loss: 1.0732 - acc: 0.66 - ETA: 19s - loss: 1.0731 - acc: 0.66 - ETA: 19s - loss: 1.0730 - acc: 0.66 - ETA: 19s - loss: 1.0731 - acc: 0.66 - ETA: 19s - loss: 1.0732 - acc: 0.66 - ETA: 19s - loss: 1.0732 - acc: 0.66 - ETA: 19s - loss: 1.0733 - acc: 0.66 - ETA: 19s - loss: 1.0734 - acc: 0.66 - ETA: 19s - loss: 1.0734 - acc: 0.66 - ETA: 18s - loss: 1.0734 - acc: 0.66 - ETA: 18s - loss: 1.0735 - acc: 0.66 - ETA: 18s - loss: 1.0736 - acc: 0.66 - ETA: 18s - loss: 1.0737 - acc: 0.66 - ETA: 18s - loss: 1.0740 - acc: 0.66 - ETA: 18s - loss: 1.0738 - acc: 0.66 - ETA: 18s - loss: 1.0735 - acc: 0.66 - ETA: 18s - loss: 1.0736 - acc: 0.66 - ETA: 18s - loss: 1.0737 - acc: 0.66 - ETA: 18s - loss: 1.0739 - acc: 0.66 - ETA: 18s - loss: 1.0742 - acc: 0.66 - ETA: 18s - loss: 1.0742 - acc: 0.66 - ETA: 18s - loss: 1.0741 - acc: 0.66 - ETA: 18s - loss: 1.0739 - acc: 0.66 - ETA: 18s - loss: 1.0742 - acc: 0.66 - ETA: 18s - loss: 1.0742 - acc: 0.66 - ETA: 18s - loss: 1.0740 - acc: 0.66 - ETA: 17s - loss: 1.0742 - acc: 0.66 - ETA: 17s - loss: 1.0741 - acc: 0.66 - ETA: 17s - loss: 1.0740 - acc: 0.66 - ETA: 17s - loss: 1.0741 - acc: 0.66 - ETA: 17s - loss: 1.0742 - acc: 0.66 - ETA: 17s - loss: 1.0741 - acc: 0.6622"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89600/100000 [=========================>....] - ETA: 17s - loss: 1.0738 - acc: 0.66 - ETA: 17s - loss: 1.0735 - acc: 0.66 - ETA: 17s - loss: 1.0740 - acc: 0.66 - ETA: 17s - loss: 1.0743 - acc: 0.66 - ETA: 17s - loss: 1.0742 - acc: 0.66 - ETA: 17s - loss: 1.0744 - acc: 0.66 - ETA: 17s - loss: 1.0744 - acc: 0.66 - ETA: 17s - loss: 1.0745 - acc: 0.66 - ETA: 17s - loss: 1.0742 - acc: 0.66 - ETA: 17s - loss: 1.0740 - acc: 0.66 - ETA: 16s - loss: 1.0742 - acc: 0.66 - ETA: 16s - loss: 1.0744 - acc: 0.66 - ETA: 16s - loss: 1.0745 - acc: 0.66 - ETA: 16s - loss: 1.0745 - acc: 0.66 - ETA: 16s - loss: 1.0742 - acc: 0.66 - ETA: 16s - loss: 1.0743 - acc: 0.66 - ETA: 16s - loss: 1.0745 - acc: 0.66 - ETA: 16s - loss: 1.0746 - acc: 0.66 - ETA: 16s - loss: 1.0750 - acc: 0.66 - ETA: 16s - loss: 1.0751 - acc: 0.66 - ETA: 16s - loss: 1.0751 - acc: 0.66 - ETA: 16s - loss: 1.0753 - acc: 0.66 - ETA: 16s - loss: 1.0753 - acc: 0.66 - ETA: 16s - loss: 1.0753 - acc: 0.66 - ETA: 16s - loss: 1.0750 - acc: 0.66 - ETA: 16s - loss: 1.0751 - acc: 0.66 - ETA: 16s - loss: 1.0754 - acc: 0.66 - ETA: 15s - loss: 1.0752 - acc: 0.66 - ETA: 15s - loss: 1.0749 - acc: 0.66 - ETA: 15s - loss: 1.0748 - acc: 0.66 - ETA: 15s - loss: 1.0749 - acc: 0.66 - ETA: 15s - loss: 1.0748 - acc: 0.66 - ETA: 15s - loss: 1.0747 - acc: 0.66 - ETA: 15s - loss: 1.0743 - acc: 0.66 - ETA: 15s - loss: 1.0743 - acc: 0.66 - ETA: 15s - loss: 1.0741 - acc: 0.66 - ETA: 15s - loss: 1.0741 - acc: 0.66 - ETA: 15s - loss: 1.0745 - acc: 0.66 - ETA: 15s - loss: 1.0742 - acc: 0.66 - ETA: 15s - loss: 1.0743 - acc: 0.66 - ETA: 15s - loss: 1.0742 - acc: 0.66 - ETA: 15s - loss: 1.0742 - acc: 0.66 - ETA: 15s - loss: 1.0742 - acc: 0.66 - ETA: 15s - loss: 1.0741 - acc: 0.66 - ETA: 14s - loss: 1.0744 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0738 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0740 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0738 - acc: 0.66 - ETA: 14s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0736 - acc: 0.66 - ETA: 14s - loss: 1.0737 - acc: 0.66 - ETA: 14s - loss: 1.0739 - acc: 0.66 - ETA: 14s - loss: 1.0736 - acc: 0.66 - ETA: 13s - loss: 1.0736 - acc: 0.66 - ETA: 13s - loss: 1.0738 - acc: 0.66 - ETA: 13s - loss: 1.0736 - acc: 0.66 - ETA: 13s - loss: 1.0734 - acc: 0.66 - ETA: 13s - loss: 1.0731 - acc: 0.66 - ETA: 13s - loss: 1.0733 - acc: 0.66 - ETA: 13s - loss: 1.0731 - acc: 0.66 - ETA: 13s - loss: 1.0732 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0729 - acc: 0.66 - ETA: 13s - loss: 1.0728 - acc: 0.66 - ETA: 13s - loss: 1.0726 - acc: 0.66 - ETA: 13s - loss: 1.0727 - acc: 0.66 - ETA: 13s - loss: 1.0725 - acc: 0.66 - ETA: 12s - loss: 1.0724 - acc: 0.66 - ETA: 12s - loss: 1.0724 - acc: 0.66 - ETA: 12s - loss: 1.0723 - acc: 0.66 - ETA: 12s - loss: 1.0721 - acc: 0.66 - ETA: 12s - loss: 1.0720 - acc: 0.66 - ETA: 12s - loss: 1.0721 - acc: 0.66 - ETA: 12s - loss: 1.0720 - acc: 0.66 - ETA: 12s - loss: 1.0719 - acc: 0.66 - ETA: 12s - loss: 1.0719 - acc: 0.66 - ETA: 12s - loss: 1.0721 - acc: 0.66 - ETA: 12s - loss: 1.0719 - acc: 0.66 - ETA: 12s - loss: 1.0718 - acc: 0.66 - ETA: 12s - loss: 1.0715 - acc: 0.66 - ETA: 12s - loss: 1.0719 - acc: 0.66 - ETA: 12s - loss: 1.0716 - acc: 0.66 - ETA: 12s - loss: 1.0715 - acc: 0.66 - ETA: 12s - loss: 1.0718 - acc: 0.66 - ETA: 11s - loss: 1.0715 - acc: 0.66 - ETA: 11s - loss: 1.0717 - acc: 0.66 - ETA: 11s - loss: 1.0717 - acc: 0.66 - ETA: 11s - loss: 1.0718 - acc: 0.66 - ETA: 11s - loss: 1.0720 - acc: 0.66 - ETA: 11s - loss: 1.0718 - acc: 0.66 - ETA: 11s - loss: 1.0718 - acc: 0.66 - ETA: 11s - loss: 1.0720 - acc: 0.66 - ETA: 11s - loss: 1.0724 - acc: 0.66 - ETA: 11s - loss: 1.0726 - acc: 0.66 - ETA: 11s - loss: 1.0728 - acc: 0.66 - ETA: 11s - loss: 1.0728 - acc: 0.66 - ETA: 11s - loss: 1.0730 - acc: 0.66 - ETA: 11s - loss: 1.0730 - acc: 0.66 - ETA: 11s - loss: 1.0730 - acc: 0.66 - ETA: 11s - loss: 1.0732 - acc: 0.66 - ETA: 11s - loss: 1.0731 - acc: 0.66 - ETA: 10s - loss: 1.0732 - acc: 0.66 - ETA: 10s - loss: 1.0733 - acc: 0.66 - ETA: 10s - loss: 1.0732 - acc: 0.66 - ETA: 10s - loss: 1.0732 - acc: 0.66 - ETA: 10s - loss: 1.0733 - acc: 0.66 - ETA: 10s - loss: 1.0734 - acc: 0.66 - ETA: 10s - loss: 1.0733 - acc: 0.66 - ETA: 10s - loss: 1.0732 - acc: 0.66 - ETA: 10s - loss: 1.0732 - acc: 0.66 - ETA: 10s - loss: 1.0734 - acc: 0.66 - ETA: 10s - loss: 1.0733 - acc: 0.66 - ETA: 10s - loss: 1.0731 - acc: 0.66 - ETA: 10s - loss: 1.0733 - acc: 0.66 - ETA: 10s - loss: 1.0734 - acc: 0.66 - ETA: 10s - loss: 1.0737 - acc: 0.66 - ETA: 10s - loss: 1.0737 - acc: 0.66 - ETA: 10s - loss: 1.0736 - acc: 0.66 - ETA: 9s - loss: 1.0736 - acc: 0.6626 - ETA: 9s - loss: 1.0736 - acc: 0.662 - ETA: 9s - loss: 1.0737 - acc: 0.662 - ETA: 9s - loss: 1.0736 - acc: 0.662 - ETA: 9s - loss: 1.0734 - acc: 0.662 - ETA: 9s - loss: 1.0732 - acc: 0.662 - ETA: 9s - loss: 1.0735 - acc: 0.662 - ETA: 9s - loss: 1.0737 - acc: 0.662 - ETA: 9s - loss: 1.0736 - acc: 0.662 - ETA: 9s - loss: 1.0736 - acc: 0.662 - ETA: 9s - loss: 1.0736 - acc: 0.662 - ETA: 9s - loss: 1.0732 - acc: 0.662 - ETA: 9s - loss: 1.0728 - acc: 0.662 - ETA: 9s - loss: 1.0730 - acc: 0.662 - ETA: 9s - loss: 1.0731 - acc: 0.662 - ETA: 9s - loss: 1.0729 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0727 - acc: 0.662 - ETA: 8s - loss: 1.0727 - acc: 0.662 - ETA: 8s - loss: 1.0726 - acc: 0.662 - ETA: 8s - loss: 1.0726 - acc: 0.662 - ETA: 8s - loss: 1.0727 - acc: 0.662 - ETA: 8s - loss: 1.0729 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0727 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 8s - loss: 1.0728 - acc: 0.662 - ETA: 7s - loss: 1.0727 - acc: 0.662 - ETA: 7s - loss: 1.0727 - acc: 0.662 - ETA: 7s - loss: 1.0726 - acc: 0.662 - ETA: 7s - loss: 1.0727 - acc: 0.662 - ETA: 7s - loss: 1.0727 - acc: 0.662 - ETA: 7s - loss: 1.0729 - acc: 0.662 - ETA: 7s - loss: 1.0731 - acc: 0.662 - ETA: 7s - loss: 1.0731 - acc: 0.662 - ETA: 7s - loss: 1.0730 - acc: 0.662 - ETA: 7s - loss: 1.0729 - acc: 0.662 - ETA: 7s - loss: 1.0728 - acc: 0.662 - ETA: 7s - loss: 1.0727 - acc: 0.662 - ETA: 7s - loss: 1.0728 - acc: 0.662 - ETA: 7s - loss: 1.0728 - acc: 0.662 - ETA: 7s - loss: 1.0725 - acc: 0.662 - ETA: 7s - loss: 1.0723 - acc: 0.663 - ETA: 7s - loss: 1.0724 - acc: 0.662 - ETA: 6s - loss: 1.0724 - acc: 0.662 - ETA: 6s - loss: 1.0722 - acc: 0.663 - ETA: 6s - loss: 1.0724 - acc: 0.662 - ETA: 6s - loss: 1.0726 - acc: 0.662 - ETA: 6s - loss: 1.0725 - acc: 0.662 - ETA: 6s - loss: 1.0725 - acc: 0.662 - ETA: 6s - loss: 1.0724 - acc: 0.662 - ETA: 6s - loss: 1.0726 - acc: 0.662 - ETA: 6s - loss: 1.0723 - acc: 0.662 - ETA: 6s - loss: 1.0721 - acc: 0.662 - ETA: 6s - loss: 1.0721 - acc: 0.662 - ETA: 6s - loss: 1.0720 - acc: 0.663 - ETA: 6s - loss: 1.0722 - acc: 0.662 - ETA: 6s - loss: 1.0722 - acc: 0.662 - ETA: 6s - loss: 1.0720 - acc: 0.663 - ETA: 5s - loss: 1.0721 - acc: 0.663 - ETA: 5s - loss: 1.0721 - acc: 0.663 - ETA: 5s - loss: 1.0721 - acc: 0.663 - ETA: 5s - loss: 1.0719 - acc: 0.663 - ETA: 5s - loss: 1.0719 - acc: 0.663 - ETA: 5s - loss: 1.0716 - acc: 0.663 - ETA: 5s - loss: 1.0716 - acc: 0.663 - ETA: 5s - loss: 1.0715 - acc: 0.663 - ETA: 5s - loss: 1.0715 - acc: 0.663 - ETA: 5s - loss: 1.0716 - acc: 0.663 - ETA: 5s - loss: 1.0715 - acc: 0.663 - ETA: 5s - loss: 1.0717 - acc: 0.663 - ETA: 5s - loss: 1.0718 - acc: 0.663 - ETA: 5s - loss: 1.0718 - acc: 0.663 - ETA: 5s - loss: 1.0718 - acc: 0.663 - ETA: 5s - loss: 1.0719 - acc: 0.663 - ETA: 4s - loss: 1.0720 - acc: 0.663 - ETA: 4s - loss: 1.0719 - acc: 0.663 - ETA: 4s - loss: 1.0720 - acc: 0.663 - ETA: 4s - loss: 1.0720 - acc: 0.663 - ETA: 4s - loss: 1.0721 - acc: 0.663 - ETA: 4s - loss: 1.0720 - acc: 0.6631"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - ETA: 4s - loss: 1.0719 - acc: 0.663 - ETA: 4s - loss: 1.0718 - acc: 0.663 - ETA: 4s - loss: 1.0717 - acc: 0.663 - ETA: 4s - loss: 1.0720 - acc: 0.663 - ETA: 4s - loss: 1.0719 - acc: 0.663 - ETA: 4s - loss: 1.0721 - acc: 0.663 - ETA: 4s - loss: 1.0722 - acc: 0.662 - ETA: 4s - loss: 1.0722 - acc: 0.662 - ETA: 4s - loss: 1.0722 - acc: 0.662 - ETA: 4s - loss: 1.0723 - acc: 0.662 - ETA: 3s - loss: 1.0722 - acc: 0.662 - ETA: 3s - loss: 1.0721 - acc: 0.662 - ETA: 3s - loss: 1.0719 - acc: 0.663 - ETA: 3s - loss: 1.0719 - acc: 0.663 - ETA: 3s - loss: 1.0718 - acc: 0.663 - ETA: 3s - loss: 1.0721 - acc: 0.662 - ETA: 3s - loss: 1.0719 - acc: 0.663 - ETA: 3s - loss: 1.0719 - acc: 0.663 - ETA: 3s - loss: 1.0718 - acc: 0.663 - ETA: 3s - loss: 1.0718 - acc: 0.663 - ETA: 3s - loss: 1.0717 - acc: 0.663 - ETA: 3s - loss: 1.0716 - acc: 0.663 - ETA: 3s - loss: 1.0714 - acc: 0.663 - ETA: 3s - loss: 1.0714 - acc: 0.663 - ETA: 3s - loss: 1.0713 - acc: 0.663 - ETA: 2s - loss: 1.0712 - acc: 0.663 - ETA: 2s - loss: 1.0713 - acc: 0.663 - ETA: 2s - loss: 1.0712 - acc: 0.663 - ETA: 2s - loss: 1.0713 - acc: 0.663 - ETA: 2s - loss: 1.0714 - acc: 0.663 - ETA: 2s - loss: 1.0714 - acc: 0.663 - ETA: 2s - loss: 1.0715 - acc: 0.663 - ETA: 2s - loss: 1.0714 - acc: 0.663 - ETA: 2s - loss: 1.0716 - acc: 0.663 - ETA: 2s - loss: 1.0717 - acc: 0.663 - ETA: 2s - loss: 1.0715 - acc: 0.663 - ETA: 2s - loss: 1.0715 - acc: 0.663 - ETA: 2s - loss: 1.0714 - acc: 0.663 - ETA: 2s - loss: 1.0716 - acc: 0.663 - ETA: 2s - loss: 1.0713 - acc: 0.663 - ETA: 1s - loss: 1.0714 - acc: 0.663 - ETA: 1s - loss: 1.0717 - acc: 0.663 - ETA: 1s - loss: 1.0717 - acc: 0.663 - ETA: 1s - loss: 1.0718 - acc: 0.662 - ETA: 1s - loss: 1.0719 - acc: 0.662 - ETA: 1s - loss: 1.0720 - acc: 0.662 - ETA: 1s - loss: 1.0720 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0722 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0721 - acc: 0.662 - ETA: 1s - loss: 1.0720 - acc: 0.662 - ETA: 0s - loss: 1.0719 - acc: 0.662 - ETA: 0s - loss: 1.0719 - acc: 0.662 - ETA: 0s - loss: 1.0719 - acc: 0.662 - ETA: 0s - loss: 1.0717 - acc: 0.663 - ETA: 0s - loss: 1.0716 - acc: 0.663 - ETA: 0s - loss: 1.0716 - acc: 0.663 - ETA: 0s - loss: 1.0716 - acc: 0.663 - ETA: 0s - loss: 1.0716 - acc: 0.663 - ETA: 0s - loss: 1.0716 - acc: 0.663 - ETA: 0s - loss: 1.0719 - acc: 0.663 - ETA: 0s - loss: 1.0719 - acc: 0.663 - ETA: 0s - loss: 1.0719 - acc: 0.662 - ETA: 0s - loss: 1.0719 - acc: 0.663 - ETA: 0s - loss: 1.0718 - acc: 0.663 - ETA: 0s - loss: 1.0718 - acc: 0.663 - ETA: 0s - loss: 1.0719 - acc: 0.663 - 48s 479us/step - loss: 1.0719 - acc: 0.6630 - val_loss: 1.0571 - val_acc: 0.6692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20faa38f860>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(x_train_part.shape[1], x_train_part.shape[2]), activation=\"tanh\", return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(64, input_shape=(500, 25000), activation=\"tanh\", return_sequences=False))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_acc', patience=2, verbose=2, mode='max',restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              #optimizer = sgd,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.fit(x_train_part, y_train_part,\n",
    "          batch_size=batch_size,\n",
    "          epochs=4, #epochs\n",
    "          callbacks=[earlyStopping],\n",
    "          validation_data=(x_test_part, y_test_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_scores = model.predict(x_test_part)\n",
    "\n",
    "y_predicted_scores[y_predicted_scores>=0.5] = 1\n",
    "y_predicted_scores[y_predicted_scores<0.5] = 0\n",
    "\n",
    "print('Classification report\\n')\n",
    "print(classification_report(y_test_part, y_predicted_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить модель из примера имплементации, но с использованием уже предобученного word2vec для русского языка в качестве инициализации эмбединга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = seed, \n",
    "                                                    test_size=0.9, shuffle=True, #0.3 by default, only for test\n",
    "                                                    stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_y_train)\n",
    "y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_url = 'https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map'\n",
    "\n",
    "mystem2upos = {}\n",
    "r = requests.get(mapping_url, stream=True)\n",
    "for pair in r.text.split('\\n'):\n",
    "    pair = pair.split()\n",
    "    if len(pair) > 1:\n",
    "        mystem2upos[pair[0]] = pair[1]\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, mapping):\n",
    "        self.m = Mystem()\n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def process(self, text, postags=True):\n",
    "        processed = self.m.analyze(text)\n",
    "        tagged = []\n",
    "        for w in processed:\n",
    "            try:\n",
    "                lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "                pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "                pos = pos.split('=')[0].strip()\n",
    "                pos = self.mapping.get(pos, 'X')\n",
    "                tagged.append(lemma.lower() + '_' + pos)\n",
    "            except KeyError:\n",
    "                continue\n",
    "            except IndexError:\n",
    "                continue\n",
    "        if not postags:\n",
    "            tagged = [t.split('_')[0] for t in tagged]\n",
    "        return tagged\n",
    "\n",
    "phrases_processor = Preprocessor(mystem2upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'ADJ',\n",
       " 'ADV': 'ADV',\n",
       " 'ADVPRO': 'ADV',\n",
       " 'ANUM': 'ADJ',\n",
       " 'APRO': 'DET',\n",
       " 'COM': 'ADJ',\n",
       " 'CONJ': 'SCONJ',\n",
       " 'INTJ': 'INTJ',\n",
       " 'NONLEX': 'X',\n",
       " 'NUM': 'NUM',\n",
       " 'PART': 'PART',\n",
       " 'PR': 'ADP',\n",
       " 'S': 'NOUN',\n",
       " 'SPRO': 'PRON',\n",
       " 'UNKN': 'X',\n",
       " 'V': 'VERB'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem2upos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1417.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize first\n",
    "x_train_tokenized = []\n",
    "for text in tqdm(x_train[:10000]):\n",
    "    tokenized_text = ' '.join(tokenize(text))\n",
    "    x_train_tokenized.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:02<00:00, 1526.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize first\n",
    "x_test_tokenized = []\n",
    "for text in tqdm(x_test[:4000]):\n",
    "    tokenized_text = ' '.join(tokenize(text))\n",
    "    x_test_tokenized.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use phrases_processor for making text pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = x_train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хорошие недорогие ножи замечаний режут угодно довольна'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tokenized[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хороший_ADJ',\n",
       " 'недорогой_ADJ',\n",
       " 'нож_NOUN',\n",
       " 'замечание_NOUN',\n",
       " 'резать_VERB',\n",
       " 'угодно_PART',\n",
       " 'довольный_ADJ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_processor.process(x_train_tokenized[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def preprocess_test(text,n_start, n_end):\\n    print (text[0])\\n    prepocessed_texts = []\\n    for sub_text in text[n_start:n_end]:\\n        prepocessed_texts.append(phrases_processor.process(text))\\n    return prepocessed_texts'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def preprocess_test(text,n_start, n_end):\n",
    "    print (text[0])\n",
    "    prepocessed_texts = []\n",
    "    for sub_text in text[n_start:n_end]:\n",
    "        prepocessed_texts.append(phrases_processor.process(text))\n",
    "    return prepocessed_texts''';\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 999/10000 [25:18<5:05:00,  2.03s/it]"
     ]
    }
   ],
   "source": [
    "prepocessed_texts = []\n",
    "i= 0\n",
    "for text in tqdm(x_train_tokenized):\n",
    "  i+=1\n",
    "  prepocessed_texts.append(phrases_processor.process(text))\n",
    "  if i==1000:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/4000 [00:00<?, ?it/s]\n",
      "  0%|                                                                               | 1/4000 [00:02<2:13:26,  2.00s/it]\n",
      "  0%|                                                                               | 2/4000 [00:04<2:16:09,  2.04s/it]\n",
      "  0%|                                                                               | 3/4000 [00:06<2:14:22,  2.02s/it]\n",
      "  0%|                                                                               | 4/4000 [00:08<2:14:34,  2.02s/it]\n",
      "  0%|                                                                               | 5/4000 [00:10<2:13:22,  2.00s/it]\n",
      "  0%|                                                                               | 6/4000 [00:11<2:10:11,  1.96s/it]\n",
      "  0%|▏                                                                              | 7/4000 [00:13<2:07:16,  1.91s/it]\n",
      "  0%|▏                                                                              | 8/4000 [00:16<2:21:20,  2.12s/it]\n",
      "  0%|▏                                                                              | 9/4000 [00:18<2:16:49,  2.06s/it]\n",
      "  0%|▏                                                                             | 10/4000 [00:20<2:11:42,  1.98s/it]\n",
      "  0%|▏                                                                             | 11/4000 [00:21<2:08:05,  1.93s/it]\n",
      "  0%|▏                                                                             | 12/4000 [00:23<2:05:09,  1.88s/it]\n",
      "  0%|▎                                                                             | 13/4000 [00:25<2:02:36,  1.85s/it]\n",
      "  0%|▎                                                                             | 14/4000 [00:27<2:01:17,  1.83s/it]\n",
      "  0%|▎                                                                             | 15/4000 [00:28<1:59:57,  1.81s/it]\n",
      "  0%|▎                                                                             | 16/4000 [00:30<2:01:49,  1.83s/it]\n",
      "  0%|▎                                                                             | 17/4000 [00:32<2:03:13,  1.86s/it]\n",
      "  0%|▎                                                                             | 18/4000 [00:34<2:02:49,  1.85s/it]\n",
      "  0%|▎                                                                             | 19/4000 [00:36<2:02:17,  1.84s/it]\n",
      "  0%|▍                                                                             | 20/4000 [00:38<2:00:17,  1.81s/it]\n",
      "  1%|▍                                                                             | 21/4000 [00:39<1:58:24,  1.79s/it]\n",
      "  1%|▍                                                                             | 22/4000 [00:41<1:56:44,  1.76s/it]\n",
      "  1%|▍                                                                             | 23/4000 [00:43<1:57:05,  1.77s/it]\n",
      "  1%|▍                                                                             | 24/4000 [00:45<1:57:15,  1.77s/it]\n",
      "  1%|▍                                                                             | 25/4000 [00:47<2:02:41,  1.85s/it]\n",
      "  1%|▌                                                                             | 26/4000 [00:49<2:02:30,  1.85s/it]\n",
      "  1%|▌                                                                             | 27/4000 [00:50<2:00:41,  1.82s/it]\n",
      "  1%|▌                                                                             | 28/4000 [00:52<1:58:07,  1.78s/it]\n",
      "  1%|▌                                                                             | 29/4000 [00:54<1:54:36,  1.73s/it]\n",
      "  1%|▌                                                                             | 30/4000 [00:55<1:54:33,  1.73s/it]\n",
      "  1%|▌                                                                             | 31/4000 [00:57<1:55:27,  1.75s/it]\n",
      "  1%|▌                                                                             | 32/4000 [00:59<1:55:16,  1.74s/it]\n",
      "  1%|▋                                                                             | 33/4000 [01:01<1:57:51,  1.78s/it]\n",
      "  1%|▋                                                                             | 34/4000 [01:02<1:57:44,  1.78s/it]\n",
      "  1%|▋                                                                             | 35/4000 [01:04<1:53:56,  1.72s/it]\n",
      "  1%|▋                                                                             | 36/4000 [01:06<1:54:46,  1.74s/it]\n",
      "  1%|▋                                                                             | 37/4000 [01:08<1:59:23,  1.81s/it]\n",
      "  1%|▋                                                                             | 38/4000 [01:10<1:58:00,  1.79s/it]\n",
      "  1%|▊                                                                             | 39/4000 [01:11<1:55:03,  1.74s/it]\n",
      "  1%|▊                                                                             | 40/4000 [01:13<1:52:42,  1.71s/it]\n",
      "  1%|▊                                                                             | 41/4000 [01:14<1:50:25,  1.67s/it]\n",
      "  1%|▊                                                                             | 42/4000 [01:16<1:48:44,  1.65s/it]\n",
      "  1%|▊                                                                             | 43/4000 [01:18<1:49:59,  1.67s/it]\n",
      "  1%|▊                                                                             | 44/4000 [01:19<1:48:46,  1.65s/it]\n",
      "  1%|▉                                                                             | 45/4000 [01:21<1:47:30,  1.63s/it]\n",
      "  1%|▉                                                                             | 46/4000 [01:23<1:51:38,  1.69s/it]\n",
      "  1%|▉                                                                             | 47/4000 [01:25<1:52:33,  1.71s/it]\n",
      "  1%|▉                                                                             | 48/4000 [01:26<1:50:16,  1.67s/it]\n",
      "  1%|▉                                                                             | 49/4000 [01:28<1:47:50,  1.64s/it]\n",
      "  1%|▉                                                                             | 50/4000 [01:29<1:48:07,  1.64s/it]\n",
      "  1%|▉                                                                             | 51/4000 [01:31<1:45:28,  1.60s/it]\n",
      "  1%|█                                                                             | 52/4000 [01:32<1:45:09,  1.60s/it]\n",
      "  1%|█                                                                             | 53/4000 [01:34<1:44:15,  1.58s/it]\n",
      "  1%|█                                                                             | 54/4000 [01:35<1:42:40,  1.56s/it]\n",
      "  1%|█                                                                             | 55/4000 [01:37<1:42:11,  1.55s/it]\n",
      "  1%|█                                                                             | 56/4000 [01:38<1:40:39,  1.53s/it]\n",
      "  1%|█                                                                             | 57/4000 [01:40<1:40:37,  1.53s/it]\n",
      "  1%|█▏                                                                            | 58/4000 [01:42<1:45:40,  1.61s/it]\n",
      "  1%|█▏                                                                            | 59/4000 [01:43<1:45:40,  1.61s/it]\n",
      "  2%|█▏                                                                            | 60/4000 [01:45<1:43:24,  1.57s/it]\n",
      "  2%|█▏                                                                            | 61/4000 [01:46<1:43:08,  1.57s/it]\n",
      "  2%|█▏                                                                            | 62/4000 [01:48<1:40:32,  1.53s/it]\n",
      "  2%|█▏                                                                            | 63/4000 [01:49<1:38:13,  1.50s/it]\n",
      "  2%|█▏                                                                            | 64/4000 [01:51<1:36:44,  1.47s/it]\n",
      "  2%|█▎                                                                            | 65/4000 [01:52<1:35:31,  1.46s/it]\n",
      "  2%|█▎                                                                            | 66/4000 [01:54<1:35:27,  1.46s/it]\n",
      "  2%|█▎                                                                            | 67/4000 [01:55<1:36:50,  1.48s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                            | 68/4000 [01:57<1:36:55,  1.48s/it]\n",
      "  2%|█▎                                                                            | 69/4000 [01:58<1:36:08,  1.47s/it]\n",
      "  2%|█▎                                                                            | 70/4000 [02:00<1:35:37,  1.46s/it]\n",
      "  2%|█▍                                                                            | 71/4000 [02:01<1:35:20,  1.46s/it]\n",
      "  2%|█▍                                                                            | 72/4000 [02:02<1:34:52,  1.45s/it]\n",
      "  2%|█▍                                                                            | 73/4000 [02:04<1:34:30,  1.44s/it]\n",
      "  2%|█▍                                                                            | 74/4000 [02:05<1:35:22,  1.46s/it]\n",
      "  2%|█▍                                                                            | 75/4000 [02:07<1:35:23,  1.46s/it]\n",
      "  2%|█▍                                                                            | 76/4000 [02:08<1:34:52,  1.45s/it]\n",
      "  2%|█▌                                                                            | 77/4000 [02:10<1:34:27,  1.44s/it]\n",
      "  2%|█▌                                                                            | 78/4000 [02:11<1:34:26,  1.44s/it]\n",
      "  2%|█▌                                                                            | 79/4000 [02:12<1:33:50,  1.44s/it]\n",
      "  2%|█▌                                                                            | 80/4000 [02:14<1:33:31,  1.43s/it]\n",
      "  2%|█▌                                                                            | 81/4000 [02:15<1:34:09,  1.44s/it]\n",
      "  2%|█▌                                                                            | 82/4000 [02:17<1:34:38,  1.45s/it]\n",
      "  2%|█▌                                                                            | 83/4000 [02:18<1:34:09,  1.44s/it]\n",
      "  2%|█▋                                                                            | 84/4000 [02:20<1:33:39,  1.44s/it]\n",
      "  2%|█▋                                                                            | 85/4000 [02:21<1:33:30,  1.43s/it]\n",
      "  2%|█▋                                                                            | 86/4000 [02:23<1:33:09,  1.43s/it]\n",
      "  2%|█▋                                                                            | 87/4000 [02:24<1:32:53,  1.42s/it]\n",
      "  2%|█▋                                                                            | 88/4000 [02:25<1:32:53,  1.42s/it]\n",
      "  2%|█▋                                                                            | 89/4000 [02:27<1:33:07,  1.43s/it]\n",
      "  2%|█▊                                                                            | 90/4000 [02:28<1:33:19,  1.43s/it]\n",
      "  2%|█▊                                                                            | 91/4000 [02:30<1:33:52,  1.44s/it]\n",
      "  2%|█▊                                                                            | 92/4000 [02:31<1:33:13,  1.43s/it]\n",
      "  2%|█▊                                                                            | 93/4000 [02:33<1:32:52,  1.43s/it]\n",
      "  2%|█▊                                                                            | 94/4000 [02:34<1:32:42,  1.42s/it]\n",
      "  2%|█▊                                                                            | 95/4000 [02:35<1:32:50,  1.43s/it]\n",
      "  2%|█▊                                                                            | 96/4000 [02:37<1:34:38,  1.45s/it]\n",
      "  2%|█▉                                                                            | 97/4000 [02:38<1:34:12,  1.45s/it]\n",
      "  2%|█▉                                                                            | 98/4000 [02:40<1:35:12,  1.46s/it]\n",
      "  2%|█▉                                                                            | 99/4000 [02:41<1:34:16,  1.45s/it]\n",
      "  2%|█▉                                                                           | 100/4000 [02:43<1:34:57,  1.46s/it]\n",
      "  3%|█▉                                                                           | 101/4000 [02:44<1:35:33,  1.47s/it]\n",
      "  3%|█▉                                                                           | 102/4000 [02:46<1:34:33,  1.46s/it]\n",
      "  3%|█▉                                                                           | 103/4000 [02:47<1:34:05,  1.45s/it]\n",
      "  3%|██                                                                           | 104/4000 [02:49<1:33:25,  1.44s/it]\n",
      "  3%|██                                                                           | 105/4000 [02:50<1:33:23,  1.44s/it]\n",
      "  3%|██                                                                           | 106/4000 [02:51<1:33:18,  1.44s/it]\n",
      "  3%|██                                                                           | 107/4000 [02:53<1:33:00,  1.43s/it]\n",
      "  3%|██                                                                           | 108/4000 [02:54<1:32:46,  1.43s/it]\n",
      "  3%|██                                                                           | 109/4000 [02:56<1:33:03,  1.44s/it]\n",
      "  3%|██                                                                           | 110/4000 [02:57<1:32:57,  1.43s/it]\n",
      "  3%|██▏                                                                          | 111/4000 [02:59<1:33:31,  1.44s/it]\n",
      "  3%|██▏                                                                          | 112/4000 [03:00<1:35:16,  1.47s/it]\n",
      "  3%|██▏                                                                          | 113/4000 [03:02<1:34:12,  1.45s/it]\n",
      "  3%|██▏                                                                          | 114/4000 [03:03<1:33:44,  1.45s/it]\n",
      "  3%|██▏                                                                          | 115/4000 [03:04<1:33:09,  1.44s/it]\n",
      "  3%|██▏                                                                          | 116/4000 [03:06<1:32:49,  1.43s/it]\n",
      "  3%|██▎                                                                          | 117/4000 [03:07<1:35:54,  1.48s/it]\n",
      "  3%|██▎                                                                          | 118/4000 [03:09<1:42:01,  1.58s/it]\n",
      "  3%|██▎                                                                          | 119/4000 [03:11<1:41:20,  1.57s/it]\n",
      "  3%|██▎                                                                          | 120/4000 [03:12<1:41:53,  1.58s/it]\n",
      "  3%|██▎                                                                          | 121/4000 [03:14<1:42:44,  1.59s/it]\n",
      "  3%|██▎                                                                          | 122/4000 [03:16<1:44:07,  1.61s/it]\n",
      "  3%|██▎                                                                          | 123/4000 [03:17<1:45:17,  1.63s/it]\n",
      "  3%|██▍                                                                          | 124/4000 [03:19<1:43:37,  1.60s/it]\n",
      "  3%|██▍                                                                          | 125/4000 [03:20<1:42:15,  1.58s/it]\n",
      "  3%|██▍                                                                          | 126/4000 [03:22<1:44:07,  1.61s/it]\n",
      "  3%|██▍                                                                          | 127/4000 [03:24<1:42:47,  1.59s/it]\n",
      "  3%|██▍                                                                          | 128/4000 [03:25<1:41:48,  1.58s/it]\n",
      "  3%|██▍                                                                          | 129/4000 [03:27<1:41:13,  1.57s/it]\n",
      "  3%|██▌                                                                          | 130/4000 [03:28<1:40:20,  1.56s/it]\n",
      "  3%|██▌                                                                          | 131/4000 [03:30<1:39:42,  1.55s/it]\n",
      "  3%|██▌                                                                          | 132/4000 [03:31<1:39:03,  1.54s/it]\n",
      "  3%|██▌                                                                          | 133/4000 [03:33<1:38:39,  1.53s/it]\n",
      "  3%|██▌                                                                          | 134/4000 [03:34<1:38:13,  1.52s/it]\n",
      "  3%|██▌                                                                          | 135/4000 [03:36<1:39:49,  1.55s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                          | 136/4000 [03:37<1:39:34,  1.55s/it]\n",
      "  3%|██▋                                                                          | 137/4000 [03:39<1:39:35,  1.55s/it]\n",
      "  3%|██▋                                                                          | 138/4000 [03:41<1:39:42,  1.55s/it]\n",
      "  3%|██▋                                                                          | 139/4000 [03:42<1:39:51,  1.55s/it]\n",
      "  4%|██▋                                                                          | 140/4000 [03:44<1:39:42,  1.55s/it]\n",
      "  4%|██▋                                                                          | 141/4000 [03:45<1:40:29,  1.56s/it]\n",
      "  4%|██▋                                                                          | 142/4000 [03:47<1:41:01,  1.57s/it]\n",
      "  4%|██▊                                                                          | 143/4000 [03:48<1:40:23,  1.56s/it]\n",
      "  4%|██▊                                                                          | 144/4000 [03:50<1:41:15,  1.58s/it]\n",
      "  4%|██▊                                                                          | 145/4000 [03:51<1:40:40,  1.57s/it]\n",
      "  4%|██▊                                                                          | 146/4000 [03:53<1:40:08,  1.56s/it]\n",
      "  4%|██▊                                                                          | 147/4000 [03:55<1:40:01,  1.56s/it]\n",
      "  4%|██▊                                                                          | 148/4000 [03:56<1:40:59,  1.57s/it]\n",
      "  4%|██▊                                                                          | 149/4000 [03:58<1:40:55,  1.57s/it]\n",
      "  4%|██▉                                                                          | 150/4000 [03:59<1:40:10,  1.56s/it]\n",
      "  4%|██▉                                                                          | 151/4000 [04:01<1:40:29,  1.57s/it]\n",
      "  4%|██▉                                                                          | 152/4000 [04:02<1:41:06,  1.58s/it]\n",
      "  4%|██▉                                                                          | 153/4000 [04:04<1:40:49,  1.57s/it]\n",
      "  4%|██▉                                                                          | 154/4000 [04:06<1:43:37,  1.62s/it]\n",
      "  4%|██▉                                                                          | 155/4000 [04:07<1:42:31,  1.60s/it]\n",
      "  4%|███                                                                          | 156/4000 [04:09<1:41:46,  1.59s/it]\n",
      "  4%|███                                                                          | 157/4000 [04:10<1:40:46,  1.57s/it]\n",
      "  4%|███                                                                          | 158/4000 [04:12<1:40:12,  1.57s/it]\n",
      "  4%|███                                                                          | 159/4000 [04:14<1:40:01,  1.56s/it]\n",
      "  4%|███                                                                          | 160/4000 [04:15<1:39:12,  1.55s/it]\n",
      "  4%|███                                                                          | 161/4000 [04:17<1:39:14,  1.55s/it]\n",
      "  4%|███                                                                          | 162/4000 [04:18<1:38:47,  1.54s/it]\n",
      "  4%|███▏                                                                         | 163/4000 [04:20<1:38:57,  1.55s/it]\n",
      "  4%|███▏                                                                         | 164/4000 [04:21<1:38:52,  1.55s/it]\n",
      "  4%|███▏                                                                         | 165/4000 [04:23<1:38:49,  1.55s/it]\n",
      "  4%|███▏                                                                         | 166/4000 [04:24<1:38:40,  1.54s/it]\n",
      "  4%|███▏                                                                         | 167/4000 [04:26<1:38:08,  1.54s/it]\n",
      "  4%|███▏                                                                         | 168/4000 [04:27<1:39:19,  1.56s/it]\n",
      "  4%|███▎                                                                         | 169/4000 [04:29<1:40:22,  1.57s/it]\n",
      "  4%|███▎                                                                         | 170/4000 [04:31<1:40:03,  1.57s/it]\n",
      "  4%|███▎                                                                         | 171/4000 [04:32<1:41:56,  1.60s/it]\n",
      "  4%|███▎                                                                         | 172/4000 [04:34<1:42:16,  1.60s/it]\n",
      "  4%|███▎                                                                         | 173/4000 [04:35<1:41:26,  1.59s/it]\n",
      "  4%|███▎                                                                         | 174/4000 [04:37<1:41:13,  1.59s/it]\n",
      "  4%|███▎                                                                         | 175/4000 [04:39<1:41:24,  1.59s/it]\n",
      "  4%|███▍                                                                         | 176/4000 [04:40<1:40:56,  1.58s/it]\n",
      "  4%|███▍                                                                         | 177/4000 [04:42<1:39:36,  1.56s/it]\n",
      "  4%|███▍                                                                         | 178/4000 [04:43<1:39:02,  1.55s/it]\n",
      "  4%|███▍                                                                         | 179/4000 [04:45<1:40:03,  1.57s/it]\n",
      "  4%|███▍                                                                         | 180/4000 [04:47<1:44:08,  1.64s/it]\n",
      "  5%|███▍                                                                         | 181/4000 [04:48<1:45:30,  1.66s/it]\n",
      "  5%|███▌                                                                         | 182/4000 [04:50<1:44:38,  1.64s/it]\n",
      "  5%|███▌                                                                         | 183/4000 [04:52<1:46:10,  1.67s/it]\n",
      "  5%|███▌                                                                         | 184/4000 [04:53<1:44:06,  1.64s/it]\n",
      "  5%|███▌                                                                         | 185/4000 [04:55<1:42:39,  1.61s/it]\n",
      "  5%|███▌                                                                         | 186/4000 [04:56<1:42:10,  1.61s/it]\n",
      "  5%|███▌                                                                         | 187/4000 [04:58<1:40:57,  1.59s/it]\n",
      "  5%|███▌                                                                         | 188/4000 [05:00<1:42:24,  1.61s/it]\n",
      "  5%|███▋                                                                         | 189/4000 [05:01<1:44:18,  1.64s/it]\n",
      "  5%|███▋                                                                         | 190/4000 [05:03<1:42:29,  1.61s/it]\n",
      "  5%|███▋                                                                         | 191/4000 [05:05<1:43:57,  1.64s/it]\n",
      "  5%|███▋                                                                         | 192/4000 [05:06<1:42:22,  1.61s/it]\n",
      "  5%|███▋                                                                         | 193/4000 [05:08<1:41:00,  1.59s/it]\n",
      "  5%|███▋                                                                         | 194/4000 [05:09<1:40:05,  1.58s/it]\n",
      "  5%|███▊                                                                         | 195/4000 [05:11<1:39:36,  1.57s/it]\n",
      "  5%|███▊                                                                         | 196/4000 [05:12<1:39:07,  1.56s/it]\n",
      "  5%|███▊                                                                         | 197/4000 [05:14<1:38:43,  1.56s/it]\n",
      "  5%|███▊                                                                         | 198/4000 [05:15<1:38:45,  1.56s/it]\n",
      "  5%|███▊                                                                         | 199/4000 [05:17<1:40:20,  1.58s/it]\n",
      "  5%|███▊                                                                         | 200/4000 [05:19<1:44:23,  1.65s/it]\n",
      "  5%|███▊                                                                         | 201/4000 [05:21<1:48:57,  1.72s/it]\n",
      "  5%|███▉                                                                         | 202/4000 [05:22<1:47:22,  1.70s/it]\n",
      "  5%|███▉                                                                         | 203/4000 [05:24<1:46:20,  1.68s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▉                                                                         | 204/4000 [05:26<1:42:45,  1.62s/it]\n",
      "  5%|███▉                                                                         | 205/4000 [05:27<1:39:42,  1.58s/it]\n",
      "  5%|███▉                                                                         | 206/4000 [05:28<1:36:46,  1.53s/it]\n",
      "  5%|███▉                                                                         | 207/4000 [05:30<1:35:35,  1.51s/it]\n",
      "  5%|████                                                                         | 208/4000 [05:31<1:33:48,  1.48s/it]\n",
      "  5%|████                                                                         | 209/4000 [05:33<1:34:18,  1.49s/it]\n",
      "  5%|████                                                                         | 210/4000 [05:34<1:37:19,  1.54s/it]\n",
      "  5%|████                                                                         | 211/4000 [05:36<1:41:26,  1.61s/it]\n",
      "  5%|████                                                                         | 212/4000 [05:38<1:43:53,  1.65s/it]\n",
      "  5%|████                                                                         | 213/4000 [05:40<1:42:57,  1.63s/it]\n",
      "  5%|████                                                                         | 214/4000 [05:41<1:39:23,  1.58s/it]\n",
      "  5%|████▏                                                                        | 215/4000 [05:43<1:38:01,  1.55s/it]\n",
      "  5%|████▏                                                                        | 216/4000 [05:44<1:38:09,  1.56s/it]\n",
      "  5%|████▏                                                                        | 217/4000 [05:46<1:37:43,  1.55s/it]\n",
      "  5%|████▏                                                                        | 218/4000 [05:47<1:37:35,  1.55s/it]\n",
      "  5%|████▏                                                                        | 219/4000 [05:50<1:54:00,  1.81s/it]\n",
      "  6%|████▏                                                                        | 220/4000 [05:52<1:57:28,  1.86s/it]\n",
      "  6%|████▎                                                                        | 221/4000 [05:54<2:02:28,  1.94s/it]\n",
      "  6%|████▎                                                                        | 222/4000 [05:56<2:03:30,  1.96s/it]\n",
      "  6%|████▎                                                                        | 223/4000 [05:58<2:02:12,  1.94s/it]\n",
      "  6%|████▎                                                                        | 224/4000 [06:00<2:03:44,  1.97s/it]\n",
      "  6%|████▎                                                                        | 225/4000 [06:02<2:03:14,  1.96s/it]\n",
      "  6%|████▎                                                                        | 226/4000 [06:03<2:01:24,  1.93s/it]\n",
      "  6%|████▎                                                                        | 227/4000 [06:05<2:01:31,  1.93s/it]\n",
      "  6%|████▍                                                                        | 228/4000 [06:07<2:00:41,  1.92s/it]\n",
      "  6%|████▍                                                                        | 229/4000 [06:09<2:00:08,  1.91s/it]\n",
      "  6%|████▍                                                                        | 230/4000 [06:11<1:56:11,  1.85s/it]\n",
      "  6%|████▍                                                                        | 231/4000 [06:13<1:53:12,  1.80s/it]\n",
      "  6%|████▍                                                                        | 232/4000 [06:14<1:50:03,  1.75s/it]\n",
      "  6%|████▍                                                                        | 233/4000 [06:16<1:49:24,  1.74s/it]\n",
      "  6%|████▌                                                                        | 234/4000 [06:17<1:46:43,  1.70s/it]\n",
      "  6%|████▌                                                                        | 235/4000 [06:19<1:44:54,  1.67s/it]\n",
      "  6%|████▌                                                                        | 236/4000 [06:21<1:45:28,  1.68s/it]\n",
      "  6%|████▌                                                                        | 237/4000 [06:22<1:44:46,  1.67s/it]\n",
      "  6%|████▌                                                                        | 238/4000 [06:24<1:44:31,  1.67s/it]\n",
      "  6%|████▌                                                                        | 239/4000 [06:26<1:43:32,  1.65s/it]\n",
      "  6%|████▌                                                                        | 240/4000 [06:27<1:43:08,  1.65s/it]\n",
      "  6%|████▋                                                                        | 241/4000 [06:29<1:42:14,  1.63s/it]\n",
      "  6%|████▋                                                                        | 242/4000 [06:31<1:42:13,  1.63s/it]\n",
      "  6%|████▋                                                                        | 243/4000 [06:32<1:42:52,  1.64s/it]\n",
      "  6%|████▋                                                                        | 244/4000 [06:34<1:42:29,  1.64s/it]\n",
      "  6%|████▋                                                                        | 245/4000 [06:36<1:42:26,  1.64s/it]\n",
      "  6%|████▋                                                                        | 246/4000 [06:37<1:41:58,  1.63s/it]\n",
      "  6%|████▊                                                                        | 247/4000 [06:39<1:41:42,  1.63s/it]\n",
      "  6%|████▊                                                                        | 248/4000 [06:40<1:42:34,  1.64s/it]\n",
      "  6%|████▊                                                                        | 249/4000 [06:42<1:42:23,  1.64s/it]\n",
      "  6%|████▊                                                                        | 250/4000 [06:44<1:42:18,  1.64s/it]\n",
      "  6%|████▊                                                                        | 251/4000 [06:46<1:47:12,  1.72s/it]\n",
      "  6%|████▊                                                                        | 252/4000 [06:48<1:52:21,  1.80s/it]\n",
      "  6%|████▊                                                                        | 253/4000 [06:49<1:53:35,  1.82s/it]\n",
      "  6%|████▉                                                                        | 254/4000 [06:51<1:49:22,  1.75s/it]\n",
      "  6%|████▉                                                                        | 255/4000 [06:53<1:46:37,  1.71s/it]\n",
      "  6%|████▉                                                                        | 256/4000 [06:54<1:44:41,  1.68s/it]\n",
      "  6%|████▉                                                                        | 257/4000 [06:56<1:44:04,  1.67s/it]\n",
      "  6%|████▉                                                                        | 258/4000 [06:58<1:43:32,  1.66s/it]\n",
      "  6%|████▉                                                                        | 259/4000 [06:59<1:47:27,  1.72s/it]\n",
      "  6%|█████                                                                        | 260/4000 [07:01<1:50:02,  1.77s/it]\n",
      "  7%|█████                                                                        | 261/4000 [07:03<1:51:45,  1.79s/it]\n",
      "  7%|█████                                                                        | 262/4000 [07:05<1:53:16,  1.82s/it]\n",
      "  7%|█████                                                                        | 263/4000 [07:07<1:52:43,  1.81s/it]\n",
      "  7%|█████                                                                        | 264/4000 [07:09<1:55:07,  1.85s/it]\n",
      "  7%|█████                                                                        | 265/4000 [07:11<1:57:56,  1.89s/it]\n",
      "  7%|█████                                                                        | 266/4000 [07:13<2:00:00,  1.93s/it]\n",
      "  7%|█████▏                                                                       | 267/4000 [07:15<1:59:19,  1.92s/it]\n",
      "  7%|█████▏                                                                       | 268/4000 [07:17<1:58:28,  1.90s/it]\n",
      "  7%|█████▏                                                                       | 269/4000 [07:18<1:58:43,  1.91s/it]\n",
      "  7%|█████▏                                                                       | 270/4000 [07:20<1:59:44,  1.93s/it]\n",
      "  7%|█████▏                                                                       | 271/4000 [07:22<1:59:18,  1.92s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                       | 272/4000 [07:24<1:59:02,  1.92s/it]\n",
      "  7%|█████▎                                                                       | 273/4000 [07:26<1:59:55,  1.93s/it]\n",
      "  7%|█████▎                                                                       | 274/4000 [07:28<1:59:46,  1.93s/it]\n",
      "  7%|█████▎                                                                       | 275/4000 [07:30<2:00:07,  1.93s/it]\n",
      "  7%|█████▎                                                                       | 276/4000 [07:32<1:59:41,  1.93s/it]\n",
      "  7%|█████▎                                                                       | 277/4000 [07:34<2:02:04,  1.97s/it]\n",
      "  7%|█████▎                                                                       | 278/4000 [07:36<1:57:03,  1.89s/it]\n",
      "  7%|█████▎                                                                       | 279/4000 [07:38<1:58:13,  1.91s/it]\n",
      "  7%|█████▍                                                                       | 280/4000 [07:40<1:59:44,  1.93s/it]\n",
      "  7%|█████▍                                                                       | 281/4000 [07:42<1:59:55,  1.93s/it]\n",
      "  7%|█████▍                                                                       | 282/4000 [07:43<1:58:42,  1.92s/it]\n",
      "  7%|█████▍                                                                       | 283/4000 [07:45<1:59:23,  1.93s/it]\n",
      "  7%|█████▍                                                                       | 284/4000 [07:47<1:59:33,  1.93s/it]\n",
      "  7%|█████▍                                                                       | 285/4000 [07:50<2:04:25,  2.01s/it]\n",
      "  7%|█████▌                                                                       | 286/4000 [07:52<2:11:18,  2.12s/it]\n",
      "  7%|█████▌                                                                       | 287/4000 [07:54<2:02:35,  1.98s/it]\n",
      "  7%|█████▌                                                                       | 288/4000 [07:56<2:02:09,  1.97s/it]\n",
      "  7%|█████▌                                                                       | 289/4000 [07:57<1:53:53,  1.84s/it]\n",
      "  7%|█████▌                                                                       | 290/4000 [07:59<1:57:00,  1.89s/it]\n",
      "  7%|█████▌                                                                       | 291/4000 [08:01<1:57:49,  1.91s/it]\n",
      "  7%|█████▌                                                                       | 292/4000 [08:03<1:57:38,  1.90s/it]\n",
      "  7%|█████▋                                                                       | 293/4000 [08:05<1:57:40,  1.90s/it]\n",
      "  7%|█████▋                                                                       | 294/4000 [08:07<1:57:19,  1.90s/it]\n",
      "  7%|█████▋                                                                       | 295/4000 [08:09<1:59:32,  1.94s/it]\n",
      "  7%|█████▋                                                                       | 296/4000 [08:11<1:59:30,  1.94s/it]\n",
      "  7%|█████▋                                                                       | 297/4000 [08:12<1:54:48,  1.86s/it]\n",
      "  7%|█████▋                                                                       | 298/4000 [08:14<1:50:06,  1.78s/it]\n",
      "  7%|█████▊                                                                       | 299/4000 [08:16<1:47:35,  1.74s/it]\n",
      "  8%|█████▊                                                                       | 300/4000 [08:17<1:46:43,  1.73s/it]\n",
      "  8%|█████▊                                                                       | 301/4000 [08:19<1:44:09,  1.69s/it]\n",
      "  8%|█████▊                                                                       | 302/4000 [08:20<1:41:46,  1.65s/it]\n",
      "  8%|█████▊                                                                       | 303/4000 [08:22<1:39:57,  1.62s/it]\n",
      "  8%|█████▊                                                                       | 304/4000 [08:24<1:39:12,  1.61s/it]\n",
      "  8%|█████▊                                                                       | 305/4000 [08:25<1:38:47,  1.60s/it]\n",
      "  8%|█████▉                                                                       | 306/4000 [08:27<1:39:15,  1.61s/it]\n",
      "  8%|█████▉                                                                       | 307/4000 [08:28<1:38:21,  1.60s/it]\n",
      "  8%|█████▉                                                                       | 308/4000 [08:30<1:37:43,  1.59s/it]\n",
      "  8%|█████▉                                                                       | 309/4000 [08:32<1:36:37,  1.57s/it]\n",
      "  8%|█████▉                                                                       | 310/4000 [08:33<1:36:42,  1.57s/it]\n",
      "  8%|█████▉                                                                       | 311/4000 [08:35<1:37:09,  1.58s/it]\n",
      "  8%|██████                                                                       | 312/4000 [08:36<1:38:51,  1.61s/it]\n",
      "  8%|██████                                                                       | 313/4000 [08:38<1:39:01,  1.61s/it]\n",
      "  8%|██████                                                                       | 314/4000 [08:40<1:38:02,  1.60s/it]\n",
      "  8%|██████                                                                       | 315/4000 [08:41<1:38:57,  1.61s/it]\n",
      "  8%|██████                                                                       | 316/4000 [08:43<1:38:22,  1.60s/it]\n",
      "  8%|██████                                                                       | 317/4000 [08:44<1:37:45,  1.59s/it]\n",
      "  8%|██████                                                                       | 318/4000 [08:46<1:40:33,  1.64s/it]\n",
      "  8%|██████▏                                                                      | 319/4000 [08:48<1:42:32,  1.67s/it]\n",
      "  8%|██████▏                                                                      | 320/4000 [08:50<1:46:12,  1.73s/it]\n",
      "  8%|██████▏                                                                      | 321/4000 [08:52<1:48:06,  1.76s/it]\n",
      "  8%|██████▏                                                                      | 322/4000 [08:53<1:49:07,  1.78s/it]\n",
      "  8%|██████▏                                                                      | 323/4000 [08:55<1:49:24,  1.79s/it]\n",
      "  8%|██████▏                                                                      | 324/4000 [08:57<1:50:34,  1.80s/it]\n",
      "  8%|██████▎                                                                      | 325/4000 [08:59<1:49:35,  1.79s/it]\n",
      "  8%|██████▎                                                                      | 326/4000 [09:00<1:45:11,  1.72s/it]\n",
      "  8%|██████▎                                                                      | 327/4000 [09:02<1:41:49,  1.66s/it]\n",
      "  8%|██████▎                                                                      | 328/4000 [09:03<1:39:42,  1.63s/it]\n",
      "  8%|██████▎                                                                      | 329/4000 [09:05<1:38:15,  1.61s/it]\n",
      "  8%|██████▎                                                                      | 330/4000 [09:06<1:37:21,  1.59s/it]\n",
      "  8%|██████▎                                                                      | 331/4000 [09:08<1:36:33,  1.58s/it]\n",
      "  8%|██████▍                                                                      | 332/4000 [09:10<1:36:03,  1.57s/it]\n",
      "  8%|██████▍                                                                      | 333/4000 [09:11<1:35:42,  1.57s/it]\n",
      "  8%|██████▍                                                                      | 334/4000 [09:13<1:37:34,  1.60s/it]\n",
      "  8%|██████▍                                                                      | 335/4000 [09:15<1:41:47,  1.67s/it]\n",
      "  8%|██████▍                                                                      | 336/4000 [09:16<1:42:24,  1.68s/it]\n",
      "  8%|██████▍                                                                      | 337/4000 [09:18<1:40:22,  1.64s/it]\n",
      "  8%|██████▌                                                                      | 338/4000 [09:20<1:39:19,  1.63s/it]\n",
      "  8%|██████▌                                                                      | 339/4000 [09:21<1:38:34,  1.62s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▌                                                                      | 340/4000 [09:23<1:38:19,  1.61s/it]\n",
      "  9%|██████▌                                                                      | 341/4000 [09:24<1:37:53,  1.61s/it]\n",
      "  9%|██████▌                                                                      | 342/4000 [09:26<1:37:34,  1.60s/it]\n",
      "  9%|██████▌                                                                      | 343/4000 [09:27<1:36:33,  1.58s/it]\n",
      "  9%|██████▌                                                                      | 344/4000 [09:29<1:36:52,  1.59s/it]\n",
      "  9%|██████▋                                                                      | 345/4000 [09:31<1:36:22,  1.58s/it]\n",
      "  9%|██████▋                                                                      | 346/4000 [09:32<1:36:16,  1.58s/it]\n",
      "  9%|██████▋                                                                      | 347/4000 [09:34<1:36:42,  1.59s/it]\n",
      "  9%|██████▋                                                                      | 348/4000 [09:35<1:36:56,  1.59s/it]\n",
      "  9%|██████▋                                                                      | 349/4000 [09:37<1:37:10,  1.60s/it]\n",
      "  9%|██████▋                                                                      | 350/4000 [09:39<1:36:37,  1.59s/it]\n",
      "  9%|██████▊                                                                      | 351/4000 [09:40<1:36:22,  1.58s/it]\n",
      "  9%|██████▊                                                                      | 352/4000 [09:42<1:35:49,  1.58s/it]\n",
      "  9%|██████▊                                                                      | 353/4000 [09:43<1:36:43,  1.59s/it]\n",
      "  9%|██████▊                                                                      | 354/4000 [09:45<1:36:45,  1.59s/it]\n",
      "  9%|██████▊                                                                      | 355/4000 [09:47<1:36:56,  1.60s/it]\n",
      "  9%|██████▊                                                                      | 356/4000 [09:48<1:37:58,  1.61s/it]\n",
      "  9%|██████▊                                                                      | 357/4000 [09:50<1:38:31,  1.62s/it]\n",
      "  9%|██████▉                                                                      | 358/4000 [09:52<1:42:14,  1.68s/it]\n",
      "  9%|██████▉                                                                      | 359/4000 [09:54<1:45:31,  1.74s/it]\n",
      "  9%|██████▉                                                                      | 360/4000 [09:55<1:47:23,  1.77s/it]\n",
      "  9%|██████▉                                                                      | 361/4000 [09:57<1:48:09,  1.78s/it]\n",
      "  9%|██████▉                                                                      | 362/4000 [09:59<1:49:19,  1.80s/it]\n",
      "  9%|██████▉                                                                      | 363/4000 [10:01<1:50:45,  1.83s/it]\n",
      "  9%|███████                                                                      | 364/4000 [10:03<1:50:46,  1.83s/it]\n",
      "  9%|███████                                                                      | 365/4000 [10:04<1:48:34,  1.79s/it]\n",
      "  9%|███████                                                                      | 366/4000 [10:06<1:43:21,  1.71s/it]\n",
      "  9%|███████                                                                      | 367/4000 [10:07<1:40:05,  1.65s/it]\n",
      "  9%|███████                                                                      | 368/4000 [10:09<1:38:41,  1.63s/it]\n",
      "  9%|███████                                                                      | 369/4000 [10:11<1:36:27,  1.59s/it]\n",
      "  9%|███████                                                                      | 370/4000 [10:12<1:33:46,  1.55s/it]\n",
      "  9%|███████▏                                                                     | 371/4000 [10:13<1:31:56,  1.52s/it]\n",
      "  9%|███████▏                                                                     | 372/4000 [10:15<1:31:30,  1.51s/it]\n",
      "  9%|███████▏                                                                     | 373/4000 [10:16<1:31:40,  1.52s/it]\n",
      "  9%|███████▏                                                                     | 374/4000 [10:18<1:36:55,  1.60s/it]\n",
      "  9%|███████▏                                                                     | 375/4000 [10:20<1:42:27,  1.70s/it]\n",
      "  9%|███████▏                                                                     | 376/4000 [10:22<1:42:48,  1.70s/it]\n",
      "  9%|███████▎                                                                     | 377/4000 [10:24<1:42:20,  1.69s/it]\n",
      "  9%|███████▎                                                                     | 378/4000 [10:25<1:39:35,  1.65s/it]\n",
      "  9%|███████▎                                                                     | 379/4000 [10:27<1:37:41,  1.62s/it]\n",
      " 10%|███████▎                                                                     | 380/4000 [10:28<1:37:22,  1.61s/it]\n",
      " 10%|███████▎                                                                     | 381/4000 [10:30<1:37:03,  1.61s/it]\n",
      " 10%|███████▎                                                                     | 382/4000 [10:31<1:36:03,  1.59s/it]\n",
      " 10%|███████▎                                                                     | 383/4000 [10:33<1:35:52,  1.59s/it]\n",
      " 10%|███████▍                                                                     | 384/4000 [10:35<1:35:32,  1.59s/it]\n",
      " 10%|███████▍                                                                     | 385/4000 [10:36<1:35:37,  1.59s/it]\n",
      " 10%|███████▍                                                                     | 386/4000 [10:38<1:34:52,  1.58s/it]\n",
      " 10%|███████▍                                                                     | 387/4000 [10:39<1:34:33,  1.57s/it]\n",
      " 10%|███████▍                                                                     | 388/4000 [10:41<1:39:19,  1.65s/it]\n",
      " 10%|███████▍                                                                     | 389/4000 [10:43<1:44:05,  1.73s/it]\n",
      " 10%|███████▌                                                                     | 390/4000 [10:45<1:45:38,  1.76s/it]\n",
      " 10%|███████▌                                                                     | 391/4000 [10:47<1:44:56,  1.74s/it]\n",
      " 10%|███████▌                                                                     | 392/4000 [10:48<1:41:26,  1.69s/it]\n",
      " 10%|███████▌                                                                     | 393/4000 [10:50<1:39:34,  1.66s/it]\n",
      " 10%|███████▌                                                                     | 394/4000 [10:51<1:37:46,  1.63s/it]\n",
      " 10%|███████▌                                                                     | 395/4000 [10:53<1:41:15,  1.69s/it]\n",
      " 10%|███████▌                                                                     | 396/4000 [10:55<1:39:22,  1.65s/it]\n",
      " 10%|███████▋                                                                     | 397/4000 [10:56<1:39:45,  1.66s/it]\n",
      " 10%|███████▋                                                                     | 398/4000 [10:58<1:38:43,  1.64s/it]\n",
      " 10%|███████▋                                                                     | 399/4000 [11:00<1:37:13,  1.62s/it]\n",
      " 10%|███████▋                                                                     | 400/4000 [11:01<1:35:48,  1.60s/it]\n",
      " 10%|███████▋                                                                     | 401/4000 [11:03<1:34:45,  1.58s/it]\n",
      " 10%|███████▋                                                                     | 402/4000 [11:04<1:34:34,  1.58s/it]\n",
      " 10%|███████▊                                                                     | 403/4000 [11:06<1:34:48,  1.58s/it]\n",
      " 10%|███████▊                                                                     | 404/4000 [11:08<1:39:09,  1.65s/it]\n",
      " 10%|███████▊                                                                     | 405/4000 [11:09<1:41:33,  1.70s/it]\n",
      " 10%|███████▊                                                                     | 406/4000 [11:11<1:41:54,  1.70s/it]\n",
      " 10%|███████▊                                                                     | 407/4000 [11:13<1:45:46,  1.77s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                     | 408/4000 [11:15<1:49:41,  1.83s/it]\n",
      " 10%|███████▊                                                                     | 409/4000 [11:17<1:49:47,  1.83s/it]\n",
      " 10%|███████▉                                                                     | 410/4000 [11:19<1:50:07,  1.84s/it]\n",
      " 10%|███████▉                                                                     | 411/4000 [11:20<1:49:22,  1.83s/it]\n",
      " 10%|███████▉                                                                     | 412/4000 [11:22<1:50:35,  1.85s/it]\n",
      " 10%|███████▉                                                                     | 413/4000 [11:24<1:49:43,  1.84s/it]\n",
      " 10%|███████▉                                                                     | 414/4000 [11:26<1:48:17,  1.81s/it]\n",
      " 10%|███████▉                                                                     | 415/4000 [11:28<1:44:23,  1.75s/it]\n",
      " 10%|████████                                                                     | 416/4000 [11:29<1:46:22,  1.78s/it]\n",
      " 10%|████████                                                                     | 417/4000 [11:31<1:49:34,  1.83s/it]\n",
      " 10%|████████                                                                     | 418/4000 [11:33<1:47:44,  1.80s/it]\n",
      " 10%|████████                                                                     | 419/4000 [11:35<1:43:39,  1.74s/it]\n",
      " 10%|████████                                                                     | 420/4000 [11:36<1:42:40,  1.72s/it]\n",
      " 11%|████████                                                                     | 421/4000 [11:38<1:45:28,  1.77s/it]\n",
      " 11%|████████                                                                     | 422/4000 [11:40<1:48:47,  1.82s/it]\n",
      " 11%|████████▏                                                                    | 423/4000 [11:42<1:48:05,  1.81s/it]\n",
      " 11%|████████▏                                                                    | 424/4000 [11:44<1:49:32,  1.84s/it]\n",
      " 11%|████████▏                                                                    | 425/4000 [11:45<1:45:29,  1.77s/it]\n",
      " 11%|████████▏                                                                    | 426/4000 [11:47<1:45:34,  1.77s/it]\n",
      " 11%|████████▏                                                                    | 427/4000 [11:49<1:47:12,  1.80s/it]\n",
      " 11%|████████▏                                                                    | 428/4000 [11:51<1:48:17,  1.82s/it]\n",
      " 11%|████████▎                                                                    | 429/4000 [11:53<1:48:39,  1.83s/it]\n",
      " 11%|████████▎                                                                    | 430/4000 [11:55<1:45:56,  1.78s/it]\n",
      " 11%|████████▎                                                                    | 431/4000 [11:56<1:41:35,  1.71s/it]\n",
      " 11%|████████▎                                                                    | 432/4000 [11:58<1:38:32,  1.66s/it]\n",
      " 11%|████████▎                                                                    | 433/4000 [11:59<1:36:25,  1.62s/it]\n",
      " 11%|████████▎                                                                    | 434/4000 [12:01<1:36:02,  1.62s/it]\n",
      " 11%|████████▎                                                                    | 435/4000 [12:03<1:39:59,  1.68s/it]\n",
      " 11%|████████▍                                                                    | 436/4000 [12:04<1:40:36,  1.69s/it]\n",
      " 11%|████████▍                                                                    | 437/4000 [12:06<1:38:19,  1.66s/it]\n",
      " 11%|████████▍                                                                    | 438/4000 [12:07<1:36:48,  1.63s/it]\n",
      " 11%|████████▍                                                                    | 439/4000 [12:09<1:36:42,  1.63s/it]\n",
      " 11%|████████▍                                                                    | 440/4000 [12:11<1:40:28,  1.69s/it]\n",
      " 11%|████████▍                                                                    | 441/4000 [12:13<1:44:39,  1.76s/it]\n",
      " 11%|████████▌                                                                    | 442/4000 [12:14<1:42:03,  1.72s/it]\n",
      " 11%|████████▌                                                                    | 443/4000 [12:16<1:39:47,  1.68s/it]\n",
      " 11%|████████▌                                                                    | 444/4000 [12:18<1:38:21,  1.66s/it]\n",
      " 11%|████████▌                                                                    | 445/4000 [12:19<1:37:16,  1.64s/it]\n",
      " 11%|████████▌                                                                    | 446/4000 [12:21<1:35:47,  1.62s/it]\n",
      " 11%|████████▌                                                                    | 447/4000 [12:22<1:36:17,  1.63s/it]\n",
      " 11%|████████▌                                                                    | 448/4000 [12:24<1:35:48,  1.62s/it]\n",
      " 11%|████████▋                                                                    | 449/4000 [12:26<1:35:22,  1.61s/it]\n",
      " 11%|████████▋                                                                    | 450/4000 [12:27<1:39:00,  1.67s/it]\n",
      " 11%|████████▋                                                                    | 451/4000 [12:29<1:40:14,  1.69s/it]\n",
      " 11%|████████▋                                                                    | 452/4000 [12:31<1:37:35,  1.65s/it]\n",
      " 11%|████████▋                                                                    | 453/4000 [12:32<1:35:47,  1.62s/it]\n",
      " 11%|████████▋                                                                    | 454/4000 [12:34<1:34:10,  1.59s/it]\n",
      " 11%|████████▊                                                                    | 455/4000 [12:35<1:33:08,  1.58s/it]\n",
      " 11%|████████▊                                                                    | 456/4000 [12:37<1:32:15,  1.56s/it]\n",
      " 11%|████████▊                                                                    | 457/4000 [12:38<1:32:11,  1.56s/it]\n",
      " 11%|████████▊                                                                    | 458/4000 [12:40<1:32:18,  1.56s/it]\n",
      " 11%|████████▊                                                                    | 459/4000 [12:42<1:31:46,  1.56s/it]\n",
      " 12%|████████▊                                                                    | 460/4000 [12:44<1:40:03,  1.70s/it]\n",
      " 12%|████████▊                                                                    | 461/4000 [12:46<1:44:57,  1.78s/it]\n",
      " 12%|████████▉                                                                    | 462/4000 [12:47<1:46:14,  1.80s/it]\n",
      " 12%|████████▉                                                                    | 463/4000 [12:49<1:46:42,  1.81s/it]\n",
      " 12%|████████▉                                                                    | 464/4000 [12:51<1:48:51,  1.85s/it]\n",
      " 12%|████████▉                                                                    | 465/4000 [12:53<1:48:45,  1.85s/it]\n",
      " 12%|████████▉                                                                    | 466/4000 [12:55<1:48:34,  1.84s/it]\n",
      " 12%|████████▉                                                                    | 467/4000 [12:57<1:50:31,  1.88s/it]\n",
      " 12%|█████████                                                                    | 468/4000 [12:59<1:49:10,  1.85s/it]\n",
      " 12%|█████████                                                                    | 469/4000 [13:01<1:50:09,  1.87s/it]\n",
      " 12%|█████████                                                                    | 470/4000 [13:03<1:54:49,  1.95s/it]\n",
      " 12%|█████████                                                                    | 471/4000 [13:04<1:50:07,  1.87s/it]\n",
      " 12%|█████████                                                                    | 472/4000 [13:06<1:48:23,  1.84s/it]\n",
      " 12%|█████████                                                                    | 473/4000 [13:08<1:42:37,  1.75s/it]\n",
      " 12%|█████████                                                                    | 474/4000 [13:09<1:37:50,  1.66s/it]\n",
      " 12%|█████████▏                                                                   | 475/4000 [13:11<1:37:10,  1.65s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▏                                                                   | 476/4000 [13:12<1:37:20,  1.66s/it]\n",
      " 12%|█████████▏                                                                   | 477/4000 [13:14<1:36:51,  1.65s/it]\n",
      " 12%|█████████▏                                                                   | 478/4000 [13:16<1:34:46,  1.61s/it]\n",
      " 12%|█████████▏                                                                   | 479/4000 [13:17<1:33:49,  1.60s/it]\n",
      " 12%|█████████▏                                                                   | 480/4000 [13:19<1:33:29,  1.59s/it]\n",
      " 12%|█████████▎                                                                   | 481/4000 [13:20<1:31:29,  1.56s/it]\n",
      " 12%|█████████▎                                                                   | 482/4000 [13:22<1:31:32,  1.56s/it]\n",
      " 12%|█████████▎                                                                   | 483/4000 [13:23<1:30:51,  1.55s/it]\n",
      " 12%|█████████▎                                                                   | 484/4000 [13:25<1:30:25,  1.54s/it]\n",
      " 12%|█████████▎                                                                   | 485/4000 [13:26<1:30:03,  1.54s/it]\n",
      " 12%|█████████▎                                                                   | 486/4000 [13:28<1:29:31,  1.53s/it]\n",
      " 12%|█████████▎                                                                   | 487/4000 [13:29<1:29:20,  1.53s/it]\n",
      " 12%|█████████▍                                                                   | 488/4000 [13:31<1:29:13,  1.52s/it]\n",
      " 12%|█████████▍                                                                   | 489/4000 [13:32<1:28:04,  1.51s/it]\n",
      " 12%|█████████▍                                                                   | 490/4000 [13:34<1:28:27,  1.51s/it]\n",
      " 12%|█████████▍                                                                   | 491/4000 [13:35<1:29:25,  1.53s/it]\n",
      " 12%|█████████▍                                                                   | 492/4000 [13:37<1:29:43,  1.53s/it]\n",
      " 12%|█████████▍                                                                   | 493/4000 [13:39<1:30:33,  1.55s/it]\n",
      " 12%|█████████▌                                                                   | 494/4000 [13:40<1:31:26,  1.56s/it]\n",
      " 12%|█████████▌                                                                   | 495/4000 [13:42<1:29:38,  1.53s/it]\n",
      " 12%|█████████▌                                                                   | 496/4000 [13:43<1:27:52,  1.50s/it]\n",
      " 12%|█████████▌                                                                   | 497/4000 [13:45<1:29:39,  1.54s/it]\n",
      " 12%|█████████▌                                                                   | 498/4000 [13:46<1:29:39,  1.54s/it]\n",
      " 12%|█████████▌                                                                   | 499/4000 [13:48<1:29:28,  1.53s/it]\n",
      " 12%|█████████▋                                                                   | 500/4000 [13:50<1:33:56,  1.61s/it]\n",
      " 13%|█████████▋                                                                   | 501/4000 [13:51<1:33:01,  1.60s/it]\n",
      " 13%|█████████▋                                                                   | 502/4000 [13:53<1:30:19,  1.55s/it]\n",
      " 13%|█████████▋                                                                   | 503/4000 [13:54<1:28:00,  1.51s/it]\n",
      " 13%|█████████▋                                                                   | 504/4000 [13:55<1:26:34,  1.49s/it]\n",
      " 13%|█████████▋                                                                   | 505/4000 [13:57<1:28:30,  1.52s/it]\n",
      " 13%|█████████▋                                                                   | 506/4000 [13:59<1:30:00,  1.55s/it]\n",
      " 13%|█████████▊                                                                   | 507/4000 [14:00<1:28:02,  1.51s/it]\n",
      " 13%|█████████▊                                                                   | 508/4000 [14:01<1:26:57,  1.49s/it]\n",
      " 13%|█████████▊                                                                   | 509/4000 [14:03<1:26:06,  1.48s/it]\n",
      " 13%|█████████▊                                                                   | 510/4000 [14:04<1:26:20,  1.48s/it]\n",
      " 13%|█████████▊                                                                   | 511/4000 [14:06<1:25:34,  1.47s/it]\n",
      " 13%|█████████▊                                                                   | 512/4000 [14:07<1:25:41,  1.47s/it]\n",
      " 13%|█████████▉                                                                   | 513/4000 [14:09<1:25:47,  1.48s/it]\n",
      " 13%|█████████▉                                                                   | 514/4000 [14:10<1:28:16,  1.52s/it]\n",
      " 13%|█████████▉                                                                   | 515/4000 [14:12<1:31:06,  1.57s/it]\n",
      " 13%|█████████▉                                                                   | 516/4000 [14:14<1:28:57,  1.53s/it]\n",
      " 13%|█████████▉                                                                   | 517/4000 [14:15<1:27:33,  1.51s/it]\n",
      " 13%|█████████▉                                                                   | 518/4000 [14:17<1:27:35,  1.51s/it]\n",
      " 13%|█████████▉                                                                   | 519/4000 [14:18<1:27:57,  1.52s/it]\n",
      " 13%|██████████                                                                   | 520/4000 [14:20<1:28:31,  1.53s/it]\n",
      " 13%|██████████                                                                   | 521/4000 [14:21<1:27:16,  1.51s/it]\n",
      " 13%|██████████                                                                   | 522/4000 [14:23<1:27:42,  1.51s/it]\n",
      " 13%|██████████                                                                   | 523/4000 [14:24<1:29:27,  1.54s/it]\n",
      " 13%|██████████                                                                   | 524/4000 [14:26<1:30:02,  1.55s/it]\n",
      " 13%|██████████                                                                   | 525/4000 [14:27<1:31:26,  1.58s/it]\n",
      " 13%|██████████▏                                                                  | 526/4000 [14:29<1:30:34,  1.56s/it]\n",
      " 13%|██████████▏                                                                  | 527/4000 [14:31<1:30:10,  1.56s/it]\n",
      " 13%|██████████▏                                                                  | 528/4000 [14:32<1:28:18,  1.53s/it]\n",
      " 13%|██████████▏                                                                  | 529/4000 [14:34<1:28:34,  1.53s/it]\n",
      " 13%|██████████▏                                                                  | 530/4000 [14:35<1:28:50,  1.54s/it]\n",
      " 13%|██████████▏                                                                  | 531/4000 [14:37<1:31:10,  1.58s/it]\n",
      " 13%|██████████▏                                                                  | 532/4000 [14:38<1:28:40,  1.53s/it]\n",
      " 13%|██████████▎                                                                  | 533/4000 [14:40<1:27:13,  1.51s/it]\n",
      " 13%|██████████▎                                                                  | 534/4000 [14:41<1:27:04,  1.51s/it]\n",
      " 13%|██████████▎                                                                  | 535/4000 [14:43<1:27:19,  1.51s/it]\n",
      " 13%|██████████▎                                                                  | 536/4000 [14:44<1:27:28,  1.52s/it]\n",
      " 13%|██████████▎                                                                  | 537/4000 [14:46<1:26:57,  1.51s/it]\n",
      " 13%|██████████▎                                                                  | 538/4000 [14:47<1:26:20,  1.50s/it]\n",
      " 13%|██████████▍                                                                  | 539/4000 [14:49<1:25:01,  1.47s/it]\n",
      " 14%|██████████▍                                                                  | 540/4000 [14:50<1:23:57,  1.46s/it]\n",
      " 14%|██████████▍                                                                  | 541/4000 [14:51<1:23:22,  1.45s/it]\n",
      " 14%|██████████▍                                                                  | 542/4000 [14:53<1:23:03,  1.44s/it]\n",
      " 14%|██████████▍                                                                  | 543/4000 [14:54<1:22:45,  1.44s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▍                                                                  | 544/4000 [14:56<1:22:58,  1.44s/it]\n",
      " 14%|██████████▍                                                                  | 545/4000 [14:57<1:22:39,  1.44s/it]\n",
      " 14%|██████████▌                                                                  | 546/4000 [14:59<1:22:31,  1.43s/it]\n",
      " 14%|██████████▌                                                                  | 547/4000 [15:00<1:22:18,  1.43s/it]\n",
      " 14%|██████████▌                                                                  | 548/4000 [15:01<1:23:09,  1.45s/it]\n",
      " 14%|██████████▌                                                                  | 549/4000 [15:03<1:24:51,  1.48s/it]\n",
      " 14%|██████████▌                                                                  | 550/4000 [15:05<1:27:31,  1.52s/it]\n",
      " 14%|██████████▌                                                                  | 551/4000 [15:06<1:28:47,  1.54s/it]\n",
      " 14%|██████████▋                                                                  | 552/4000 [15:08<1:27:36,  1.52s/it]\n",
      " 14%|██████████▋                                                                  | 553/4000 [15:09<1:26:37,  1.51s/it]\n",
      " 14%|██████████▋                                                                  | 554/4000 [15:11<1:25:34,  1.49s/it]\n",
      " 14%|██████████▋                                                                  | 555/4000 [15:12<1:24:38,  1.47s/it]\n",
      " 14%|██████████▋                                                                  | 556/4000 [15:14<1:26:05,  1.50s/it]\n",
      " 14%|██████████▋                                                                  | 557/4000 [15:15<1:27:02,  1.52s/it]\n",
      " 14%|██████████▋                                                                  | 558/4000 [15:17<1:27:32,  1.53s/it]\n",
      " 14%|██████████▊                                                                  | 559/4000 [15:18<1:29:58,  1.57s/it]\n",
      " 14%|██████████▊                                                                  | 560/4000 [15:21<1:39:49,  1.74s/it]\n",
      " 14%|██████████▊                                                                  | 561/4000 [15:23<1:47:48,  1.88s/it]\n",
      " 14%|██████████▊                                                                  | 562/4000 [15:24<1:43:41,  1.81s/it]\n",
      " 14%|██████████▊                                                                  | 563/4000 [15:26<1:41:10,  1.77s/it]\n",
      " 14%|██████████▊                                                                  | 564/4000 [15:28<1:38:39,  1.72s/it]\n",
      " 14%|██████████▉                                                                  | 565/4000 [15:29<1:37:43,  1.71s/it]\n",
      " 14%|██████████▉                                                                  | 566/4000 [15:31<1:34:46,  1.66s/it]\n",
      " 14%|██████████▉                                                                  | 567/4000 [15:32<1:32:30,  1.62s/it]\n",
      " 14%|██████████▉                                                                  | 568/4000 [15:34<1:31:29,  1.60s/it]\n",
      " 14%|██████████▉                                                                  | 569/4000 [15:36<1:30:29,  1.58s/it]\n",
      " 14%|██████████▉                                                                  | 570/4000 [15:37<1:29:56,  1.57s/it]\n",
      " 14%|██████████▉                                                                  | 571/4000 [15:39<1:30:24,  1.58s/it]\n",
      " 14%|███████████                                                                  | 572/4000 [15:40<1:34:23,  1.65s/it]\n",
      " 14%|███████████                                                                  | 573/4000 [15:42<1:34:01,  1.65s/it]\n",
      " 14%|███████████                                                                  | 574/4000 [15:44<1:34:20,  1.65s/it]\n",
      " 14%|███████████                                                                  | 575/4000 [15:45<1:32:19,  1.62s/it]\n",
      " 14%|███████████                                                                  | 576/4000 [15:47<1:31:02,  1.60s/it]\n",
      " 14%|███████████                                                                  | 577/4000 [15:48<1:29:45,  1.57s/it]\n",
      " 14%|███████████▏                                                                 | 578/4000 [15:50<1:29:00,  1.56s/it]\n",
      " 14%|███████████▏                                                                 | 579/4000 [15:51<1:29:01,  1.56s/it]\n",
      " 14%|███████████▏                                                                 | 580/4000 [15:53<1:28:27,  1.55s/it]\n",
      " 15%|███████████▏                                                                 | 581/4000 [15:55<1:28:36,  1.55s/it]\n",
      " 15%|███████████▏                                                                 | 582/4000 [15:56<1:29:11,  1.57s/it]\n",
      " 15%|███████████▏                                                                 | 583/4000 [15:58<1:32:21,  1.62s/it]\n",
      " 15%|███████████▏                                                                 | 584/4000 [16:00<1:43:35,  1.82s/it]\n",
      " 15%|███████████▎                                                                 | 585/4000 [16:02<1:45:27,  1.85s/it]\n",
      " 15%|███████████▎                                                                 | 586/4000 [16:04<1:45:41,  1.86s/it]\n",
      " 15%|███████████▎                                                                 | 587/4000 [16:06<1:45:49,  1.86s/it]\n",
      " 15%|███████████▎                                                                 | 588/4000 [16:08<1:45:17,  1.85s/it]\n",
      " 15%|███████████▎                                                                 | 589/4000 [16:10<1:46:41,  1.88s/it]\n",
      " 15%|███████████▎                                                                 | 590/4000 [16:12<1:50:24,  1.94s/it]\n",
      " 15%|███████████▍                                                                 | 591/4000 [16:14<1:52:07,  1.97s/it]\n",
      " 15%|███████████▍                                                                 | 592/4000 [16:15<1:45:56,  1.87s/it]\n",
      " 15%|███████████▍                                                                 | 593/4000 [16:17<1:41:19,  1.78s/it]\n",
      " 15%|███████████▍                                                                 | 594/4000 [16:19<1:41:22,  1.79s/it]\n",
      " 15%|███████████▍                                                                 | 595/4000 [16:21<1:46:25,  1.88s/it]\n",
      " 15%|███████████▍                                                                 | 596/4000 [16:23<1:44:58,  1.85s/it]\n",
      " 15%|███████████▍                                                                 | 597/4000 [16:24<1:43:30,  1.83s/it]\n",
      " 15%|███████████▌                                                                 | 598/4000 [16:26<1:40:41,  1.78s/it]\n",
      " 15%|███████████▌                                                                 | 599/4000 [16:28<1:37:33,  1.72s/it]\n",
      " 15%|███████████▌                                                                 | 600/4000 [16:29<1:35:03,  1.68s/it]\n",
      " 15%|███████████▌                                                                 | 601/4000 [16:31<1:34:08,  1.66s/it]\n",
      " 15%|███████████▌                                                                 | 602/4000 [16:32<1:32:54,  1.64s/it]\n",
      " 15%|███████████▌                                                                 | 603/4000 [16:34<1:31:29,  1.62s/it]\n",
      " 15%|███████████▋                                                                 | 604/4000 [16:36<1:32:43,  1.64s/it]\n",
      " 15%|███████████▋                                                                 | 605/4000 [16:37<1:31:00,  1.61s/it]\n",
      " 15%|███████████▋                                                                 | 606/4000 [16:39<1:30:38,  1.60s/it]\n",
      " 15%|███████████▋                                                                 | 607/4000 [16:40<1:31:11,  1.61s/it]\n",
      " 15%|███████████▋                                                                 | 608/4000 [16:42<1:30:23,  1.60s/it]\n",
      " 15%|███████████▋                                                                 | 609/4000 [16:44<1:30:49,  1.61s/it]\n",
      " 15%|███████████▋                                                                 | 610/4000 [16:45<1:31:46,  1.62s/it]\n",
      " 15%|███████████▊                                                                 | 611/4000 [16:47<1:31:29,  1.62s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▊                                                                 | 612/4000 [16:49<1:32:36,  1.64s/it]\n",
      " 15%|███████████▊                                                                 | 613/4000 [16:51<1:37:16,  1.72s/it]\n",
      " 15%|███████████▊                                                                 | 614/4000 [16:52<1:38:40,  1.75s/it]\n",
      " 15%|███████████▊                                                                 | 615/4000 [16:54<1:35:56,  1.70s/it]\n",
      " 15%|███████████▊                                                                 | 616/4000 [16:56<1:35:55,  1.70s/it]\n",
      " 15%|███████████▉                                                                 | 617/4000 [16:57<1:33:41,  1.66s/it]\n",
      " 15%|███████████▉                                                                 | 618/4000 [16:59<1:33:02,  1.65s/it]\n",
      " 15%|███████████▉                                                                 | 619/4000 [17:00<1:31:31,  1.62s/it]\n",
      " 16%|███████████▉                                                                 | 620/4000 [17:02<1:30:17,  1.60s/it]\n",
      " 16%|███████████▉                                                                 | 621/4000 [17:03<1:29:25,  1.59s/it]\n",
      " 16%|███████████▉                                                                 | 622/4000 [17:05<1:28:25,  1.57s/it]\n",
      " 16%|███████████▉                                                                 | 623/4000 [17:07<1:28:28,  1.57s/it]\n",
      " 16%|████████████                                                                 | 624/4000 [17:08<1:28:05,  1.57s/it]\n",
      " 16%|████████████                                                                 | 625/4000 [17:10<1:27:27,  1.55s/it]\n",
      " 16%|████████████                                                                 | 626/4000 [17:11<1:27:49,  1.56s/it]\n",
      " 16%|████████████                                                                 | 627/4000 [17:13<1:28:59,  1.58s/it]\n",
      " 16%|████████████                                                                 | 628/4000 [17:14<1:29:03,  1.58s/it]\n",
      " 16%|████████████                                                                 | 629/4000 [17:16<1:28:02,  1.57s/it]\n",
      " 16%|████████████▏                                                                | 630/4000 [17:18<1:27:46,  1.56s/it]\n",
      " 16%|████████████▏                                                                | 631/4000 [17:19<1:27:23,  1.56s/it]\n",
      " 16%|████████████▏                                                                | 632/4000 [17:21<1:26:57,  1.55s/it]\n",
      " 16%|████████████▏                                                                | 633/4000 [17:22<1:27:17,  1.56s/it]\n",
      " 16%|████████████▏                                                                | 634/4000 [17:24<1:27:30,  1.56s/it]\n",
      " 16%|████████████▏                                                                | 635/4000 [17:25<1:26:58,  1.55s/it]\n",
      " 16%|████████████▏                                                                | 636/4000 [17:27<1:30:59,  1.62s/it]\n",
      " 16%|████████████▎                                                                | 637/4000 [17:29<1:29:40,  1.60s/it]\n",
      " 16%|████████████▎                                                                | 638/4000 [17:30<1:28:42,  1.58s/it]\n",
      " 16%|████████████▎                                                                | 639/4000 [17:32<1:29:12,  1.59s/it]\n",
      " 16%|████████████▎                                                                | 640/4000 [17:33<1:28:57,  1.59s/it]\n",
      " 16%|████████████▎                                                                | 641/4000 [17:35<1:28:20,  1.58s/it]\n",
      " 16%|████████████▎                                                                | 642/4000 [17:37<1:28:10,  1.58s/it]\n",
      " 16%|████████████▍                                                                | 643/4000 [17:38<1:26:56,  1.55s/it]\n",
      " 16%|████████████▍                                                                | 644/4000 [17:40<1:26:58,  1.55s/it]\n",
      " 16%|████████████▍                                                                | 645/4000 [17:41<1:27:51,  1.57s/it]\n",
      " 16%|████████████▍                                                                | 646/4000 [17:43<1:30:12,  1.61s/it]\n",
      " 16%|████████████▍                                                                | 647/4000 [17:45<1:31:36,  1.64s/it]\n",
      " 16%|████████████▍                                                                | 648/4000 [17:46<1:29:37,  1.60s/it]\n",
      " 16%|████████████▍                                                                | 649/4000 [17:48<1:27:45,  1.57s/it]\n",
      " 16%|████████████▌                                                                | 650/4000 [17:49<1:27:12,  1.56s/it]\n",
      " 16%|████████████▌                                                                | 651/4000 [17:51<1:26:35,  1.55s/it]\n",
      " 16%|████████████▌                                                                | 652/4000 [17:52<1:25:48,  1.54s/it]\n",
      " 16%|████████████▌                                                                | 653/4000 [17:54<1:25:49,  1.54s/it]\n",
      " 16%|████████████▌                                                                | 654/4000 [17:55<1:25:44,  1.54s/it]\n",
      " 16%|████████████▌                                                                | 655/4000 [17:57<1:25:33,  1.53s/it]\n",
      " 16%|████████████▋                                                                | 656/4000 [17:58<1:25:47,  1.54s/it]\n",
      " 16%|████████████▋                                                                | 657/4000 [18:00<1:25:49,  1.54s/it]\n",
      " 16%|████████████▋                                                                | 658/4000 [18:01<1:25:48,  1.54s/it]\n",
      " 16%|████████████▋                                                                | 659/4000 [18:03<1:25:14,  1.53s/it]\n",
      " 16%|████████████▋                                                                | 660/4000 [18:04<1:24:39,  1.52s/it]\n",
      " 17%|████████████▋                                                                | 661/4000 [18:06<1:25:10,  1.53s/it]\n",
      " 17%|████████████▋                                                                | 662/4000 [18:08<1:25:13,  1.53s/it]\n",
      " 17%|████████████▊                                                                | 663/4000 [18:09<1:26:10,  1.55s/it]\n",
      " 17%|████████████▊                                                                | 664/4000 [18:11<1:25:59,  1.55s/it]\n",
      " 17%|████████████▊                                                                | 665/4000 [18:12<1:25:56,  1.55s/it]\n",
      " 17%|████████████▊                                                                | 666/4000 [18:14<1:26:17,  1.55s/it]\n",
      " 17%|████████████▊                                                                | 667/4000 [18:15<1:25:45,  1.54s/it]\n",
      " 17%|████████████▊                                                                | 668/4000 [18:17<1:25:27,  1.54s/it]\n",
      " 17%|████████████▉                                                                | 669/4000 [18:18<1:25:28,  1.54s/it]\n",
      " 17%|████████████▉                                                                | 670/4000 [18:20<1:25:23,  1.54s/it]\n",
      " 17%|████████████▉                                                                | 671/4000 [18:21<1:25:42,  1.54s/it]\n",
      " 17%|████████████▉                                                                | 672/4000 [18:23<1:26:33,  1.56s/it]\n",
      " 17%|████████████▉                                                                | 673/4000 [18:25<1:26:02,  1.55s/it]\n",
      " 17%|████████████▉                                                                | 674/4000 [18:26<1:26:59,  1.57s/it]\n",
      " 17%|████████████▉                                                                | 675/4000 [18:28<1:32:00,  1.66s/it]\n",
      " 17%|█████████████                                                                | 676/4000 [18:30<1:30:33,  1.63s/it]\n",
      " 17%|█████████████                                                                | 677/4000 [18:31<1:29:06,  1.61s/it]\n",
      " 17%|█████████████                                                                | 678/4000 [18:33<1:27:26,  1.58s/it]\n",
      " 17%|█████████████                                                                | 679/4000 [18:34<1:26:49,  1.57s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████                                                                | 680/4000 [18:36<1:26:00,  1.55s/it]\n",
      " 17%|█████████████                                                                | 681/4000 [18:37<1:25:31,  1.55s/it]\n",
      " 17%|█████████████▏                                                               | 682/4000 [18:39<1:24:57,  1.54s/it]\n",
      " 17%|█████████████▏                                                               | 683/4000 [18:40<1:25:39,  1.55s/it]\n",
      " 17%|█████████████▏                                                               | 684/4000 [18:42<1:24:53,  1.54s/it]\n",
      " 17%|█████████████▏                                                               | 685/4000 [18:43<1:24:23,  1.53s/it]\n",
      " 17%|█████████████▏                                                               | 686/4000 [18:45<1:24:10,  1.52s/it]\n",
      " 17%|█████████████▏                                                               | 687/4000 [18:46<1:24:27,  1.53s/it]\n",
      " 17%|█████████████▏                                                               | 688/4000 [18:48<1:27:16,  1.58s/it]\n",
      " 17%|█████████████▎                                                               | 689/4000 [18:50<1:27:39,  1.59s/it]\n",
      " 17%|█████████████▎                                                               | 690/4000 [18:51<1:26:30,  1.57s/it]\n",
      " 17%|█████████████▎                                                               | 691/4000 [18:53<1:26:47,  1.57s/it]\n",
      " 17%|█████████████▎                                                               | 692/4000 [18:54<1:26:45,  1.57s/it]\n",
      " 17%|█████████████▎                                                               | 693/4000 [18:56<1:28:46,  1.61s/it]\n",
      " 17%|█████████████▎                                                               | 694/4000 [18:58<1:30:27,  1.64s/it]\n",
      " 17%|█████████████▍                                                               | 695/4000 [19:00<1:31:18,  1.66s/it]\n",
      " 17%|█████████████▍                                                               | 696/4000 [19:01<1:29:51,  1.63s/it]\n",
      " 17%|█████████████▍                                                               | 697/4000 [19:03<1:31:50,  1.67s/it]\n",
      " 17%|█████████████▍                                                               | 698/4000 [19:04<1:31:02,  1.65s/it]\n",
      " 17%|█████████████▍                                                               | 699/4000 [19:06<1:30:20,  1.64s/it]\n",
      " 18%|█████████████▍                                                               | 700/4000 [19:08<1:30:24,  1.64s/it]\n",
      " 18%|█████████████▍                                                               | 701/4000 [19:09<1:29:08,  1.62s/it]\n",
      " 18%|█████████████▌                                                               | 702/4000 [19:11<1:28:58,  1.62s/it]\n",
      " 18%|█████████████▌                                                               | 703/4000 [19:13<1:28:18,  1.61s/it]\n",
      " 18%|█████████████▌                                                               | 704/4000 [19:14<1:28:04,  1.60s/it]\n",
      " 18%|█████████████▌                                                               | 705/4000 [19:16<1:28:27,  1.61s/it]\n",
      " 18%|█████████████▌                                                               | 706/4000 [19:17<1:28:23,  1.61s/it]\n",
      " 18%|█████████████▌                                                               | 707/4000 [19:19<1:27:05,  1.59s/it]\n",
      " 18%|█████████████▋                                                               | 708/4000 [19:20<1:26:24,  1.57s/it]\n",
      " 18%|█████████████▋                                                               | 709/4000 [19:22<1:25:38,  1.56s/it]\n",
      " 18%|█████████████▋                                                               | 710/4000 [19:23<1:25:22,  1.56s/it]\n",
      " 18%|█████████████▋                                                               | 711/4000 [19:25<1:24:53,  1.55s/it]\n",
      " 18%|█████████████▋                                                               | 712/4000 [19:27<1:24:49,  1.55s/it]\n",
      " 18%|█████████████▋                                                               | 713/4000 [19:28<1:24:31,  1.54s/it]\n",
      " 18%|█████████████▋                                                               | 714/4000 [19:30<1:24:22,  1.54s/it]\n",
      " 18%|█████████████▊                                                               | 715/4000 [19:31<1:24:33,  1.54s/it]\n",
      " 18%|█████████████▊                                                               | 716/4000 [19:33<1:24:10,  1.54s/it]\n",
      " 18%|█████████████▊                                                               | 717/4000 [19:34<1:24:21,  1.54s/it]\n",
      " 18%|█████████████▊                                                               | 718/4000 [19:36<1:23:57,  1.53s/it]\n",
      " 18%|█████████████▊                                                               | 719/4000 [19:37<1:23:45,  1.53s/it]\n",
      " 18%|█████████████▊                                                               | 720/4000 [19:39<1:23:56,  1.54s/it]\n",
      " 18%|█████████████▉                                                               | 721/4000 [19:40<1:24:05,  1.54s/it]\n",
      " 18%|█████████████▉                                                               | 722/4000 [19:42<1:23:42,  1.53s/it]\n",
      " 18%|█████████████▉                                                               | 723/4000 [19:43<1:23:19,  1.53s/it]\n",
      " 18%|█████████████▉                                                               | 724/4000 [19:45<1:23:21,  1.53s/it]\n",
      " 18%|█████████████▉                                                               | 725/4000 [19:47<1:23:43,  1.53s/it]\n",
      " 18%|█████████████▉                                                               | 726/4000 [19:48<1:24:16,  1.54s/it]\n",
      " 18%|█████████████▉                                                               | 727/4000 [19:50<1:23:35,  1.53s/it]\n",
      " 18%|██████████████                                                               | 728/4000 [19:51<1:27:29,  1.60s/it]\n",
      " 18%|██████████████                                                               | 729/4000 [19:53<1:28:34,  1.62s/it]\n",
      " 18%|██████████████                                                               | 730/4000 [19:55<1:28:42,  1.63s/it]\n",
      " 18%|██████████████                                                               | 731/4000 [19:56<1:31:50,  1.69s/it]\n",
      " 18%|██████████████                                                               | 732/4000 [19:58<1:33:39,  1.72s/it]\n",
      " 18%|██████████████                                                               | 733/4000 [20:00<1:30:59,  1.67s/it]\n",
      " 18%|██████████████▏                                                              | 734/4000 [20:02<1:31:32,  1.68s/it]\n",
      " 18%|██████████████▏                                                              | 735/4000 [20:03<1:33:13,  1.71s/it]\n",
      " 18%|██████████████▏                                                              | 736/4000 [20:05<1:32:53,  1.71s/it]\n",
      " 18%|██████████████▏                                                              | 737/4000 [20:07<1:31:19,  1.68s/it]\n",
      " 18%|██████████████▏                                                              | 738/4000 [20:08<1:29:45,  1.65s/it]\n",
      " 18%|██████████████▏                                                              | 739/4000 [20:10<1:26:42,  1.60s/it]\n",
      " 18%|██████████████▏                                                              | 740/4000 [20:11<1:24:48,  1.56s/it]\n",
      " 19%|██████████████▎                                                              | 742/4000 [20:13<1:11:48,  1.32s/it]\n",
      " 19%|██████████████▎                                                              | 743/4000 [20:14<1:13:27,  1.35s/it]\n",
      " 19%|██████████████▎                                                              | 744/4000 [20:16<1:14:58,  1.38s/it]\n",
      " 19%|██████████████▎                                                              | 745/4000 [20:17<1:16:14,  1.41s/it]\n",
      " 19%|██████████████▎                                                              | 746/4000 [20:18<1:16:19,  1.41s/it]\n",
      " 19%|██████████████▍                                                              | 747/4000 [20:20<1:17:27,  1.43s/it]\n",
      " 19%|██████████████▍                                                              | 748/4000 [20:21<1:18:10,  1.44s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                              | 749/4000 [20:23<1:18:28,  1.45s/it]\n",
      " 19%|██████████████▍                                                              | 750/4000 [20:24<1:19:07,  1.46s/it]\n",
      " 19%|██████████████▍                                                              | 751/4000 [20:26<1:18:44,  1.45s/it]\n",
      " 19%|██████████████▍                                                              | 752/4000 [20:28<1:23:56,  1.55s/it]\n",
      " 19%|██████████████▍                                                              | 753/4000 [20:29<1:23:49,  1.55s/it]\n",
      " 19%|██████████████▌                                                              | 754/4000 [20:31<1:22:13,  1.52s/it]\n",
      " 19%|██████████████▌                                                              | 755/4000 [20:32<1:21:11,  1.50s/it]\n",
      " 19%|██████████████▌                                                              | 756/4000 [20:34<1:21:29,  1.51s/it]\n",
      " 19%|██████████████▌                                                              | 757/4000 [20:35<1:20:19,  1.49s/it]\n",
      " 19%|██████████████▌                                                              | 758/4000 [20:36<1:19:27,  1.47s/it]\n",
      " 19%|██████████████▌                                                              | 759/4000 [20:38<1:18:43,  1.46s/it]\n",
      " 19%|██████████████▋                                                              | 760/4000 [20:40<1:23:05,  1.54s/it]\n",
      " 19%|██████████████▋                                                              | 761/4000 [20:41<1:23:38,  1.55s/it]\n",
      " 19%|██████████████▋                                                              | 762/4000 [20:43<1:23:07,  1.54s/it]\n",
      " 19%|██████████████▋                                                              | 763/4000 [20:45<1:32:07,  1.71s/it]\n",
      " 19%|██████████████▋                                                              | 764/4000 [20:46<1:29:02,  1.65s/it]\n",
      " 19%|██████████████▋                                                              | 765/4000 [20:48<1:25:18,  1.58s/it]\n",
      " 19%|██████████████▋                                                              | 766/4000 [20:49<1:22:40,  1.53s/it]\n",
      " 19%|██████████████▊                                                              | 767/4000 [20:51<1:21:26,  1.51s/it]\n",
      " 19%|██████████████▊                                                              | 768/4000 [20:52<1:20:42,  1.50s/it]\n",
      " 19%|██████████████▊                                                              | 769/4000 [20:54<1:20:31,  1.50s/it]\n",
      " 19%|██████████████▊                                                              | 770/4000 [20:55<1:20:18,  1.49s/it]\n",
      " 19%|██████████████▊                                                              | 771/4000 [20:56<1:19:34,  1.48s/it]\n",
      " 19%|██████████████▊                                                              | 772/4000 [20:58<1:19:46,  1.48s/it]\n",
      " 19%|██████████████▉                                                              | 773/4000 [20:59<1:19:03,  1.47s/it]\n",
      " 19%|██████████████▉                                                              | 774/4000 [21:01<1:18:33,  1.46s/it]\n",
      " 19%|██████████████▉                                                              | 775/4000 [21:02<1:18:49,  1.47s/it]\n",
      " 19%|██████████████▉                                                              | 776/4000 [21:04<1:19:26,  1.48s/it]\n",
      " 19%|██████████████▉                                                              | 777/4000 [21:06<1:24:33,  1.57s/it]\n",
      " 19%|██████████████▉                                                              | 778/4000 [21:07<1:23:41,  1.56s/it]\n",
      " 19%|██████████████▉                                                              | 779/4000 [21:09<1:22:31,  1.54s/it]\n",
      " 20%|███████████████                                                              | 780/4000 [21:10<1:20:54,  1.51s/it]\n",
      " 20%|███████████████                                                              | 781/4000 [21:12<1:20:09,  1.49s/it]\n",
      " 20%|███████████████                                                              | 782/4000 [21:13<1:19:43,  1.49s/it]\n",
      " 20%|███████████████                                                              | 783/4000 [21:15<1:20:59,  1.51s/it]\n",
      " 20%|███████████████                                                              | 784/4000 [21:16<1:19:38,  1.49s/it]\n",
      " 20%|███████████████                                                              | 785/4000 [21:17<1:18:25,  1.46s/it]\n",
      " 20%|███████████████▏                                                             | 786/4000 [21:19<1:17:36,  1.45s/it]\n",
      " 20%|███████████████▏                                                             | 787/4000 [21:20<1:17:03,  1.44s/it]\n",
      " 20%|███████████████▏                                                             | 788/4000 [21:22<1:16:57,  1.44s/it]\n",
      " 20%|███████████████▏                                                             | 789/4000 [21:23<1:16:48,  1.44s/it]\n",
      " 20%|███████████████▏                                                             | 790/4000 [21:25<1:16:37,  1.43s/it]\n",
      " 20%|███████████████▏                                                             | 791/4000 [21:26<1:16:20,  1.43s/it]\n",
      " 20%|███████████████▏                                                             | 792/4000 [21:27<1:17:07,  1.44s/it]\n",
      " 20%|███████████████▎                                                             | 793/4000 [21:29<1:16:45,  1.44s/it]\n",
      " 20%|███████████████▎                                                             | 794/4000 [21:30<1:16:23,  1.43s/it]\n",
      " 20%|███████████████▎                                                             | 795/4000 [21:32<1:16:03,  1.42s/it]\n",
      " 20%|███████████████▎                                                             | 796/4000 [21:33<1:15:59,  1.42s/it]\n",
      " 20%|███████████████▎                                                             | 797/4000 [21:35<1:15:59,  1.42s/it]\n",
      " 20%|███████████████▎                                                             | 798/4000 [21:36<1:17:01,  1.44s/it]\n",
      " 20%|███████████████▍                                                             | 799/4000 [21:38<1:20:32,  1.51s/it]\n",
      " 20%|███████████████▍                                                             | 800/4000 [21:39<1:19:24,  1.49s/it]\n",
      " 20%|███████████████▍                                                             | 801/4000 [21:41<1:19:11,  1.49s/it]\n",
      " 20%|███████████████▍                                                             | 802/4000 [21:42<1:19:41,  1.50s/it]\n",
      " 20%|███████████████▍                                                             | 803/4000 [21:44<1:19:11,  1.49s/it]\n",
      " 20%|███████████████▍                                                             | 804/4000 [21:45<1:21:58,  1.54s/it]\n",
      " 20%|███████████████▍                                                             | 805/4000 [21:47<1:21:13,  1.53s/it]\n",
      " 20%|███████████████▌                                                             | 806/4000 [21:48<1:20:02,  1.50s/it]\n",
      " 20%|███████████████▌                                                             | 807/4000 [21:50<1:19:30,  1.49s/it]\n",
      " 20%|███████████████▌                                                             | 808/4000 [21:51<1:18:45,  1.48s/it]\n",
      " 20%|███████████████▌                                                             | 809/4000 [21:53<1:18:10,  1.47s/it]\n",
      " 20%|███████████████▌                                                             | 810/4000 [21:54<1:17:51,  1.46s/it]\n",
      " 20%|███████████████▌                                                             | 811/4000 [21:55<1:17:47,  1.46s/it]\n",
      " 20%|███████████████▋                                                             | 812/4000 [21:57<1:17:20,  1.46s/it]\n",
      " 20%|███████████████▋                                                             | 813/4000 [21:58<1:16:53,  1.45s/it]\n",
      " 20%|███████████████▋                                                             | 814/4000 [22:00<1:16:41,  1.44s/it]\n",
      " 20%|███████████████▋                                                             | 815/4000 [22:01<1:16:58,  1.45s/it]\n",
      " 20%|███████████████▋                                                             | 816/4000 [22:03<1:17:20,  1.46s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▋                                                             | 817/4000 [22:04<1:16:57,  1.45s/it]\n",
      " 20%|███████████████▋                                                             | 818/4000 [22:06<1:16:58,  1.45s/it]\n",
      " 20%|███████████████▊                                                             | 819/4000 [22:07<1:16:56,  1.45s/it]\n",
      " 20%|███████████████▊                                                             | 820/4000 [22:08<1:16:57,  1.45s/it]\n",
      " 21%|███████████████▊                                                             | 821/4000 [22:10<1:16:56,  1.45s/it]\n",
      " 21%|███████████████▊                                                             | 822/4000 [22:11<1:18:12,  1.48s/it]\n",
      " 21%|███████████████▊                                                             | 823/4000 [22:13<1:17:50,  1.47s/it]\n",
      " 21%|███████████████▊                                                             | 824/4000 [22:15<1:19:42,  1.51s/it]\n",
      " 21%|███████████████▉                                                             | 825/4000 [22:16<1:21:58,  1.55s/it]\n",
      " 21%|███████████████▉                                                             | 826/4000 [22:18<1:22:07,  1.55s/it]\n",
      " 21%|███████████████▉                                                             | 827/4000 [22:19<1:22:33,  1.56s/it]\n",
      " 21%|███████████████▉                                                             | 828/4000 [22:21<1:21:39,  1.54s/it]\n",
      " 21%|███████████████▉                                                             | 829/4000 [22:22<1:20:59,  1.53s/it]\n",
      " 21%|███████████████▉                                                             | 830/4000 [22:24<1:24:42,  1.60s/it]\n",
      " 21%|███████████████▉                                                             | 831/4000 [22:26<1:26:13,  1.63s/it]\n",
      " 21%|████████████████                                                             | 832/4000 [22:27<1:25:01,  1.61s/it]\n",
      " 21%|████████████████                                                             | 833/4000 [22:29<1:24:34,  1.60s/it]\n",
      " 21%|████████████████                                                             | 834/4000 [22:30<1:23:33,  1.58s/it]\n",
      " 21%|████████████████                                                             | 835/4000 [22:32<1:22:33,  1.57s/it]\n",
      " 21%|████████████████                                                             | 836/4000 [22:33<1:21:24,  1.54s/it]\n",
      " 21%|████████████████                                                             | 837/4000 [22:35<1:20:37,  1.53s/it]\n",
      " 21%|████████████████▏                                                            | 838/4000 [22:36<1:20:14,  1.52s/it]\n",
      " 21%|████████████████▏                                                            | 839/4000 [22:38<1:19:44,  1.51s/it]\n",
      " 21%|████████████████▏                                                            | 840/4000 [22:40<1:20:24,  1.53s/it]\n",
      " 21%|████████████████▏                                                            | 841/4000 [22:41<1:20:32,  1.53s/it]\n",
      " 21%|████████████████▏                                                            | 842/4000 [22:43<1:20:40,  1.53s/it]\n",
      " 21%|████████████████▏                                                            | 843/4000 [22:44<1:21:30,  1.55s/it]\n",
      " 21%|████████████████▏                                                            | 844/4000 [22:46<1:23:03,  1.58s/it]\n",
      " 21%|████████████████▎                                                            | 845/4000 [22:47<1:22:24,  1.57s/it]\n",
      " 21%|████████████████▎                                                            | 846/4000 [22:49<1:21:54,  1.56s/it]\n",
      " 21%|████████████████▎                                                            | 847/4000 [22:51<1:23:17,  1.59s/it]\n",
      " 21%|████████████████▎                                                            | 848/4000 [22:52<1:23:07,  1.58s/it]\n",
      " 21%|████████████████▎                                                            | 849/4000 [22:54<1:23:42,  1.59s/it]\n",
      " 21%|████████████████▎                                                            | 850/4000 [22:55<1:22:39,  1.57s/it]\n",
      " 21%|████████████████▍                                                            | 851/4000 [22:57<1:22:41,  1.58s/it]\n",
      " 21%|████████████████▍                                                            | 852/4000 [22:58<1:23:14,  1.59s/it]\n",
      " 21%|████████████████▍                                                            | 853/4000 [23:00<1:22:44,  1.58s/it]\n",
      " 21%|████████████████▍                                                            | 854/4000 [23:02<1:21:33,  1.56s/it]\n",
      " 21%|████████████████▍                                                            | 855/4000 [23:03<1:22:41,  1.58s/it]\n",
      " 21%|████████████████▍                                                            | 856/4000 [23:05<1:22:37,  1.58s/it]\n",
      " 21%|████████████████▍                                                            | 857/4000 [23:06<1:22:25,  1.57s/it]\n",
      " 21%|████████████████▌                                                            | 858/4000 [23:08<1:21:18,  1.55s/it]\n",
      " 21%|████████████████▌                                                            | 859/4000 [23:09<1:21:45,  1.56s/it]\n",
      " 22%|████████████████▌                                                            | 860/4000 [23:11<1:21:16,  1.55s/it]\n",
      " 22%|████████████████▌                                                            | 861/4000 [23:13<1:23:19,  1.59s/it]\n",
      " 22%|████████████████▌                                                            | 862/4000 [23:14<1:24:21,  1.61s/it]\n",
      " 22%|████████████████▌                                                            | 863/4000 [23:16<1:23:50,  1.60s/it]\n",
      " 22%|████████████████▋                                                            | 864/4000 [23:17<1:21:57,  1.57s/it]\n",
      " 22%|████████████████▋                                                            | 865/4000 [23:19<1:19:54,  1.53s/it]\n",
      " 22%|████████████████▋                                                            | 866/4000 [23:20<1:18:16,  1.50s/it]\n",
      " 22%|████████████████▋                                                            | 867/4000 [23:22<1:17:08,  1.48s/it]\n",
      " 22%|████████████████▋                                                            | 868/4000 [23:23<1:16:25,  1.46s/it]\n",
      " 22%|████████████████▋                                                            | 869/4000 [23:25<1:16:17,  1.46s/it]\n",
      " 22%|████████████████▋                                                            | 870/4000 [23:26<1:15:54,  1.46s/it]\n",
      " 22%|████████████████▊                                                            | 871/4000 [23:27<1:15:25,  1.45s/it]\n",
      " 22%|████████████████▊                                                            | 872/4000 [23:29<1:15:06,  1.44s/it]\n",
      " 22%|████████████████▊                                                            | 873/4000 [23:30<1:14:45,  1.43s/it]\n",
      " 22%|████████████████▊                                                            | 874/4000 [23:32<1:14:34,  1.43s/it]\n",
      " 22%|████████████████▊                                                            | 875/4000 [23:33<1:14:30,  1.43s/it]\n",
      " 22%|████████████████▊                                                            | 876/4000 [23:35<1:14:43,  1.44s/it]\n",
      " 22%|████████████████▉                                                            | 877/4000 [23:36<1:14:46,  1.44s/it]\n",
      " 22%|████████████████▉                                                            | 878/4000 [23:37<1:15:05,  1.44s/it]\n",
      " 22%|████████████████▉                                                            | 879/4000 [23:39<1:14:43,  1.44s/it]\n",
      " 22%|████████████████▉                                                            | 880/4000 [23:40<1:14:36,  1.43s/it]\n",
      " 22%|████████████████▉                                                            | 881/4000 [23:42<1:14:21,  1.43s/it]\n",
      " 22%|████████████████▉                                                            | 882/4000 [23:43<1:14:17,  1.43s/it]\n",
      " 22%|████████████████▉                                                            | 883/4000 [23:45<1:14:29,  1.43s/it]\n",
      " 22%|█████████████████                                                            | 884/4000 [23:46<1:14:41,  1.44s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████                                                            | 885/4000 [23:47<1:14:54,  1.44s/it]\n",
      " 22%|█████████████████                                                            | 886/4000 [23:49<1:14:44,  1.44s/it]\n",
      " 22%|█████████████████                                                            | 887/4000 [23:50<1:14:26,  1.43s/it]\n",
      " 22%|█████████████████                                                            | 888/4000 [23:52<1:14:15,  1.43s/it]\n",
      " 22%|█████████████████                                                            | 889/4000 [23:53<1:14:54,  1.44s/it]\n",
      " 22%|█████████████████▏                                                           | 890/4000 [23:55<1:14:40,  1.44s/it]\n",
      " 22%|█████████████████▏                                                           | 891/4000 [23:56<1:14:22,  1.44s/it]\n",
      " 22%|█████████████████▏                                                           | 892/4000 [23:58<1:16:58,  1.49s/it]\n",
      " 22%|█████████████████▏                                                           | 893/4000 [23:59<1:19:17,  1.53s/it]\n",
      " 22%|█████████████████▏                                                           | 894/4000 [24:01<1:19:43,  1.54s/it]\n",
      " 22%|█████████████████▏                                                           | 895/4000 [24:03<1:20:57,  1.56s/it]\n",
      " 22%|█████████████████▏                                                           | 896/4000 [24:04<1:20:51,  1.56s/it]\n",
      " 22%|█████████████████▎                                                           | 897/4000 [24:06<1:20:26,  1.56s/it]\n",
      " 22%|█████████████████▎                                                           | 898/4000 [24:07<1:19:44,  1.54s/it]\n",
      " 22%|█████████████████▎                                                           | 899/4000 [24:09<1:19:12,  1.53s/it]\n",
      " 22%|█████████████████▎                                                           | 900/4000 [24:10<1:18:57,  1.53s/it]\n",
      " 23%|█████████████████▎                                                           | 901/4000 [24:12<1:19:03,  1.53s/it]\n",
      " 23%|█████████████████▎                                                           | 902/4000 [24:13<1:19:03,  1.53s/it]\n",
      " 23%|█████████████████▍                                                           | 903/4000 [24:15<1:20:21,  1.56s/it]\n",
      " 23%|█████████████████▍                                                           | 904/4000 [24:16<1:19:38,  1.54s/it]\n",
      " 23%|█████████████████▍                                                           | 905/4000 [24:18<1:19:36,  1.54s/it]\n",
      " 23%|█████████████████▍                                                           | 906/4000 [24:19<1:19:56,  1.55s/it]\n",
      " 23%|█████████████████▍                                                           | 907/4000 [24:21<1:19:07,  1.53s/it]\n",
      " 23%|█████████████████▍                                                           | 908/4000 [24:22<1:18:52,  1.53s/it]\n",
      " 23%|█████████████████▍                                                           | 909/4000 [24:24<1:19:09,  1.54s/it]\n",
      " 23%|█████████████████▌                                                           | 910/4000 [24:26<1:19:04,  1.54s/it]\n",
      " 23%|█████████████████▌                                                           | 911/4000 [24:27<1:18:33,  1.53s/it]\n",
      " 23%|█████████████████▌                                                           | 912/4000 [24:29<1:18:15,  1.52s/it]\n",
      " 23%|█████████████████▌                                                           | 913/4000 [24:30<1:19:39,  1.55s/it]\n",
      " 23%|█████████████████▌                                                           | 914/4000 [24:32<1:19:24,  1.54s/it]\n",
      " 23%|█████████████████▌                                                           | 915/4000 [24:33<1:18:52,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 916/4000 [24:35<1:18:35,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 917/4000 [24:36<1:18:46,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 918/4000 [24:38<1:18:45,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 919/4000 [24:39<1:18:23,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 920/4000 [24:41<1:18:27,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 921/4000 [24:42<1:18:45,  1.53s/it]\n",
      " 23%|█████████████████▋                                                           | 922/4000 [24:44<1:18:45,  1.54s/it]\n",
      " 23%|█████████████████▊                                                           | 923/4000 [24:46<1:19:43,  1.55s/it]\n",
      " 23%|█████████████████▊                                                           | 924/4000 [24:47<1:18:57,  1.54s/it]\n",
      " 23%|█████████████████▊                                                           | 925/4000 [24:49<1:18:43,  1.54s/it]\n",
      " 23%|█████████████████▊                                                           | 926/4000 [24:50<1:18:59,  1.54s/it]\n",
      " 23%|█████████████████▊                                                           | 927/4000 [24:52<1:18:30,  1.53s/it]\n",
      " 23%|█████████████████▊                                                           | 928/4000 [24:53<1:18:15,  1.53s/it]\n",
      " 23%|█████████████████▉                                                           | 929/4000 [24:55<1:17:49,  1.52s/it]\n",
      " 23%|█████████████████▉                                                           | 930/4000 [24:56<1:18:28,  1.53s/it]\n",
      " 23%|█████████████████▉                                                           | 931/4000 [24:58<1:18:36,  1.54s/it]\n",
      " 23%|█████████████████▉                                                           | 932/4000 [24:59<1:18:08,  1.53s/it]\n",
      " 23%|█████████████████▉                                                           | 933/4000 [25:01<1:18:26,  1.53s/it]\n",
      " 23%|█████████████████▉                                                           | 934/4000 [25:02<1:18:24,  1.53s/it]\n",
      " 23%|█████████████████▉                                                           | 935/4000 [25:04<1:17:59,  1.53s/it]\n",
      " 23%|██████████████████                                                           | 936/4000 [25:05<1:18:17,  1.53s/it]\n",
      " 23%|██████████████████                                                           | 937/4000 [25:07<1:17:39,  1.52s/it]\n",
      " 23%|██████████████████                                                           | 938/4000 [25:08<1:17:39,  1.52s/it]\n",
      " 23%|██████████████████                                                           | 939/4000 [25:10<1:17:20,  1.52s/it]\n",
      " 24%|██████████████████                                                           | 940/4000 [25:11<1:17:17,  1.52s/it]\n",
      " 24%|██████████████████                                                           | 941/4000 [25:13<1:17:30,  1.52s/it]\n",
      " 24%|██████████████████▏                                                          | 942/4000 [25:15<1:17:46,  1.53s/it]\n",
      " 24%|██████████████████▏                                                          | 943/4000 [25:16<1:17:55,  1.53s/it]\n",
      " 24%|██████████████████▏                                                          | 944/4000 [25:18<1:18:11,  1.54s/it]\n",
      " 24%|██████████████████▏                                                          | 945/4000 [25:19<1:18:08,  1.53s/it]\n",
      " 24%|██████████████████▏                                                          | 946/4000 [25:21<1:17:54,  1.53s/it]\n",
      " 24%|██████████████████▏                                                          | 947/4000 [25:22<1:17:28,  1.52s/it]\n",
      " 24%|██████████████████▏                                                          | 948/4000 [25:24<1:18:50,  1.55s/it]\n",
      " 24%|██████████████████▎                                                          | 949/4000 [25:25<1:18:06,  1.54s/it]\n",
      " 24%|██████████████████▎                                                          | 950/4000 [25:27<1:17:37,  1.53s/it]\n",
      " 24%|██████████████████▎                                                          | 951/4000 [25:28<1:17:12,  1.52s/it]\n",
      " 24%|██████████████████▎                                                          | 952/4000 [25:30<1:17:10,  1.52s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▎                                                          | 953/4000 [25:31<1:17:08,  1.52s/it]\n",
      " 24%|██████████████████▎                                                          | 954/4000 [25:33<1:17:33,  1.53s/it]\n",
      " 24%|██████████████████▍                                                          | 955/4000 [25:34<1:17:35,  1.53s/it]\n",
      " 24%|██████████████████▍                                                          | 956/4000 [25:36<1:17:10,  1.52s/it]\n",
      " 24%|██████████████████▍                                                          | 957/4000 [25:37<1:16:56,  1.52s/it]\n",
      " 24%|██████████████████▍                                                          | 958/4000 [25:39<1:16:53,  1.52s/it]\n",
      " 24%|██████████████████▍                                                          | 959/4000 [25:40<1:16:41,  1.51s/it]\n",
      " 24%|██████████████████▍                                                          | 960/4000 [25:42<1:17:57,  1.54s/it]\n",
      " 24%|██████████████████▍                                                          | 961/4000 [25:44<1:18:13,  1.54s/it]\n",
      " 24%|██████████████████▌                                                          | 962/4000 [25:45<1:18:08,  1.54s/it]\n",
      " 24%|██████████████████▌                                                          | 963/4000 [25:47<1:17:42,  1.54s/it]\n",
      " 24%|██████████████████▌                                                          | 964/4000 [25:48<1:17:14,  1.53s/it]\n",
      " 24%|██████████████████▌                                                          | 965/4000 [25:50<1:16:55,  1.52s/it]\n",
      " 24%|██████████████████▌                                                          | 966/4000 [25:51<1:16:44,  1.52s/it]\n",
      " 24%|██████████████████▌                                                          | 967/4000 [25:53<1:17:23,  1.53s/it]\n",
      " 24%|██████████████████▋                                                          | 968/4000 [25:54<1:17:19,  1.53s/it]\n",
      " 24%|██████████████████▋                                                          | 969/4000 [25:56<1:16:52,  1.52s/it]\n",
      " 24%|██████████████████▋                                                          | 970/4000 [25:57<1:19:09,  1.57s/it]\n",
      " 24%|██████████████████▋                                                          | 971/4000 [25:59<1:18:53,  1.56s/it]\n",
      " 24%|██████████████████▋                                                          | 972/4000 [26:01<1:19:10,  1.57s/it]\n",
      " 24%|██████████████████▋                                                          | 973/4000 [26:02<1:19:47,  1.58s/it]\n",
      " 24%|██████████████████▋                                                          | 974/4000 [26:04<1:19:29,  1.58s/it]\n",
      " 24%|██████████████████▊                                                          | 975/4000 [26:05<1:18:32,  1.56s/it]\n",
      " 24%|██████████████████▊                                                          | 976/4000 [26:07<1:18:37,  1.56s/it]\n",
      " 24%|██████████████████▊                                                          | 977/4000 [26:09<1:21:36,  1.62s/it]\n",
      " 24%|██████████████████▊                                                          | 978/4000 [26:10<1:20:05,  1.59s/it]\n",
      " 24%|██████████████████▊                                                          | 979/4000 [26:12<1:20:32,  1.60s/it]\n",
      " 24%|██████████████████▊                                                          | 980/4000 [26:13<1:21:37,  1.62s/it]\n",
      " 25%|██████████████████▉                                                          | 981/4000 [26:15<1:20:27,  1.60s/it]\n",
      " 25%|██████████████████▉                                                          | 982/4000 [26:17<1:19:19,  1.58s/it]\n",
      " 25%|██████████████████▉                                                          | 983/4000 [26:18<1:18:23,  1.56s/it]\n",
      " 25%|██████████████████▉                                                          | 984/4000 [26:20<1:18:05,  1.55s/it]\n",
      " 25%|██████████████████▉                                                          | 985/4000 [26:21<1:17:18,  1.54s/it]\n",
      " 25%|██████████████████▉                                                          | 986/4000 [26:23<1:17:26,  1.54s/it]\n",
      " 25%|██████████████████▉                                                          | 987/4000 [26:24<1:17:14,  1.54s/it]\n",
      " 25%|███████████████████                                                          | 988/4000 [26:26<1:17:30,  1.54s/it]\n",
      " 25%|███████████████████                                                          | 989/4000 [26:27<1:17:15,  1.54s/it]\n",
      " 25%|███████████████████                                                          | 990/4000 [26:29<1:16:39,  1.53s/it]\n",
      " 25%|███████████████████                                                          | 991/4000 [26:30<1:16:13,  1.52s/it]\n",
      " 25%|███████████████████                                                          | 992/4000 [26:32<1:15:55,  1.51s/it]\n",
      " 25%|███████████████████                                                          | 993/4000 [26:33<1:18:43,  1.57s/it]\n",
      " 25%|███████████████████▏                                                         | 994/4000 [26:35<1:17:53,  1.55s/it]\n",
      " 25%|███████████████████▏                                                         | 995/4000 [26:36<1:17:28,  1.55s/it]\n",
      " 25%|███████████████████▏                                                         | 996/4000 [26:38<1:18:57,  1.58s/it]\n",
      " 25%|███████████████████▏                                                         | 997/4000 [26:40<1:19:40,  1.59s/it]\n",
      " 25%|███████████████████▏                                                         | 998/4000 [26:41<1:18:22,  1.57s/it]\n",
      " 25%|███████████████████▏                                                         | 999/4000 [26:43<1:17:37,  1.55s/it]"
     ]
    }
   ],
   "source": [
    "prepocessed_texts_test = []\n",
    "i= 0\n",
    "for text in tqdm(x_test_tokenized):\n",
    "  i+=1\n",
    "  prepocessed_texts_test.append(phrases_processor.process(text))\n",
    "  if i==1000:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prepocessed_texts.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)\n",
    "\n",
    "with open('prepocessed_texts_test.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)\n",
    "    \n",
    "with open('y_test.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_train.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)\n",
    "    \n",
    "with open('x_test.pkl', 'wb') as fp:\n",
    "    pickle.dump(prepocessed_texts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop targets\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = cwd + '\\\\models\\\\word2vec\\\\ruwikiruscorpora-nobigrams_upos_skipgram_300_5_2018.vec.gz'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.most_similar('платить_VERB')\n",
    "#word_vector = model['платить_VERB']\n",
    "#word_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('играмм_NOUN', 0.6844817399978638),\n",
       " ('игругой_NOUN', 0.6661473512649536),\n",
       " ('игра_PROPN', 0.6560357809066772),\n",
       " ('игре_VERB', 0.6470746994018555),\n",
       " ('игр_NOUN', 0.6220640540122986),\n",
       " ('видеоигра_NOUN', 0.6018214225769043),\n",
       " ('dishonored_PROPN', 0.5930976867675781),\n",
       " ('littlebigplanet_PROPN', 0.5877217054367065),\n",
       " (\"mirror's_PROPN\", 0.5868256688117981),\n",
       " ('moba_PROPN', 0.5865598320960999)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.most_similar('платить_VERB')\n",
    "#word_vector = model['платить_VERB']\n",
    "#word_vector.shape\n",
    "model.most_similar('игра_NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = model['и']\n",
    "word_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 97.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(\n",
    "    char_level=True,\n",
    "    #filters=None,\n",
    "    lower=True,\n",
    "    num_words=max_features\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(prepocessed_texts)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(prepocessed_texts)\n",
    "x_test = tokenizer.texts_to_sequences(prepocessed_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = sequence.pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 100\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "word_index = tokenizer.word_index\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = model[word]\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 3 for 'conv1d_12/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,3,128], [1,5,128,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 3 for 'conv1d_12/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,3,128], [1,5,128,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-a4c8617151a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# global max pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                 dilation_rate=self.dilation_rate[0])\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             outputs = K.conv2d(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3609\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3611\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         data_format=data_format)\n\u001b[1;32m--> 780\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv1d\u001b[1;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m   \u001b[1;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 553\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 553\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    555\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m         data_format=data_format)\n\u001b[0m\u001b[0;32m   2472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m    957\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 3 for 'conv1d_12/convolution/Conv2D' (op: 'Conv2D') with input shapes: [?,1,3,128], [1,5,128,128]."
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
    "          epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
